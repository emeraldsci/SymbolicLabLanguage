(* ::Package:: *)

(* ::Text:: *)
(*\[Copyright] 2011-2023 Emerald Cloud Lab, Inc.*)


(* ::Section:: *)
(*Source Code*)


(* ::Subsection:: *)
(*AnalyzePeaks*)


(* ::Subsubsection:: *)
(*Options*)


(* ---------------------- *)
(* --- DEFINE OPTIONS --- *)
(* ---------------------- *)



DefineOptions[AnalyzePeaks,
	Options :> {
		IndexMatching[
			{
				OptionName -> ReferenceField,
				Default -> Automatic,
				Description -> "Specify which field in data object will be analyzed for peaks.",
				AllowNull -> True,
				Category -> "General",
				Widget -> With[
					{
						referenceFieldP=Alternatives[
							(* 2D Fields *)
							AbsorbanceSpectrum,Chromatogram,SecondaryChromatogram,
							Absorbance,SecondaryAbsorbance,Conductance,Scattering,
							Fluorescence,SecondaryFluorescence,TertiaryFluorescence,QuaternaryFluorescence,
							Conductance,ConductivityFlowCellTemperature,pH,pHFlowCellTemperature,
							MultiAngleLightScattering22Degree,MultiAngleLightScattering28Degree,MultiAngleLightScattering32Degree,MultiAngleLightScattering38Degree,
							MultiAngleLightScattering44Degree,MultiAngleLightScattering50Degree,MultiAngleLightScattering57Degree,MultiAngleLightScattering64Degree,
							MultiAngleLightScattering72Degree,MultiAngleLightScattering81Degree,MultiAngleLightScattering90Degree,MultiAngleLightScattering99Degree,
							MultiAngleLightScattering108Degree,MultiAngleLightScattering117Degree,MultiAngleLightScattering126Degree,MultiAngleLightScattering134Degree,
							MultiAngleLightScattering141Degree,MultiAngleLightScattering147Degree,
							DynamicLightScattering,RefractiveIndex,ExcitationSpectrum,EmissionSpectrum,
							Intensity,MassSpectrum,NMRSpectrum,OptimalLaneImage,OptimalLaneIntensity,
							LowExposureLaneIntensity,MediumLowExposureLaneIntensity,MediumHighExposureLaneIntensity,HighExposureLaneIntensity,
							LowExposureLadderIntensity,MediumLowExposureLadderIntensity,MediumHighExposureLadderIntensity,HighExposureLadderIntensity,
							LowExposureGelImage,MediumLowExposureGelImage,MediumHighExposureGelImage,HighExposureGelImage,
							LowExposureGelImageFile,MediumLowExposureGelImageFile,MediumHighExposureGelImageFile,HighExposureGelImageFile,
							LaneImage,BlankedDiffractionPattern,SampleElectropherogram,MarkerElectropherogram,
							PostSelectionElectropherogram,HeatingCurves,MolarHeatingCurves,FIDResponse,Charge,
							InitialIntensityDistribution,InitialMassDistribution,FinalIntensityDistribution,FinalMassDistribution,
							AbsorbanceSpectrum,AbsorbanceDifferenceSpectrum,CircularDichroismAbsorbanceSpectrum,CircularDichroismSpectrum,
							UnblankedAbsorbanceSpectrum,UnblankedAbsorbanceDifferenceSpectrum,UnblankedCircularDichroismAbsorbanceSpectrum,
							IntensityDistribution,MassDistribution,IonAbundance,ProcessedUVAbsorbanceData,RelativeMigrationData,Electropherogram,DNAFragmentSizeAnalyses,RNAFragmentSizeAnalyses,
							(* 3D Fields *)
							Absorbance3D,Chromatogram3D,IonAbundance3D
						]
					},
					Alternatives[
						Widget[Type->Enumeration,Pattern:>referenceFieldP],
						Adder[Widget[Type->Enumeration,Pattern:>referenceFieldP]]
					]
				]
			},
			{
				OptionName -> DataSetTransformationFunction,
				Default -> Null,
				Description -> "A pure function or quantity function which will be mapped over the resolved raw input data prior to peak-picking.",
				AllowNull -> True,
				Category -> "General",
				Widget -> Alternatives[
					"Scale"->Widget[Type->Enumeration,Pattern:>LogLinear|LinearLog|LogLog],
					"f[{x,y}]"->Widget[Type->Expression,Pattern:>_Function|_QuantityFunction,Size->Line,PatternTooltip->"A pure function of the form f[{x,y}]->{x2,y2}."],
					"f[x],g[y]"->{
						"X transform"->Alternatives[
							"Function"->Widget[Type->Expression,Pattern:>_Function|_QuantityFunction,Size->Line,PatternTooltip->"A pure function of the form f[x]->x2."],
							Widget[Type->Enumeration,Pattern:>Alternatives[None]]
						],
						"Y transform"->Alternatives[
							"Function"->Widget[Type->Expression,Pattern:>_Function|_QuantityFunction,Size->Line,PatternTooltip->"A pure function of the form f[y]->y2."],
							Widget[Type->Enumeration,Pattern:>Alternatives[None]]
						]
					}
				]
			},
			{
				OptionName -> Wavelength,
				Default -> Automatic,
				Description -> "Specify which slice of data to look at when working with 3D Chromatography data. Automatic will default to the minimum wavelength.",
				AllowNull -> True,
				Category -> "General",
				Widget -> Widget[Type -> Quantity, Pattern :> GreaterEqualP[0 Nanometer, Nanometer], Units -> Alternatives[Nanometer]]
			},
			{
				OptionName -> Name,
				Default -> Null,
				Description -> "Name to be used for the Object[Analysis, Peaks] generated by this analysis.",
				AllowNull -> True,
				Category -> "General",
				Widget -> Widget[Type->String,Pattern:>_String, Size -> Line]
			},
			{
				OptionName -> PeakType,
				Default -> Automatic,
				Description -> "Specify the type of peak analysis to conduct.",
				AllowNull -> True,
				Category -> "General",
				Widget -> Widget[Type->Enumeration,Pattern:>Alternatives[Chromatography, NMR, Generic, Manual]]
			},
			{
				OptionName -> DataSliceDimension,
				Default -> Automatic,
				Description -> "Specify which dimension(s) of 3+ dimensional input data should be held constant to produce two-dimensional slice(s) for peak-picking.",
				ResolutionDescription -> "Given 3+ dimensional input data, the default slice dimension(s) will be determined based on the input data type and the ReferenceField option. For 2D input data, this option defaults to Null.",
				AllowNull -> True,
				Category -> "Data Slicing",

				Widget -> Alternatives[
					Adder[Alternatives[Widget[Type->Enumeration, Pattern:>Alternatives[ElutionTime,MassToChargeRatio,Wavelength]],
						"Index"->Widget[Type->Number,Pattern:>GreaterP[0,1]]]],
					Widget[Type->Enumeration,	Pattern:>Alternatives[ElutionTime,MassToChargeRatio,Wavelength]],
						"Index"->Widget[Type->Number,Pattern:>GreaterP[0,1]]]

			},
			{
				OptionName -> DataSlice,
				Default -> Automatic,
				Description -> "For each member of DataSliceDimension, a single value or range of values over which the input data should be sliced to produce two-dimensional {x,y} data for peak picking.",
				ResolutionDescription -> "Given 3+ dimensional input data, the default slice will be determined based on the input data type and the ReferenceField option. For 2D input data, this option defaults to Null.",
				AllowNull -> True,
				Category -> "Data Slicing",
				Widget->Alternatives[
					"Single Value"->Widget[Type->Expression, Pattern:>UnitsP[], Size->Word],
					"Range"->Widget[Type -> Expression, Pattern :> Alternatives[UnitsP[];;UnitsP[], {UnitsP[];;UnitsP[]..}], Size -> Line]
				]
			},
			{
				OptionName -> SliceReductionFunction,
				Default -> Automatic,
				Description -> "For each member of DataSliceDimension, determines how the DataSlice should be flattened along that dimension if data is sliced over a range of values.",
				ResolutionDescription->"Given 3+ dimensional input data, defaults to Mean. For 2D input data, this option defaults to Null.",
				AllowNull -> True,
				Category -> "Data Slicing",
				Widget ->
					Alternatives[
						Widget[Type->Enumeration, Pattern:>Alternatives[Total,Mean,Max,Min]],
						Adder[Widget[Type->Enumeration, Pattern:>Alternatives[Total,Mean,Max,Min]]]
					]
			},
			{
				OptionName -> SliceReferencePeaks,
				Default -> Automatic,
				Description -> "A peaks analysis object which will be used as reference for slicing 3+ dimensional data. Peak positions will be used to set the default values for the DataSliceDimension and DataSlice options.",
				ResolutionDescription -> "Given 3+ dimensional input data, defaults to None. For 2D input data, this option defaults to Null.",
				AllowNull->True,
				Category -> "Data Slicing",
				Widget -> Alternatives[
					Widget[Type->Enumeration, Pattern:>Alternatives[None]],
					Widget[Type->Object, Pattern:>ObjectP[Object[Analysis,Peaks]]]
				]
			},
			{
				OptionName -> OperatingFrequency,
				Default -> Automatic,
				Description -> "Operating frequency at which input NMR data was collected.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Widget[Type->Quantity,Pattern:>GreaterP[0.0 Megahertz],Units->Megahertz]
			},
			{
				OptionName -> Nucleus,
				Default -> Automatic,
				Description -> "The nucleus whose spins were recorded in the input NMR data.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Widget[Type->Enumeration,Pattern:>Nucleus1DP]
			},
			{
				OptionName -> DeuteratedSolvent,
				Default -> Automatic,
				Description -> "The deuterated solvent used in the input NMR data.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Alternatives[
					Widget[Type->Enumeration,Pattern:>DeuteratedSolventP],
					Widget[Type->Object,Pattern:>ObjectP[{Model[Sample],Object[Sample]}]]
				]
			},
			{
				OptionName -> MaximumJSplitting,
				Default -> Automatic,
				Description -> "Adjacent peaks whose centers are separated by a distance less than MaximumJSplitting will be treated as part of the same splitting group. Values given in Hertz will be converted to PPM using the resolved OperatingFrequency.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Widget[Type->Quantity,Pattern:>GreaterEqualP[0.0 Hertz]|GreaterEqualP[0.0 PPM],Units->Alternatives[Hertz,PPM],PatternTooltip->"Must be greater than zero."]
			},
			{
				OptionName -> SplittingSpacingTolerance,
				Default -> Automatic,
				Description -> "The maximum relative deviation in peak spacing for which peaks are considered to be part of the same splitting group.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Widget[Type->Number,Pattern:>GreaterEqualP[0.0],PatternTooltip->"Must be greater than zero."]
			},
			{
				OptionName -> SplittingRelativeIntegralTolerance,
				Default -> Automatic,
				Description -> "The maximum relative deviation in peak area ratios for which peaks groups will be assigned a simple splitting pattern.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Widget[Type->Number,Pattern:>GreaterEqualP[0.0],PatternTooltip->"Must be greater than zero."]
			},
			{
				OptionName -> PeakGroupDomains,
				Default -> Automatic,
				Description -> "A list of non-overlapping PPM spans indicating the location of peak groupings.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> Adder[
					Span[
						Widget[Type->Quantity,Pattern:>RangeP[-\[Infinity]*PPM,\[Infinity]*PPM],Units->PPM],
						Widget[Type->Quantity,Pattern:>RangeP[-\[Infinity]*PPM,\[Infinity]*PPM],Units->PPM]
					]
				]
			},
			{
				OptionName -> PeakIntegralNormalizationGroup,
				Default -> Automatic,
				Description -> "The peak group and corresponding integrated area used to normalize peak areas for NMR splitting analysis.",
				ResolutionDescription -> "Automatic resolution attempts to make all peak areas as close to integers as possible.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget -> {
					"Peak Group Index"->Widget[Type->Number,Pattern:>GreaterP[0,1],PatternTooltip->"An integer index greater than zero."],
					"Integral"->Widget[Type->Number,Pattern:>GreaterP[0.0],PatternTooltip->"Must be greater than zero."]
				}
			},
			{
				OptionName -> PeakGroupMultiplicity,
				Default -> Automatic,
				Description -> "Specify the multiplicity of each NMR peak group. Listed integers may be used to specify arbitrarily complex splitting patterns, e.g. {{2,3,2},..} for a doublet of triplets of doublets.",
				ResolutionDescription -> "Automatic resolution assigns multiplicities based on peak areas and spacing, defaulting to the generic multiplet \"m\" if no canonical splitting pattern is detected.",
				AllowNull -> True,
				Category -> "NMR Peak Splitting",
				Widget ->Alternatives[
					"Select"->Adder[
						Widget[Type->Enumeration,Pattern:>Alternatives[
							"Multiplet (m)"|
							"Singlet (s)"|
							"Doublet (d)"|
							"Triplet (t)"|
							"Quartet (q)"|
							"Quintet (quint)"|
							"Sextet (sx)"|
							"Heptet (hep)"|
							"Octet (oct)"|
							"Nonet (non)"|
							"Dectet (dec)"|
							"Doublet of doublets (dd)"|
							"Doublet of triplets (dt)"|
							"Doublet of quartets (dq)"|
							"Triplet of doublets (td)"|
							"Triplet of triplets (tt)"|
							"Triplet of quartets (tq)"|
							"Quartet of doublets (qd)"|
							"Quartet of triplets (qt)"|
							"Quartet of quartets (qq)"
						]]
					],
 					"Custom"->Adder[Widget[Type->Expression,Pattern:>{(GreaterP[0,1]|"m")..},Size->Word]]
				]
			},
			{
				OptionName -> TemplateAssignmentTolerance,
				Default -> Automatic,
				Description -> "A template peak's position must be less than this amount away from a candidate peak to be considered for alignment.  Automatic resolves to 1% of total data width.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Widget[Type -> Expression, Pattern :> UnitsP[], Size->Line]
			},
			{
				OptionName -> PeakLabels,
				Default -> Automatic,
				Description -> "Labels for each peak, index-matched against peak positions.",
				ResolutionDescription -> "By default, each peak is labeled with the index of which it appears.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Alternatives[
					Adder[Widget[Type->String,Pattern:>_String,Size->Word]],
					Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				],
				Expandable->True
			},
			{
				OptionName -> ParentPeaks,
				Default -> Automatic,
				ResolutionDescription -> "When analyzing CESDS data, the default parent peak is the first identified peak. Otherwise, each peak is assigned to the largest peak found in the data object by default.",
				Description -> "The label of the parent peak that each of the found peaks is matched to.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Adder[
					Alternatives[
						"Index"->Widget[Type->Number,Pattern:>GreaterP[0,1],Min->0,PatternTooltip->"Integer greater than zero."],
						"Label"->Widget[Type->String,Pattern:>_String,Size->Word,PatternTooltip->"Label must match one of PeakLabels."]
					]
				]
			},
			{
				OptionName -> RelativeLabeling,
				Default -> Automatic,
				Description -> "If True, unlabeled peaks with be labeled with their relative retention time, e.g. RRT0.8.",
				ResolutionDescription -> "Null if PeakType is not Chromatography.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Widget[Type->Enumeration,Pattern:>BooleanP]
			},
			{
				OptionName -> PeakAssignments,
				Default -> {},
				Description -> "Putative molecule that peaks corresponds to.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Alternatives[
					"Absolute"->Adder[
						{
							"Position" -> Widget[Type->Expression,Pattern:>UnitsP[],Size->Line],
							"Model" -> Widget[Type->Object,Pattern:>ObjectP[Model[Molecule]]],
							"Tolerance" -> Widget[Type->Expression,Pattern:>UnitsP[],Size->Line]
						}
					],
					"Relative"->Adder[
						{
							"Position" -> Widget[Type->Quantity,Pattern:>GreaterP[0.0 RRT],Units->RRT,PatternTooltip->"Must be greater than zero."],
							"Model" -> Widget[Type->Object,Pattern:>ObjectP[Model[Molecule]]],
							"Tolerance" -> Widget[Type->Quantity,Pattern:>GreaterP[0.0 RRT],Units->RRT,PatternTooltip->"Must be greater than zero."]
						}
					],
					"Maximum in Range"->Adder[
						{
							"Range" -> Alternatives[
								"Unitless" -> Span[
									Widget[Type->Number, Pattern:>GreaterEqualP[0.0]],
									Widget[Type->Number, Pattern:>GreaterEqualP[0.0]]
								],
								"Units" -> Widget[Type->Expression,Pattern:>Span[UnitsP[],UnitsP[]],Size->Line]
							],
							"Model" -> Widget[Type->Object,Pattern:>ObjectP[Model[Molecule]]]
						}
					],
					"Automatic"->Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				]
			},
			{
				OptionName -> KnownSpecies,
				Default -> Null,
				Description -> "Any known molecule(s) whose signals are expected to be in the input NMR data.",
				ResolutionDescription -> "Null if PeakType is not NMR.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Alternatives[
					Adder[Alternatives[
						"Molecule"->Widget[Type->Molecule,Pattern:>MoleculeP],
						"Model"->Widget[Type->Object,Pattern:>ObjectP[Model[Molecule]],PatternTooltip->"Model representing the known molecule."]
					]],
					Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				]
			},
			{
				OptionName -> SplittingAssignments,
				Default -> Automatic,
				Description -> "A list of known atomic assignments of the form {molecule, index}, corresponding to each peak splitting group specified by PeakGroupDomains.",
				ResolutionDescription -> "Null if PeakType is not NMR. Must have the same length as PeakGroupDomains.",
				AllowNull -> True,
				Category -> "Peak Assignment",
				Widget -> Adder[
					Alternatives[
						{
							"Chemical Shift"->Widget[Type->Quantity,Pattern:>GreaterP[-10.0 PPM],Units->PPM],
							"Molecule"->Widget[Type->Molecule,Pattern:>MoleculeP],
							"Atomic Indices"->Widget[Type->Expression,Pattern:>ListableP[{_Integer...}],Size->Paragraph,BoxText->"A list of atomic indices {i1,i2,..} in the provided Molecule."]
						},
						Widget[Type->Enumeration,Pattern:>Alternatives[Unknown]]
					]
				]
			},
			{
				OptionName -> Domain,
				Default -> Automatic,
				Description -> "Any data points whose x-value lies outside of the specified domain interval(s) will be excluded from analysis. If multiple domains are specified for one input, each domain will be analyzed separately, and the analyses will be merged.",
				ResolutionDescription -> "Automatic includes all points to be the full domain.",
				AllowNull -> False,
				Category -> "Method",
				Widget->Alternatives[
					Adder[{
						"Min" -> Widget[Type -> Number, Pattern :> RangeP[-Infinity, Infinity]],
						"Max" -> Widget[Type->Number, Pattern :> RangeP[-Infinity, Infinity]]
						}],
					Widget[Type -> Expression, Pattern :> Alternatives[_Span, {_Span..}], Size -> Line]
				]
			},
			{
				OptionName -> AbsoluteThreshold,
				Default -> Automatic,
				Description -> "A peak's maximum y-value must exceed this threshold to be detected.",
				ResolutionDescription -> "AbsoluteThreshold is decided by type of input and max y-values if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Widget[Type -> Number, Pattern :> RangeP[-Infinity,Infinity]],
					Adder[Widget[Type -> Number, Pattern :> RangeP[-Infinity,Infinity]]
				]]
			},
			{
				OptionName -> RelativeThreshold,
				Default -> Automatic,
				Description -> "The distance from a peak's maximum y-value to its baseline must exceed this threshold to be detected.",
				ResolutionDescription -> "RelativeThreshold is decided by type of input and max and min y-values if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]],
					Adder[Widget[Type -> Number, Pattern :> GreaterEqualP[0]]]
				]
			},
			{
				OptionName -> WidthThreshold,
				Default -> Automatic,
				Description -> "A peak's width at half-height must exceed this threshold to be detected.",
				ResolutionDescription -> "WidthThreshold is decided by type of input and max and min x-values if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Adder[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]]
				]
			},
			{
				OptionName -> AreaThreshold,
				Default -> Automatic,
				Description -> "A peak's area must exceed this threshold to be detected.",
				ResolutionDescription -> "AreaThreshold is decided by type of input and area under curve if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]],
					Adder[Widget[Type -> Number, Pattern :> GreaterEqualP[0]]
					]]
			},
			{
				OptionName -> EdgeFraction,
				Default -> Automatic,
				Description -> "The starting and ending x-values of the peak are chosen as the points whose y-values reach this fraction of the peak's height.",
				ResolutionDescription -> "EdgeFraction is 0 if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[Widget[Type -> Number, Pattern :> GreaterEqualP[0]],
					Adder[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]]
				]]
			},
			{
				OptionName -> SmoothingRadius,
				Default -> Automatic,
				Description -> "Radius for GaussianFilter used to smooth data points before peak picking.",
				ResolutionDescription -> "SmoothingRadius is decided by type of input if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]],
					Adder[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]]
				]]
			},
			{
				OptionName -> ConsolidateWidth,
				Default -> Automatic,
				Description -> "Any peak whose width is less than ConsolidateWidth will be consolidated by merging with the closest adjacent peak.",
				ResolutionDescription -> "ConsolidateWidth is decided by type of input and max and min x-values if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]],
					Adder[
					Widget[Type -> Number, Pattern :> GreaterEqualP[0]]
				]
					]
			},
			{
				OptionName -> ConsolidateHeight,
				Default -> Automatic,
				Description -> "Any peak whose max height is not at least ConsolidateHeight larger than the height at the edge of an adjacent peak will be consolidated by merging with that adjacent peak.",
				ResolutionDescription -> "ConsolidateHeight is decided by type of input and max and min y-values if set to Automatic.",
				AllowNull -> False,
				Category -> "Method",
				Widget ->
					Alternatives[
						Widget[Type -> Number, Pattern :> GreaterEqualP[0]],
						Adder[
							Widget[Type -> Number, Pattern :> GreaterEqualP[0]]
						]
					]
			},
			{
				OptionName -> Include,
				Default -> {},
				Description -> "Any peak whose range contains a point in Include will be included in the returned peaks. If a peak contains points from both Include and Exclude, it will be excluded.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Adder[Widget[Type -> Number, Pattern :> RangeP[-Infinity, Infinity]]],
					Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				]
			},
			{
				OptionName -> Exclude,
				Default -> {},
				Description -> "Any peak whose range contains a point in Exclude will be excluded from the returned peaks. If a peak contains points from both Include and Exclude, it will be excluded.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Alternatives[
					Adder[Widget[Type -> Number, Pattern :> RangeP[-Infinity, Infinity]]],
					Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				]
			},
			{
				OptionName -> Baseline,
				Default -> DomainConstant,
				Description -> "Method to use for computing peak baselines. The baseline affects a peak's height and area. The baseline is fit to the points inside of the domain that are not part of any peak.",
				AllowNull -> False,
				Category -> "Method",
				Widget -> Widget[Type -> Enumeration, Pattern :> LocalConstant | LocalLinear | DomainConstant | DomainLinear | DomainNonlinear | EndpointLinear | GlobalConstant | GlobalLinear | GlobalNonlinear]
			},
			{
				OptionName -> BaselineFeatureWidth,
				Default -> Automatic,
				Description -> "A parameter for method Baseline->DomainNonlinear that sets the width of variations in the data above which it is followed by the fitted baseline function.  See section 'Options/BaselineFeatureWidth' for examples below.  Internally, the method 'DomainNonlinear' uses the Mathematica function, EstimatedBackground[data, sigma], in which the BaselineFeatureWidth value determines 'sigma'.",
				AllowNull -> True,
				Category -> "Method",
				Widget -> Widget[Type -> Number,Pattern :> GreaterEqualP[0]]
			},
			{
				OptionName -> BlankPeaks,
				Default -> Automatic,
				Description -> "Any peak whose range overlaps with a peak in BlankPeaks will be excluded from returned peaks. When input is associated with a protocol with blank data, blank peaks will be automatically retrieved.",
				AllowNull -> True,
				Category -> "Method",
				Widget -> Widget[Type -> Object, Pattern :> ObjectP[Object[Analysis, Peaks]]]
			},
			{
				OptionName -> HighlightBaselinePoints,
				Default -> False,
				Description -> "If true, show points used to calculate the peaks baseline.",
				AllowNull -> True,
				Category -> "Method",
				Widget -> Widget[Type->Enumeration,Pattern:>BooleanP]
			},
      {
				OptionName -> ManualPeakRanges,
        Default -> Null,
        Description -> "A list of ranges (left boundary and right boundary) defining manually selected peaks.",
        ResolutionDescription -> "If PeakType is Manual, defaults to an empty list {}, and Null otherwise.",
        AllowNull -> True,
        Category -> "Manual Peak Specification",
        Widget -> Alternatives[
					Adder[
						Span[
							Widget[Type->Number, Pattern:>RangeP[-\[Infinity],\[Infinity]]],
							Widget[Type->Number, Pattern:>RangeP[-\[Infinity],\[Infinity]]]
						]
					],
					Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				]
      },
      {
				OptionName -> ManualPeakPositions,
        Default -> Null,
        Description -> "For each range in ManualPeakRanges, the position of the peak within that range.",
        ResolutionDescription -> "Defaults to the position of the maximal value in the input data for each range if PeakType is Manual, and Null otherwise.",
        AllowNull -> True,
        Category -> "Manual Peak Specification",
        Widget -> Alternatives[
					Adder[Widget[Type->Number, Pattern:>RangeP[-\[Infinity],\[Infinity]]]],
					Widget[Type->Enumeration,Pattern:>Alternatives[{}]]
				]
      },
			{
				OptionName -> SkipTangentFieldCalculation,
				Default -> True,
				Description -> "If True, disable computation of tangent fields to improve performance.",
				AllowNull -> True,
				Category -> "Hidden",
				Widget -> Widget[Type -> Enumeration, Pattern:>Alternatives[True|False]]
			},
			IndexMatchingInput -> "Input Data"
		],
		AnalysisPreviewSymbolOption,
		AnalysisTemplateOption,
		OutputOption,
		UploadOption
	}
];

(* ::Subsubsection::Closed:: *)


(* ---------------------------- *)
(* --- MESSAGES AND ERRORS  --- *)
(* ---------------------------- *)
Error::DataFormat="The DownsampledDataFile in linked downsampling object `1` did not resolve to a SparseArray. Please re-run AnalyzeDownsampling on input object `2`.";
Error::DomainInvalidForManual="The Domain option cannot be set when Peak type is Manual. Please remove manual peak options, or clear the domain option in your function call.";
Error::DownsampledDataNotFound="Input object `1` has no linked downsampled data in field DownsamplingAnalyses. Please run AnalyzeDownsampling on `1`. Downsampled data is required for plotting.";
Error::DownsampledDataNotReady="Input object `2` was created recently and data is still being downsampled by the ECL. Please check back at `1`, or run AnalyzeDownsampling on input object `2` locally. Plotting cannot continue until data has been downsampled.";
Error::IncompatibleUnits = "Units `1` in `2` are incompatible with units `3` in `4`. Please specify compatible units, or provide a dimensionless number to default to units of `3`.";
Error::InvalidManualOptionLengths = "The length of option ManualPeakRanges (`1`) does not match the length of ManualPeakPositions (`2`). Please make sure these options are index-matched and have the same length.";
Error::InvalidManualPositions = "The position values `1` in ManualPeakPositions are outside of their corresponding peak ranges `2` in ManualPeakRanges. Please make sure that each manually specified position falls within its corresponding peak range.";
Error::InvalidManualRanges = "Option value `1` for ManualPeakRanges contains overlapping spans. Please ensure that none of the ranges in this option specification overlap.";
Error::InvalidMultiplicity = "The provided value `1` for option PeakGroupMultiplicity is invalid. Please verify that individual labels are correctly formatted, and that multiple splittings consist only of integers greater than one.";
Error::InvalidNamedDimension="DataSliceDimension `1` cannot be used with ReferenceField `2`. For `2`, named dimensions must be one of `3`.";
Error::InvalidSliceDimension="Slicing dimensions `1` of input data with dimension `2` will not result in 2-dimensional {x,y} data. Please specify exactly `3` unique dimension(s) to slice.";
Error::InvalidSliceLength="Option DataSlice `1` has length `2`, which does not match the length of DataSliceDimensions. Please supply a list with length `3`.";
Error::InvalidSplittingDomains = "The provided value `1` for option PeakGroupDomains is invalid. Please check that each span is increasing, and that none of the spans overlap.";
Error::InvalidTransformation = "The resolved DataSetTransformationFunction `1` results in transformed data which does not match CoordinatesP. Please ensure that the DataSetTransformationFunction is correct.";
Error::MixedAssignment = "Absolute and relative peak assignments cannot be used simultaneously. Please ensure that either all assignments are relative (units of RRT), or that all assignments are absolute (no RRT units).";
Error::NucleusMismatch = "The atoms specified in option SplittingAssignments do not match the resolved Nucleus `1`. Please verify that all molecular indices in SplittingAssignments correspond to the nucleus `1`.";
Error::ParameterNotFound = "No value found for option `1`. Please check that field `2` exists in `3`, or that the supplied value for option `1` is valid.";
Error::SliceDimensionOutOfBounds="Cannot slice dimensions `1` from input data with dimension `2`. Please ensure dimensions are between 1 and `3`, or use named dimensions.";
Error::UnrecognizedWavelength = "Unable to find data that matches the given Wavelength. Please check the wavelength range in input object, and select a new value for the Wavelength option.";
Error::DataNotFound = "Unable to find any data from the `1` field in the object, `2`.";
Warning::AutomaticWavelength = "AnalyzePeaks is automatically resolving the wavelength to `1`. If this is undesired, please call: AnalyzePeaks[`1`, Wavelength->differentValue] to select a better data slice to pick peaks on.";
Warning::AutomaticAssignmentNotAvailable = "Automatic assignment of NMR peaks to molecular structure is not available for nucleus type `1`. Peaks must be annotated manually using option SplittingAssignments.";
Warning::AreaToleranceExceeded = "SplittingRelativeIntegralTolerance exceeded while assigning multiplicity `1` to peaks at `2` (relative areas: `3`). Please verify that the multiplicity assignment is correct, or increase SplittingRelativeIntegralTolerance.";
Warning::EmptySplittingDomain = "The provided domain(s) `1` contain no peaks. Please verify that the PeakGroupDomains option is correct, or adjust peak-picking options to ensure all peaks have been identified.";
Warning::ConflictingPeakAssignments = "The PeakAssignments to the maximal-area peak in ranges `1` result in assignment to the same peak. The last PeakAssignment for these ranges will be used. Please modify the peak ranges so that only one assignment is made to each peak.";
Warning::DuplicateAssignment = "Multiple assignments in option SplittingAssignments were matched to the same domain(s) `1`. Only the first assignment in this range will be used.";
Warning::ExcludeOverwriteInclude = "Exclude contains point also in Include. Any peak whose range contains this point will be excluded from the returned peaks.";
Warning::IncompatibleSliceUnits="Incompatible units `1` provided in DataSlice option; expected units compatible with `2` for dimension `3`. Units will be ignored.";
Warning::MismatchedPeakCounts = "Multiplicities `1` at indices `2` in option PeakGroupMultiplicity are inconsistent with the number of peaks in the corresponding splitting groups `3`. J-coupling constants will not be calculated for these groups.";
Warning::MolecularAssignment = "Unable to automatically assign peaks to any of the nuclei in KnownSpecies `1`. Please ensure peaks have been correctly labeled, or manually provide assignments using option SplittingAssignments.";
Warning::PeakGroupMultiplicityMismatch = "The number of peak multiplicities (`1`) does not match the resolved number of peak groups (`2`). Excess multiplicities will be ignored, and missing specifications will be defaulted.";
Warning::OptionUnavailable = "Option `1` cannot be used with resolved PeakType `2`, and will be ignored in analysis.";
Warning::ParameterMismatch = "Supplied value `1` for option `2` does not match value `3` found in input `4`. Please verify that `1` is correct, or use Automatic to default to input value.";
Warning::ParentPeakIndices = "Indices `1` in option ParentPeaks are outside of the range 1 to `2`, the number of identified peaks, and will be defaulted to the largest peak (index `3`).";
Warning::ParentPeaksMismatch = "Parent peaks contain labels `1` which do not correspond to any labels or assignments. Please ensure that all entries in parent peaks have a corresponding label or assignment.";
Warning::ParentPeaksPadded = "`1` parent peaks were specified, but `2` peaks were identified. Extra parents will be ignored, and unspecified parents will default to the largest peak.";
Warning::PeakLabelsMismatch = "Number of Peak labels does not match number of peaks. Excess labels will be ignored.";
Warning::ReverseComplexCoupling = "Automatic calculation of J-coupling constants is not supported for complex multiple splittings. `1` peaks were expected for the specified multiplicity `2`, but only `3` were identified in the splitting group.";
Warning::SpacingToleranceExceeded = "SplittingSpacingTolerance exceeded while assigning multiplicity `1` to peaks at `2`. Please verify that the multiplicity assignment is correct, or increase SplittingSpacingTolerance.";
Warning::SplittingIgnoreUnits = "Input data was provided with x-units of `1` instead of PPM. Units will be ignored in peak-splitting analysis.";
Warning::UnmatchedAssignment = "The assignment(s) `1` in option SplittingAssignments could not be matched to any resolved peak splitting domains, and will be ignored.";
Warning::UnrecognizedPeaksField = "Unable to interpret given ReferenceField. Please check the ReferenceField is correct for the input data type.";
Warning::WavelengthMismatch = "Wavelength option does not match the wavelengh of ReferenceField Chromatogram, default to `1`.";
Warning::DeprecatedBaseline = "The baseline option, `1`, will soon be deprecated, please replace the option with `2`.";
Warning::DeprecatedDataSlicePattern = "DataSlice option `1` is in a deprecated pattern. Please replace the list with span in the future.";

(* ---------------------------- *)
(* --- PATTERN DEFINITIONS  --- *)
(* ---------------------------- *)

(* List of Object[Data, _] types which can be analyzed for peaks *)
peakDataTypes={
	Object[Data,AbsorbanceSpectroscopy],
	Object[Data,AgaroseGelElectrophoresis],
	Object[Data,CapillaryGelElectrophoresisSDS],
	Object[Data,Chromatography],
	Object[Data,ChromatographyMassSpectra],
	Object[Data,DifferentialScanningCalorimetry],
	Object[Data,FluorescenceSpectroscopy],
	Object[Data,IRSpectroscopy],
	Object[Data,LuminescenceSpectroscopy],
	Object[Data,MassSpectrometry],
	Object[Data,MeltingCurve],
	Object[Data,NMR],
	Object[Data,PAGE],
	Object[Data,TLC],
	Object[Data,Western],
	Object[Data,XRayDiffraction],
	Object[Data,CircularDichroism],
	Object[Data,DynamicLightScattering],
	Object[Data,CoulterCount],
	Object[Data,CapillaryIsoelectricFocusing],
	Object[Data,FragmentAnalysis]
};

(* List of Object[Protocol, _] types which can be analyzed for peaks *)
peakProtocolTypes={
	Object[Protocol,AbsorbanceSpectroscopy],
	Object[Protocol,AgaroseGelElectrophoresis],
	Object[Protocol,CapillaryGelElectrophoresisSDS],
	Object[Protocol,DifferentialScanningCalorimetry],
	Object[Protocol,FlashChromatography],
	Object[Protocol,FluorescenceSpectroscopy],
	Object[Protocol,FPLC],
	Object[Protocol,HPLC],
	Object[Protocol,IRSpectroscopy],
	Object[Protocol,LCMS],
	Object[Protocol,LuminescenceSpectroscopy],
	Object[Protocol,MassSpectrometry],
	Object[Protocol,NMR],
	Object[Protocol,PAGE],
	Object[Protocol,PowderXRD],
	Object[Protocol,SupercriticalFluidChromatography],
	Object[Protocol,Western],
	Object[Protocol,CircularDichroism],
	Object[Protocol,DynamicLightScattering],
	Object[Protocol,CoulterCount],
	Object[Protocol,CapillaryIsoelectricFocusing],
	Object[Protocol,FragmentAnalysis]
};

(* Raw (non-object) data types which can be analyzed for peaks *)
peakRawDataTypes=Alternatives[
	CoordinatesP,
	QuantityCoordinatesP[],
	QuantityMatrixP[{Second,Meter,AbsorbanceUnit}], (* 3D Chromatogram *)
	_Image
];

(* Pattern for a single AnalyzePeaks input *)
inputAnalyzePeaksP=Alternatives[
	ObjectP[peakDataTypes],
	peakRawDataTypes
];

(* Pattern for a list of AnalyzePeaks inputs *)
listInputAnalyzePeaksP=Alternatives[
	ObjectP[peakProtocolTypes],
	{inputAnalyzePeaksP..}
];

(* A list of rules mapping  multiplet labels to lists-of-integers *)
multiplicityStringToIntegerRules={
	"Multiplet (m)" -> {"m"},
	"Singlet (s)" -> {1},
	"Doublet (d)" -> {2},
	"Triplet (t)" -> {3},
	"Quartet (q)" -> {4},
	"Quintet (quint)" -> {5},
	"Sextet (sx)" -> {6},
	"Heptet (hep)" -> {7},
	"Octet (oct)" -> {8},
	"Nonet (non)" -> {9},
	"Dectet (dec)" -> {10},
	"Doublet of doublets (dd)" -> {2,2},
	"Doublet of triplets (dt)" -> {2,3},
	"Doublet of quartets (dq)" -> {2,4},
	"Triplet of doublets (td)" -> {3,2},
	"Triplet of triplets (tt)" -> {3,3},
	"Triplet of quartets (tq)" -> {3,4},
	"Quartet of doublets (qd)" -> {4,2},
	"Quartet of triplets (qt)" -> {4,3},
	"Quartet of quartets (qq)" -> {4,4}
};

(* Valid Strings for specifying multiplicity *)
multiplicityStringP=Alternatives@@(First/@multiplicityStringToIntegerRules);

(* A mapping of supported solvent models for NMR *)
solventModelsForNMR={
	Model[Molecule, "id:BYDOjvG676VD"]->"Chloroform",
	Model[Molecule, "id:qdkmxzqabaVY"]->"DMSO",
	Model[Molecule, "id:n0k9mG8PJb4p"]->"Benzene",
	Model[Molecule, "id:01G6nvwRW8o4"]->"Acetone",
	Model[Molecule, "id:1ZA60vL5WKN6"]->"Acetonitrile",
	Model[Molecule, "id:Z1lqpMzR4Ldo"]->"Methanol",
	Model[Molecule, "id:54n6evLm7NzB"]->"Water"
};

(* A lookup table defining which types/fields use Downsampling *)
downsampledDataLookup={
	Object[Data, ChromatographyMassSpectra]->{IonAbundance3D}
};

(* For each sliceable field, a mapping of names to dimensions *)
sliceableFieldDimensionLookup={
	IonAbundance3D->{ElutionTime->1,MassToChargeRatio->2}
};

(* For each sliceable field, a mapping of names to units *)
sliceableFieldUnitLookup=sliceableFieldDimensionLookup/.{
	ElutionTime->Minute,
	MassToChargeRatio->Dalton
};

(* Fields which contain 3+D data for which slicing is supported *)
sliceableDataFieldP=Alternatives@@(First/@sliceableFieldDimensionLookup);

(* Mapping of units to plot types in reference peak preview plots *)
referencePlotTypeRules={
	{Dalton, AbsorbanceUnit|ArbitraryUnit}->"Mass Spectrum",
	{Second|Minute, AbsorbanceUnit|ArbitraryUnit|Lumen}->"Chromatogram",
	{PPM, ArbitraryUnit}->"NMR Spectrum",
	{Meter, AbsorbanceUnit|ArbitraryUnit|Lumen}->"Spectrum"
};


(* -------------------------- *)
(* --- PROTOCOL OVERLOAD  --- *)
(* -------------------------- *)
AnalyzePeaks[in:ObjectP[peakProtocolTypes],ops:OptionsPattern[AnalyzePeaks]]:=Module[
	{listedInputs},

	(* Protocol input resolution returns a list of peaks data objects taken from the protocol *)
	listedInputs=resolveAnalyzePeaksListInput[in];

	(* Conduct peak-picking analysis on each input data object *)
	AnalyzePeaks[listedInputs, ops]
];


(* -------------------------- *)
(* --- MAIN FUNCTION BODY --- *)
(* -------------------------- *)
AnalyzePeaks[in:ListableP[inputAnalyzePeaksP],ops:OptionsPattern[AnalyzePeaks]]:=Module[
	{
		listedData,objListedData,listedOptions,rulesRequiringUnnecessaryList,analysisPacketStart,outputSpecification,output,gatherTests,
		safeOptions,safeOptionTests,rawTemplateOptions,templateTests,templateOptions,combinedOptions,
		resolvedInputsResult,validLengths,validLengthTests,
		refField,xyUnits,rawData,wavelength,slicingOps,image,inputWLTests,samples,
		mostlyResolvedOptionsResult,mostlyResolvedOptions,mostlyResolvedOptionsTests,templateAlignmentRules,
		rawDataExpanded,listedDataExpanded,samplesExpanded,imagesExpanded,xyUnitsExpanded,
		findPeaksResult,peakFieldList,baselineFunctionList,
		resolvedOptions,resolvedOptionsTests, baselineRangesList,
		peakPackets,previewRule,optionsRule,testsRule,resultRule, opsIn
	},

	(* Ensure that inputs are in a list. If "in" is a singular list-like input, such as CoordinatesP, manually wrap it in a list. *)
	listedData=If[MatchQ[in,peakRawDataTypes],
		{in},
		ToList[in]
	];

	(* Replace list-like raw inputs with dummy objects, because list-like inputs will cause ValidInputLengthsQ and ApplyTemplateOptions to error *)
	objListedData=Replace[listedData,peakRawDataTypes->Object[Data,Chromatography,""],1];

	(* Ensure that options are in a list *)
	opsIn=ToList[ops];

	(* Gentle warning if DataSlice is in deprecated form *)
	listedOptions=If[MatchQ[Lookup[opsIn,DataSlice],{{_,_}..}],
		Message[Warning::DeprecatedDataSlicePattern,Lookup[opsIn,DataSlice]];
		(* Automatically convert it into span *)
		opsIn/.Lookup[opsIn,DataSlice]:>(Lookup[opsIn,DataSlice]/.{{a_,b_}}:>a;;b),
		opsIn
	];

	(*
		As part of removing unnecessarily listedness, we now restore the missing outer List that
		the internals of AnalyzePeaks is expecting for these options.
	*)
	(*  1. These user-supplied options require an outer pair of { } for internals of Analyze Peaks to work *)
	rulesRequiringUnnecessaryList=FilterRules[listedOptions,
		{
			DataSliceDimension, DataSlice, SliceReductionFunction, Domain,
			AbsoluteThreshold, RelativeThreshold, WidthThreshold, AreaThreshold,
			EdgeFraction, SmoothingRadius, ConsolidateWidth, ConsolidateHeight
		}
	];
	(*  2.
		MapAt: Apply ECL`ToList to each OptionValue supplied (restoring the outer '{ }' if needed)
		Join, DeleteDuplicatesBy:  Then merge them in with the remaining user-supplied options
	*)
	listedOptions=DeleteDuplicatesBy[
		Join[
			If[rulesRequiringUnnecessaryList=!={}
				,MapAt[ToList,rulesRequiringUnnecessaryList,{All,2}]
				,{}]
			,listedOptions]
		,First];

	(* Create an analysis packet with Author, DateCreated, and UnresolvedOptions populated *)
	analysisPacketStart=analysisPacketStandardFieldsStart[listedOptions];

	(* Throw a warning message if the inputs or options contain any temporal links *)
	checkTemporalLinks[listedData,listedOptions];

	(* Determine the requested return value from the function *)
	outputSpecification=OptionValue[Output];
	output=ToList[OptionValue[Output]];

	(* Determine if we should keep a running list of tests *)
	gatherTests=MemberQ[output,Tests];

	(* Call SafeOptions to make sure all options match pattern *)
	{safeOptions,safeOptionTests}=If[gatherTests,
		SafeOptions[AnalyzePeaks,listedOptions,AutoCorrect->False,Output->{Result,Tests}],
		{SafeOptions[AnalyzePeaks,listedOptions,AutoCorrect->False],Null}
	];

	(* If the specified options don't match their patterns return $Failed *)
	If[MatchQ[safeOptions,$Failed],
		Return[outputSpecification/.{
			Result->$Failed,
			Tests->safeOptionTests,
			Options->$Failed,
			Preview->Null
		}]
	];

	(* Use any template options to get values for options not specified in myOptions *)
	{rawTemplateOptions,templateTests}=If[gatherTests,
		ApplyTemplateOptions[AnalyzePeaks,{objListedData},listedOptions,Output->{Result,Tests}],
		{ApplyTemplateOptions[AnalyzePeaks,{objListedData},listedOptions],Null}
	];

	(* Replace template PeakLabels option with user-supplied PeakLabels option, because we don't want to copy the template directly *)
	templateOptions=ReplaceRule[rawTemplateOptions,ExtractRule[safeOptions,PeakLabels]];

	(* Combine safe options with templated options, preserving the original PeakLabels options *)
	combinedOptions=ReplaceRule[safeOptions,templateOptions];

	(* Resolve inputs, storing reference field, physical units, raw xy data, and other fields *)
	resolvedInputsResult=Check[
		{refField,xyUnits,rawData,samples,wavelength,slicingOps,image,inputWLTests}=resolveAnalyzePeaksInputs[listedData,combinedOptions,gatherTests],
		$Failed,
		{Error::InvalidInput,Error::InvalidOption}
	];

	(* Hard fail if the inputs could not be resolved *)
	If[MatchQ[resolvedInputsResult,$Failed],
		Return[outputSpecification/.{
			Result->$Failed,
			Tests->Join[safeOptionTests,inputWLTests],
			Options->combinedOptions,
			Preview->Null
		}]
	];

	(* Ensure all options are the correct length. Silence missing option errors. *)
	{validLengths,validLengthTests}=Quiet[
		If[gatherTests,
			ValidInputLengthsQ[AnalyzePeaks,{objListedData},DeleteCases[listedOptions,DataSlice->_],Output->{Result,Tests}],
			{ValidInputLengthsQ[AnalyzePeaks,{objListedData},DeleteCases[listedOptions,DataSlice->_]],Null}
		],
		Warning::IndexMatchingOptionMissing
	];

	(* If option lengths are invalid, return $Failed *)
	If[!validLengths,
		Return[outputSpecification/.{
			Result -> $Failed,
			Tests -> Join[safeOptionTests,validLengthTests],
			Options -> $Failed,
			Preview -> Null
		}]
	];

	(* Resolve all options which do not require identification of peaks, checking for invalid inputs and options *)
	mostlyResolvedOptionsResult=Check[
		{mostlyResolvedOptions,mostlyResolvedOptionsTests}=If[gatherTests,
			resolveAnalyzePeaksOptions[rawData,listedData,xyUnits,refField,wavelength,slicingOps,combinedOptions,safeOptions,Output->{Result,Tests}],
			{resolveAnalyzePeaksOptions[rawData,listedData,xyUnits,refField,wavelength,slicingOps,combinedOptions,safeOptions],Null}
		],
		$Failed,
		{Error::InvalidInput,Error::InvalidOption}
	];

	(* If the specified options don't match their patterns or if option lengths are invalid return $Failed *)
	If[MatchQ[mostlyResolvedOptionsResult,$Failed],
		Return[outputSpecification/.{
			Result->$Failed,
			Tests->Join[safeOptionTests,validLengthTests,mostlyResolvedOptionsTests],
			Options->combinedOptions,
			Preview->Null
		}]
	];

	(* Resolve template alignment rules, which determine how peaks identified in Template (if-provided) should be aligned to peaks in this analysis *)
	templateAlignmentRules=getPeakLabelsList[mostlyResolvedOptions];

	(* Expand fields to account for multiple reference fields for a single object *)
	{rawDataExpanded,listedDataExpanded,samplesExpanded,imagesExpanded,xyUnitsExpanded}=Transpose@MapThread[
		If[MatchQ[#1,{CoordinatesP..}],
			Sequence@@Transpose[{#1,Repeat[#2,Length[#1]],#3,Repeat[#4,Length[#1]],#5}],
			{#1,#2,#3,#4,#5}
		]&,
		{rawData,listedData,samples,image,xyUnits}
	];

	(* Compute peak fields (position, height, area, etc.) and baseline functions for each input *)
	findPeaksResult=Check[
		{peakFieldList,baselineFunctionList, baselineRangesList}=Transpose@MapThread[
			findPeaks[#1,#2,#3]&,
			{rawDataExpanded,templateAlignmentRules,mostlyResolvedOptions}
		],
		$Failed,
		{Error::InvalidInput,Error::InvalidOption}
	];

	(* Resolve the options which depend on peaks identified by findPeaks *)
	{resolvedOptions,resolvedOptionsTests}=Transpose@MapThread[
		resolveRemainingOptionsSingle[#1,#2,#3,combinedOptions]&,
		{mostlyResolvedOptions,peakFieldList,baselineFunctionList}
	];

	(* Construct peaks packets from the computed peak fields and options *)
	peakPackets=If[MatchQ[mostlyResolvedOptionsResult,$Failed]||MatchQ[findPeaksResult,$Failed],
		$Failed,
		MapThread[
			formatPeakPacket[#1,#2,#3,analysisPacketStart,#4,#5,#6]&,
			{listedDataExpanded,peakFieldList,baselineFunctionList,resolvedOptions,samplesExpanded,Range[Length[listedDataExpanded]]}
		]
	];

	(* Prepare the Preview result if we were asked to do so *)
	previewRule=Preview->If[MemberQ[output,Preview]&&!MatchQ[peakPackets,$Failed],
		Module[{baseGraphic},
			With[
				{
					previews=MapThread[analyzePeaksPreview[#1,#2,#3,#4,#5,#6,#7, #8]&,
						{rawDataExpanded,imagesExpanded,xyUnitsExpanded,resolvedOptions,listedDataExpanded,templateAlignmentRules,peakPackets, Transpose[findPeaksResult]}
					],

					slices=Lookup[stripAppendReplaceKeyHeads[peakPackets],ReferenceDataSlice,Null]
				},

				(* Generate the final preview graphic *)
				baseGraphic=formatPreviewGraphic[rawDataExpanded,xyUnitsExpanded,previews,slices,resolvedOptions];



				If[(*Adding interactive elements under the following conditions:*)

					(*AnalyzePeaksPreview call does not come from PlotPeaks*)
					Not[Plot`Private`$fromPlotPeaks] &&
					(*The input type is not Object[Data,NMR] -- these peaks are handled very different from
					   other types of peaks*)
					FreeQ[Lookup[resolvedOptions,PeakType],NMR] &&
					(*The AnalyzePeaksPreview call comes from CommandBuilder*)
					SameQ[$ECLApplication,CommandCenter],


					Catch[
						addPeaksInteractiveElements[
							baseGraphic,
							stripAppendReplaceKeyHeads[peakPackets],
							resolvedOptions
						],
						"LabelPeaks",
						baseGraphic&
					],
					baseGraphic
				]
			]
		],
		Null
	];

	(* Prepare the Options result if we were asked to do so *)
	optionsRule=Options->If[MemberQ[output,Options],
		RemoveHiddenOptions[AnalyzePeaks,
			Map[
				(* Use ToExpression to convert strings into symbols *)
				collapsePeaksOption[ToExpression[#],ToExpression[#]/.resolvedOptions]&,
				(* List of all options, as strings, without their values *)
				First/@Options[AnalyzePeaks]
			]
		],
		Null
	];

	(* Prepare the Tests result if we were asked to do so *)
	testsRule=Tests->If[MemberQ[output,Tests],
		Join[
			safeOptionTests,
			templateTests,
			mostlyResolvedOptionsTests,
			Flatten[resolvedOptionsTests],
			Flatten[validLengthTests],
			Flatten[inputWLTests]
		],
		Null
	];

	(* Prepare standard output if we were asked to do so *)
	resultRule=Result->Which[
		(* If Result was not requested in Output option, set Result->Null *)
		Not[MemberQ[output,Result]],
		Null,

		(* Result was requested but peak-picking analysis failed *)
		MatchQ[mostlyResolvedOptionsResult,$Failed]||MatchQ[findPeaksResult,$Failed],
		$Failed,

		(* Format the output based on options *)
		MemberQ[output,Result],
		With[
			(* Check the Upload option for each input to determine if it should be uploaded *)
			{
				output=MapThread[analyzePeaksResult[#1,#2,#3,#4,#5]&,
					{
						PadRight[listedData,Length[peakPackets]],
						PadRight[rawData,Length[peakPackets]],
						PadRight[xyUnits,Length[peakPackets]],
						peakPackets,
						resolvedOptions
					}
				]
			},

			(* If a single dataset was provided, de-list the output *)
			If[MatchQ[in,inputAnalyzePeaksP]&&Length[output]==1,First[output],output]
		]
	];

	(* Return the specified outputs *)
	outputSpecification/.{previewRule,optionsRule,testsRule,resultRule}
];




(* ::Subsection::Closed:: *)
(*AnalyzePeaksOptions*)


DefineOptions[AnalyzePeaksOptions,
	SharedOptions :> {AnalyzePeaks},
	{
		OptionName -> OutputFormat,
		Default -> Table,
		AllowNull -> False,
		Widget -> Widget[Type->Enumeration, Pattern:>Alternatives[Table, List]],
		Description -> "Determines whether the function returns a table or a list of the options."
	}
];


AnalyzePeaksOptions[in: ObjectP[peakProtocolTypes], ops: OptionsPattern[AnalyzePeaksOptions]] := Module[
	{inList},
	inList = resolveAnalyzePeaksListInput[in];
	AnalyzePeaksOptions[inList, ops]
];


AnalyzePeaksOptions[in: ListableP[inputAnalyzePeaksP], ops: OptionsPattern[AnalyzePeaksOptions]] := Module[
	{listedOptions, noOutputOptions, options},

	listedOptions = ToList[ops];

	(* remove the OutputFormat option before passing to the core function because it doesn't make sense here *)
	noOutputOptions = DeleteCases[listedOptions, Rule[OutputFormat,_]];

	(* return options from main function body *)
	options=AnalyzePeaks[in,ReplaceRule[noOutputOptions,{Output->Options}]];

	(* Return the option as a list or table *)
	If[MatchQ[Lookup[listedOptions,OutputFormat,Table],Table] && !MatchQ[options, ListableP[$Failed]],
		LegacySLL`Private`optionsToTable[options,AnalyzePeaks],
		options
	]
];


(* ::Subsection:: *)
(*AnalyzePeaksPreview*)


DefineOptions[AnalyzePeaksPreview,
	SharedOptions :> {AnalyzePeaks}
];


AnalyzePeaksPreview[in: ObjectP[peakProtocolTypes], ops: OptionsPattern[AnalyzePeaksPreview]] := Module[
	{inList},
	inList = resolveAnalyzePeaksListInput[in];
	AnalyzePeaksPreview[inList, ops]
];


AnalyzePeaksPreview[in: ListableP[inputAnalyzePeaksP], ops: OptionsPattern[AnalyzePeaksPreview]] :=
	AnalyzePeaks[in, ReplaceRule[ToList[ops],{Output->Preview}]];


(* ::Subsection::Closed:: *)
(*ValidAnalyzePeaksQ*)


DefineOptions[ValidAnalyzePeaksQ,
	Options:>{
		VerboseOption,
		OutputFormatOption
	},
	SharedOptions :> {AnalyzePeaks}
];


ValidAnalyzePeaksQ[in: ObjectP[peakProtocolTypes], ops: OptionsPattern[ValidAnalyzePeaksQ]] := Module[
	{inList},
	inList = resolveAnalyzePeaksListInput[in];
	ValidAnalyzePeaksQ[inList, ops]
];


ValidAnalyzePeaksQ[in: ListableP[inputAnalyzePeaksP], ops: OptionsPattern[ValidAnalyzePeaksQ]] := Module[
	{preparedOptions,functionTests,initialTestDescription,allTests, verbose, outputFormat},

	(* Remove the Verbose option and add Output->Tests to get the options ready for <Function> *)
	preparedOptions=Normal@KeyDrop[Append[ToList[ops],Output->Tests],{Verbose,OutputFormat}];

	(* Call the function to get a list of tests *)
	functionTests=AnalyzePeaks[in,preparedOptions];

	initialTestDescription="All provided options and inputs match their provided patterns (no further testing can proceed if this test fails):";

	allTests=If[MatchQ[functionTests,$Failed],
		{Test[initialTestDescription,False,True]},
		Module[{initialTest,validObjectBooleans,voqWarnings,testResults},
			initialTest=Test[initialTestDescription,True,True];

			(* Create warnings for invalid objects *)
			If[MatchQ[in, ListableP[ObjectP[]]],
				validObjectBooleans=ECL`ValidObjectQ[ToList[in],OutputFormat->Boolean];
				voqWarnings=MapThread[
					Warning[ToString[#1,InputForm]<>" is valid (run ValidObjectQ for more detailed information):",
						#2,
						True
					]&,
					{ToList[in],validObjectBooleans}
				],
				voqWarnings = {}
			];

			(* Get all the tests/warnings *)
			Join[functionTests,voqWarnings]
		]
	];

	(* determine the Verbose and OutputFormat options; quiet the OptionValue::nodef message in case someone just passed nonsense *)
	{verbose, outputFormat} = OptionDefault[OptionValue[ValidAnalyzePeaksQ, {ops}, {Verbose, OutputFormat}]];

	(* Run all the tests as requested *)
	Lookup[RunUnitTest[<|"ValidAnalyzePeaksQ" -> allTests|>, OutputFormat -> outputFormat, Verbose -> verbose], "ValidAnalyzePeaksQ"]
];


(* ::Subsection:: *)
(*analyzePeaksPreview*)


analyzePeaksPreview[xy0_,img_,units_,ops_,dataTag_,template_,finalPeakPacket:$Failed, findPeaksResult_]=Null;

analyzePeaksPreview[xyIn_, image_, units_, resolvedOps_, dataTag_, templateRules_, finalPeakPacket_, findPeaksResult_] := Module[
	{
		xy, xmin, xmax, ymin, ymax, maxPeakHeight, excludeOp, pkTypeOp, rescaleNMRcheck,
		plotRange, dataType, refField, extraplotopts,
		domainVar, absVar, relVar, globalConsolVar, widthConsolVar, spanVar, numZones,
		pksPacket, pks, resolutionMatrix, peakSplitDomainEpilogs,
		widthbars, peakEpilogPrimitives, smoothedplotPrimitive, controlsplotPrimitive, colorsList, epilog, baselinePrimitive, drawLine, peakRangeEpilogs,
		fig, epilogs, baselineFunction, xyTransformed, pksPacketEpilog, baselineRanges, height, showBaseline
	},

	(* Determine the data type and what field was plotted *)
	dataType = If[MatchQ[dataTag,ObjectP[]],dataTag[Type],Null];
	refField = Lookup[resolvedOps, ReferenceField]/.{
		lst_List:>First[lst]
	};

	(* get transformed xy0 for plot values if we will use a loglinear plot *)
	xyTransformed = If[MatchQ[dataType,Object[Data,AgaroseGelElectrophoresis]],
		(* Log the first values for epilogs in log linear plot *)
		{Log10[First[#]], Last[#]} & /@ xyIn,
		(* otherwise retain the same value *)
        	xyIn
	];

	(* Process transformed data to get plot bounds *)
	xy = ToPackedArray[xyTransformed];

	(* Get the bounding box which contains all raw data  *)
	{{xmin, xmax}, {ymin, ymax}} = CoordinateBounds[xy];
    
	(* pull info out of findPeaksResult *)
	{pksPacket, baselineFunction, baselineRanges} = findPeaksResult;

	(* clean up finalPeakPacket, and pull out core packets *)
	pks = getPeaksCoreFields[pksPacket];

	(* pull fields from peaks packet *)
	height = Lookup[pksPacket, Height];

	(* Get the height of the tallest peak *)
	maxPeakHeight=Max[height];
    
	(* Identify the number of domains used in peaks analysis, and get variables for each domain from peaks analysis. *)
	{
		excludeOp,
		pkTypeOp,
		domainVar,
		absVar,
		relVar,
		globalConsolVar,
		widthConsolVar,
		spanVar
	} = Lookup[resolvedOps,
		{
		    Exclude,
		    PeakType,
		    Domain,
		    AbsoluteThreshold,
		    RelativeThreshold,
		    ConsolidateHeight,
		    ConsolidateWidth,
		    SmoothingRadius
		}
	];

	(* In NMR, we may want to exclude tall peaks (extraneous solvent signal), so it is nice to adjust the y-axis. *)
	rescaleNMRcheck=And[
		(* only True if NMR analysis is being done *)
		MatchQ[pkTypeOp,NMR],
		(* True if either domain or Exclude has been altered by the user *)
		Or[
			MatchQ[excludeOp,Except[{}]],
			MatchQ[domainVar,Except[{{xmin,xmax}}]]
		]
	];

	(* Plot range shows all data, with extra tolerance at the top for aesthetic purposes *)
	plotRange=If[rescaleNMRcheck,
		(* In NMR peak-splitting analysis, if Exclude is set, rescale y-axes to exclude large peaks *)
		{{xmin, xmax}, {ymin, maxPeakHeight + (maxPeakHeight - ymin) * 0.06}},
		(* Default: plot range shows all data with extra space on top border *)
		{{xmin, xmax}, {ymin, ymax + (ymax - ymin) * 0.06}}
	];

	(* Use the data type to determine if the y-axis should be included *)
	extraplotopts = Switch[dataType,
		Object[Data, NMR], {Yaxis -> False},
		Object[Data, MassSpectrometry], {Yaxis -> False},
		_, {Yaxis -> True}
	];

	numZones = Length[domainVar];

	(* create an input for the peaks epilog *)
	pksPacketEpilog = Join[pks, <|Type -> Object[Analysis, Peaks],BaselineFunction->baselineFunction|>];

	(*
		if the data type is agarose we want to perform a log transform on the x axis of data for the Peaks Epilog
		after all calculations have been performed. This will put the epilog in the right place, but also
		get the areas correct.
	*)
	If[MatchQ[dataType, Object[Data,AgaroseGelElectrophoresis]],
		(* rescale the baseline, widths, ranges, and peaklocations *)
		pksPacketEpilog = Plot`Private`scaleUnitlessPeaksLogLinear[pksPacketEpilog,LogLinear, Null];
		(* drop the extra keys to get the same pks format as above *)
		pks = KeyDrop[pksPacketEpilog,{Type, BaselineFunction}];
		(* pull out the transformed baseline function *)
		baselineFunction = Lookup[pksPacketEpilog, BaselineFunction];
		(* transform the domains and baseline ranges for the epilogs *)
		domainVar = Log10[domainVar];
        	baselineRanges = Log10[baselineRanges];
		(* note that we are now scaling the data loglinearly *)
		extraplotopts = ReplaceRule[extraplotopts, {Scale->LogLinear}];
	];

	resolutionMatrix = fullResolutionMatrixHalfHeight[pks];

	widthbars = False;
	peakEpilogPrimitives[pks_] := Replace[PeakEpilog[xyTransformed, pksPacketEpilog, PlotRange -> plotRange, Sequence@@extraplotopts, Display -> If[widthbars, {Peaks, PeakWidths}, {Peaks}]], _PeakEpilog -> {}];
	smoothedplotPrimitive[False] := {};
	smoothedplotPrimitive[True] := Table[{Red,Line[gaussianSmooth1D[selectInDomain[xy, domainVar[[ix]]], spanVar[ix]]]},{ix,1,numZones}];

	controlsplotPrimitive[False,pks_]:={};
	controlsplotPrimitive[True,pks_]:=Flatten[Table[epilog[ix, pks], {ix,1,numZones}],1];
	colorsList = Rest @ ColorData[1, "ColorList"];
	epilog[ix_,pks_]:=With[{xminpt = xmin, color=(Mod[#,Length[colorsList],1]&)},Join[
		{
			{colorsList[[color[ix]]],Line[{{domainVar[[ix, 1]],ymin},{domainVar[[ix, 1]],ymax}}]},
			{colorsList[[color[ix]]],Line[{{domainVar[[ix, 2]],ymin},{domainVar[[ix, 2]],ymax}}]}
		},
		{
			{colorsList[[color[ix]]],Line[Transpose[{{domainVar[[ix, 1]],domainVar[[ix, 2]]},absVar[[ix]]*{1,1}}]]},
			{colorsList[[color[ix]]],Dashed,Line[Transpose[{{domainVar[[ix, 1]],domainVar[[ix, 2]]},(absVar[[ix]]+relVar[[ix]])*{1,1}}]]},
			{colorsList[[color[ix]]],Dotted,Line[Transpose[{{domainVar[[ix, 1]],domainVar[[ix, 2]]},(absVar[[ix]]+globalConsolVar[[ix]]*{1,1})}]]},

			MapThread[{colorsList[[color[ix]]],Dotted,Line[{{#1-widthConsolVar[[ix]],#2+baselineFunction[#1]},{#1+widthConsolVar[[ix]],#2+baselineFunction[#1]}}]}&,Lookup[pks,{Position,Height}]]
		}
		]
	];

	baselinePrimitive[False,_,_]:={};
	baselinePrimitive[True,LocalConstant|LocalLinear,pks_,blf_]:=MapThread[drawLine[#1,#2,#3,#4]&,({PeakRangeStart,PeakRangeEnd,BaselineSlope,BaselineIntercept}/.pks)];

	baselinePrimitive[True,EndpointLinear,pks_,blf_]:=Module[{xyInDomain},

		(*For multiple domains map the baselines into the domains. Otherwise apply the baseline to the whole dataset*)
		Map[
			Function[dom,
				xyInDomain = selectInclusiveMatrixPointsInsideRangeC[xy,dom[[1]],dom[[2]]];
				{Thick,Orange,Line[Transpose[{xyInDomain[[;;,1]],blf/@xyInDomain[[;;,1]]}]]}
				],
			domainVar
		]
	];

	baselinePrimitive[True,DomainConstant|DomainLinear,pks_,blf_]:=Module[{xyInDomain},

		(*Map baselines across domains. They will only be applied to the ranges where the baseline is valid*)
		Map[
			Function[dom,
				xyInDomain = selectInclusiveMatrixPointsInsideRangeC[xy,dom[[1]],dom[[2]]];
				{Thick,Orange,Line[Transpose[{xyInDomain[[;;,1]],blf/@xyInDomain[[;;,1]]}]]}
				],
			domainVar
		]

	];

	baselinePrimitive[True,DomainNonlinear,pks_,blf_]:=Module[{xyInDomain},
		Map[
			Function[dom,
				xyInDomain = selectInclusiveMatrixPointsInsideRangeC[xy,dom[[1]],dom[[2]]];
				{Thick,Orange,Line[Transpose[{xyInDomain[[;;,1]],blf/@xyInDomain[[;;,1]]}]]}
				],
			domainVar
		]
	];

	baselinePrimitive[True,baseline:GlobalConstant|GlobalLinear|GlobalNonlinear,pks_,blf_]:=Module[
		{
			newBaseline, newBaselineAssociation
		},

		(* Lookup the correct baseline *)
		newBaselineAssociation = <|
			GlobalConstant -> DomainConstant,
			GlobalLinear -> DomainLinear,
			GlobalNonlinear -> DomainNonlinear
		|>;

		newBaseline = Lookup[newBaselineAssociation, baseline];

		(* Throw warning *)
		Message[Warning::DeprecatedBaseline, baseline, newBaseline];

		(* Call with modified baseline *)
		baselinePrimitive[True,newBaseline,pks,blf]

	];

	baselinePrimitive[___]:={};
	drawLine[x1_,x2_,Null,Null]:={Thick,Orange,Line[{{x1,Mean[xy[[;;,2]]]},{x2,Mean[xy[[;;,2]]]}}]};
	drawLine[x1_,x2_,slope_,intercept_]:={Thick,Orange,Line[{{x1,(x1*slope+intercept)},{x2,(x2*slope+intercept)}}]};

	peakRangeEpilogs[True,pks_]:={Thick,Darker[Gray],MapThread[Line[{{#1,ymin},{#2,ymin}}]&,Lookup[pks,{PeakRangeStart,PeakRangeEnd}]]};
	peakRangeEpilogs[False,pks_]:={};

	(*Lookup baseline epilog option*)
	showBaseline = Lookup[resolvedOps, HighlightBaselinePoints];

	(*Show the baseline epilog*)
	baselineEpilog[True]:= Module[{},
		(*Pull out xy points in the domains*)
		allXYPointsInDomain = Map[
			Function[dom,
				selectInclusiveMatrixPointsInsideRangeC[xy,dom[[1]],dom[[2]]]
				],
			domainVar
		];

		(*pull out xy points in the domain outside of the peaks*)
		pointsOutsidePeaks = Fold[Analysis`Private`selectInclusiveMatrixPointsOutsideRangeC[#1, Sequence @@ #2] &, Flatten[allXYPointsInDomain,1], Flatten[baselineRanges,1]];

		(*create a graphic to show those points*)
		{Red, PointSize[Medium],Point[pointsOutsidePeaks]}
	];
 
	baselineEpilog[False]:= {};

	peakSplitDomainEpilogs[_,Null]:={};
	peakSplitDomainEpilogs[True,pkGroupDomains_]:={Thick,Darker[Red],Flatten@Map[
		{
			(* Group index that each peak domain corresponds to, None otherwise *)
			With[{
					groupIndex=First@FirstPosition[First/@Lookup[pksPacket,SplittingData],
						_?(Function[{pos},spanContainsQ[#,pos]]),
						{""},
						1
					]
				},
				Text[
					Style[ToString[groupIndex],Bold,Darker@Red,FontFamily->"Arial",12],
					{-Mean[List@@Unitless[#]],ymin},
					{0,1.5}
				]
			],
			Line[{{-Unitless[First[#]],ymin},{-Unitless[Last[#]],ymin}}]
		}&,
		pkGroupDomains
	]};
 
	peakSplitDomainEpilogs[False,pkGroupDomains_]:={};

	epilogs=Switch[dataType,
		(* NMR Data *)
		Object[Data,NMR],
			{
				peakSplitDomainEpilogs[True,Lookup[pksPacket,PeakGroupDomains]]
			},

		(* CoulterCount data *)
		Object[Data,CoulterCount],
			{
				baselinePrimitive[True,Lookup[resolvedOps,Baseline],pks,baselineFunction],
				peakRangeEpilogs[True,pks],
				baselineEpilog[showBaseline]
			},

		(* Everything else *)
		_,
			{
				peakEpilogPrimitives[pks],
				smoothedplotPrimitive[False],
				controlsplotPrimitive[True,pks],
				baselinePrimitive[True,Lookup[resolvedOps,Baseline],pks,baselineFunction],
				peakRangeEpilogs[False,pks],
				baselineEpilog[showBaseline]
			}
	];

	(* Overloads with different previews based on the input data type *)
	fig=Switch[dataType,

		(* Fluorescence/Absorbance Spec and/or Western *)
		Alternatives[Object[Data, FluorescenceSpectroscopy],Object[Data, AbsorbanceSpectroscopy],Object[Data, Western]],
			ECL`PlotObject[dataType[[2]],xy,Display->{},ImageSize->550,PlotRange->plotRange*units,Zoomable->False],

		(* Mass Spectrometry Data *)
		Object[Data, MassSpectrometry],
			ECL`PlotObject[dataType[[2]],xy,Display->{},ImageSize->550,PlotRange->plotRange*units,Frame->{{True,False},{True,False}},Zoomable->False],

		(* Chromatography Data *)
		Object[Data, Chromatography],
			ECL`EmeraldListLinePlot[QuantityArray[xy,units],Display->{},ImageSize->550,PlotRange->plotRange*units],

		(* ChromatographyMassSpectra Data *)
		Object[Data, ChromatographyMassSpectra],
			ECL`EmeraldListLinePlot[xy,
				FrameLabel->Map[
					If[MatchQ[#,1],
						Automatic,
						(UnitDimension[#]<>UnitForm[#,Number->False])/.{"Mol. Weight (Da)"->"m/z"}
					]&,
					units
				],
				PlotLabel->"",
				PlotRange->plotRange,
				ImageSize->550
			],

		(* PAGE or TLC Data (superimpose image) *)
		Alternatives[Object[Data, PAGE], Object[Data, TLC]],
			Show[
				ListLinePlot[xy,Filling->Bottom,ImageSize->550,FrameLabel->{"Pixel Position","Summed Pixel Intensity"},PlotRange->{{xmin,xmax},{ymin,1.25*ymax}}],
				Graphics[Inset[image,{0,1.1*ymax},{0,1.1*ymax},xmax]]
			],

		(* Agarose Gel Electrophoresis *)
		Object[Data,AgaroseGelElectrophoresis],
			ECL`PlotObject[dataType[[2]],ToPackedArray[xyIn],Display->{},ImageSize->550,PlotRange->plotRange*units,Scale->LogLinear,Zoomable->False],

		(* NMR Data *)
		Object[Data,NMR],
			ECL`PlotNMR[QuantityArray[xy,units],Peaks->stripAppendReplaceKeyHeads[finalPeakPacket],PlotRange->plotRange,FrameLabel->{"Chemical Shift (PPM)",None},Prolog->epilogs],

		(* CoulterCount Data *)
		Object[Data,CoulterCount],
			ECL`PlotCoulterCount[QuantityArray[xy, units], Peaks -> stripAppendReplaceKeyHeads[finalPeakPacket], Legend -> Null, PlotLabel -> ECL`InternalUpload`ObjectToString[dataTag], PlotRange -> plotRange, Epilog -> epilogs],

		(* Default Case is a plot of the raw data *)
		_,
			Unzoomable[ECL`PlotObject[xy,PlotRange->plotRange,ImageSize->550]]
	];

	(* TODO: Wrap this into the fig switch *)
	If[MatchQ[dataType,Object[Data,NMR]|Object[Data,CoulterCount]],
		fig,
		Zoomable[Show[fig, Epilog->epilogs]]
	]
];


(* Format the preview graphic *)
formatPreviewGraphic[rawData_,xyUnits_,rawPreviews_,rawSlices_,resolvedOps_]:=Module[
	{refPeaks,refPeakGraphics,refPeakLabels,checkedPeakLabels,sliceLabels,plotTypeLabels,finalPreviews},

	(* List of reference peaks, if they were provided for each slice *)
	refPeaks=ToList[Lookup[resolvedOps,SliceReferencePeaks,Null]/.{None->Null}];

	(* Reference peak graphics, Null if no reference peaks were provided. Don't repeat calculations  *)
	refPeakGraphics=refPeaks/.Map[
		#->createReferencePeakPreview[#]&,
		DeleteDuplicates[refPeaks]
	]/.{Null->Nothing};

	(* Labels from reference peaks *)
	refPeakLabels=Download[First[refPeaks],PeakLabel];

	(* If length of labels matches number of slices, then we can use labels for the slices *)
	checkedPeakLabels=If[Length[refPeakLabels]==Length[rawSlices],
		refPeakLabels,
		Repeat[Null,Length[rawSlices]]
	];

	(* If we are previewing slices, then generate labels for each slice *)
	sliceLabels=If[Length[rawSlices]==Length[rawPreviews]&&!MatchQ[rawSlices,Null|{Null..}],
		MapThread[
			Function[{slice,label},
				Which[
					(* Use a peak label if it was provided *)
					MatchQ[label,_String],label,
					(* If a span was given, then display a range *)
					First[slice]!=Last[slice],StringRiffle[ToString/@Round[slice,0.01]," - "],
					(* If sliced at a single value, then use that value *)
					True,ToString@Round[First[slice],0.01]
				]
			],
			{FirstOrDefault/@rawSlices,checkedPeakLabels}
		],
		Null
	];

	(* Resolve labels for plot types *)
	plotTypeLabels=Replace[
		UnitBase[xyUnits]/.referencePlotTypeRules,
		Except[_String]->"Preview",
		{1}
	];

	(* Add reference peaks when appropriate *)
	finalPreviews=If[Length[refPeakGraphics]==Length[rawPreviews],
		MapThread[
			Grid[{{
				#1,
				#2/.{Rule[PlotLabel,""]->Rule[PlotLabel,#4<>" for "<>#3]}
			}}]&,
			{refPeakGraphics,rawPreviews,sliceLabels,plotTypeLabels}
		],
		rawPreviews
	];

	(* If a single input was provided, show a single preview, else throw previews into slides *)
	Which[
		Length[rawData]==1,First[finalPreviews],
		!MatchQ[sliceLabels,Null],MenuView[Thread[sliceLabels->finalPreviews]],
		True,SlideView[finalPreviews]
	]
];

(* Default preview is Null *)
createReferencePeakPreview[_]:=Null;

(* Given a peaks object, create a preview for reference peaks *)
createReferencePeakPreview[pksObj:ObjectP[Object[Analysis,Peaks]]]:=Module[
	{pksRef,pksRefField,dataToPlot,xUnit,yUnit,xyData,unitlessPeakPacket,label},

	(* Get the Reference object and Reference field *)
	{pksRef,pksRefField}=Download[pksObj,{Reference[[-1]][Object],ReferenceField}];

	(* Get units of data to plot and unitless values *)
	dataToPlot=Download[pksRef,pksRefField];
	{{xUnit,yUnit},xyData}=Analysis`Private`unitsAndMagnitudes[dataToPlot];

	(* Strip units from the peak packet for speed *)
	unitlessPeakPacket=KeyDrop[Download[pksObj],PeakUnits];

	(* Resolve the label for the reference peaks based on units and type *)
	label=UnitBase[{xUnit,yUnit}]/.referencePlotTypeRules;

	(* Plot the unitless data for speed *)
	EmeraldListLinePlot[xyData,
		PlotLabel->Column[
			{
				Style["Reference "<>If[MatchQ[label,_String],label,"Peaks"],18],
				Style[ToString[NamedObject@pksRef]<>"["<>ToString[pksRefField]<>"]",Directive[12,Gray,Plain]]
			},
			Alignment->Center,
			Spacings->0.1
		],
		FrameLabel->{
			If[MatchQ[xUnit,1],Automatic,UnitDimension[xUnit]<>UnitForm[xUnit,Number->False]],
			If[MatchQ[yUnit,1],Automatic,UnitDimension[yUnit]<>UnitForm[yUnit,Number->False]]
		},
		Peaks->unitlessPeakPacket,
		Zoomable->True,
		Filling->Bottom
	]
];



(* ::Subsection::Closed:: *)
(*resolveAnalyzePeaksInputs*)


(* Map input resolution over each input. Resolution by input type is handled by resolveSingleInput[] *)
resolveAnalyzePeaksInputs[in_,combinedOps_,gatherTests_]:=Module[
	{
        numInputs,refOption,listedRefOption,resolvedInputs,expandedOps,refField,xyUnits,rawData,
        wavelengths,slicingOps,tests,images,samples,transformFunc,transformedUnits,transformedData,
        listedRefOptions
    },

	(* Number of inputs *)
	numInputs=Length[in];

	(* User-specified reference field option *)
	refOption=Lookup[combinedOps,ReferenceField,Automatic];

	(* Convert this to a list with the same length as the number of inputs *)
	listedRefOptions=If[Length[refOption]==numInputs,
		refOption,
		Repeat[refOption,numInputs]
	];

	(* Index-Expand the reference field option in the combined options *)
	expandedOps=If[numInputs==Length[refOption],
		Map[
			ReplaceRule[combinedOps,ReferenceField->Part[refOption,#]]&,
			Range[numInputs]
		],
		Repeat[combinedOps,numInputs]
	];

	(* Primary Input Resolution. *)
	resolvedInputs=MapThread[resolveSingleInput[#1,#2,#3,gatherTests]&,{in,expandedOps,listedRefOptions}];

	(* Split resolved inputs into constituent fields. *)
	{refField,xyUnits,rawData,samples,wavelengths,slicingOps,tests}=If[MatchQ[Dimensions[resolvedInputs],{_,7,___}],
		Transpose[resolvedInputs],
		Message[Error::InvalidInput,in];
		Repeat[$Failed,7]
	];

	(* If input is PAGE data, download an image of the gel, otherwise Null *)
	images=resolveAnalyzePeaksImage/@in;

	(* Transformation function to apply to data, Null if none should be used *)
	transformFunc=Lookup[combinedOps,DataSetTransformationFunction,Null];

	(* Apply transformation functions if the transformation function option was specified. *)
	{transformedData,transformedUnits}=transformRawData[N[rawData],xyUnits,transformFunc];

	(* Return the resolved input fields *)
	{
		refField,
		transformedUnits,
		transformedData,
		samples,
		wavelengths,
		slicingOps,
		images,
		tests
	}
];

(* ::Subsubsection:: *)
(* transformRawData *)

(* Special Keys (LogLinear,LinearLog, and LogLog) *)
transformRawData[rawData_,units_,LogLinear]:=transformRawData[rawData,units,{(Log10[#]&),(Identity[#]&)}];
transformRawData[rawData_,units_,LinearLog]:=transformRawData[rawData,units,{(Identity[#]&),(Log10[#]&)}];
transformRawData[rawData_,units_,LogLog]:=transformRawData[rawData,units,{(Log10[#]&),(Log10[#]&)}];

(* If individual functions were specified, map to single function overload *)
transformRawData[rawData_,units_,{funcX:_Function|None,funcY:_Function|None}]:=Module[
	{combinedTransformFunc},

	(* Combine the two transformation functions *)
	combinedTransformFunc=Function[{xy},
		{
			(funcX/.{None->Identity})[First@xy],
			(funcY/.{None->Identity})[Last@xy]
		}
	];

	(* Pass on to the primary overload*)
	transformRawData[rawData,units,combinedTransformFunc]
];

(* Primary overload - single transformation function *)
transformRawData[rawData_,units_,tfunc:_Function|_QuantityFunction]:=Module[
	{transformedData,unitCheck,transformedUnits,checkedData},

	(* Apply the transformation function to each dataset *)
	transformedData=Quiet@Map[
		Function[{coords},tfunc/@coords],
		rawData
	];

	(* Return early and error if the transformation function doesn't return xy coordinates *)
	If[!MatchQ[transformedData,{CoordinatesP..}],
		Message[Error::InvalidTransformation,tfunc];
		Message[Error::InvalidOption,DataSetTransformationFunction];
		Return[{rawData,units}];
	];

	(* Apply the transformation function to each set of units to see if we get the same units back *)
	unitChecks=Map[tfunc,units];

	(* Keep old units if transform was unitary, otherwise default to unitless *)
	transformedUnits=MapThread[
		Function[{xy,check},
			{
				If[First[xy]===Units@First[check],First[xy],1],
				If[Last[xy]===Units@Last[check],Last[xy],1]
			}
		],
		{units,unitChecks}
	];

	(* Return requested values *)
	{transformedData,transformedUnits}
];

(* Do nothing if no transformation function was specified *)
transformRawData[rawData_,units_,other_]:={rawData,units};


(* ::Subsubsection:: *)
(*resolveSingleInput*)

(***
	resolveSingleInput[input, combinedOps, refOption, gatherTests] must return:
 		{
			refField - If input is an object, the field in that object which contains data to analyze, Null otherwise.
			xyUnits - Physical units of the input data.
			rawData - Unitless numerical raw data, as a list of {x,y} data points, for peaks analysis
			samples - For object inputs, links to any SamplesIn associated with the data, {} otherwise.
			wavelength - For 3D Chromatography data only, the wavelength at which the signal was collected, and Null otherwise.
			slicingOps - A list of options used for data slicing. These options are Null for 2D data.
			tests - When gatherTests is True, any tests which are returned by input resolution, otherwise {}.
		}
***)

(**************************)
(*** Raw numerical data ***)
(**************************)

(* 2D Numerical Data {{x,y}..} *)
resolveSingleInput[xy:CoordinatesP|QuantityCoordinatesP[], safeOps_, refOption_, collectTestsBoolean_]:={Null,Sequence@@unitsAndMagnitudes[xy],{},Null,{},{}};

(* 3D Numerical Data {{x,wavelength,y}..}. Assumed to be chromatography data. *)
resolveSingleInput[xzy: QuantityMatrixP[], safeOps_, refOption_, collectTestsBoolean_] := Module[
	{unit, data, out2D, wavelength},
	{unit, data} = unitsAndMagnitudes[xzy];
	{out2D, wavelength} = sliceChromatogram3D[unit,data,Lookup[safeOps,Wavelength],Null];
	{Null, Sequence@@out2D, {}, wavelength, {}, {}}
];


(**************************************)
(*** Resolution for sliced 3+D Data ***)
(**************************************)

(* Resolution for data slicing checks to see if the ReferenceField option matches sliceableDataFieldP *)
resolveSingleInput[obj:ObjectP[],safeOps_,refOption:sliceableDataFieldP,collectTestsBoolean_]:=Module[
	{
		dim,downsampledFields,downsamplingQ,samplesIn,downsamplePacket,downsampleDataObj,downsampledData,
		data,refPeaksOps,slicingOps,slice,slicePattern,listedSlicingOps,automaticOps,
		combinedSlicingOps,resolvedSlicingOps, type
	},

	(* Dimensionality of the requested reference field *)
	dim=Length[Lookup[sliceableFieldDimensionLookup,refOption]]+1;

	(* get the type of the object *)
	type = Download[obj, Type];

	(* A list of fields of the input object type which use downsampling *)
	downsampledFields=Lookup[downsampledDataLookup, type, {}];

	(* True if the object and refOption will require downsampling *)
	downsamplingQ=MemberQ[downsampledFields,refOption];

	(* Download fields required by the object *)
	{samplesIn,downsamplePacket}=If[downsamplingQ,
		Download[obj,{SamplesIn,Packet[DownsamplingAnalyses[[-1]][{Object,DataUnits,SamplingGridPoints,NoiseThreshold,DownsampledDataFile}]]}],
		{Download[obj,SamplesIn],Null}
	];

	(* Return early fail state if the data can't be resolved *)
	If[MemberQ[Values[downsamplePacket],$Failed],
		If[(Now-dataObject[DateCreated])<(12 Hour),
			(* Object was created recently *)
			Message[Error::DownsampledDataNotReady,DateString[dataObject[DateCreated]+(12 Hour)],dataObject],
			(* Object was not created recently *)
			Message[Error::DownsampledDataNotFound,dataObject]
		];
		Return[$Failed]
	];

	(* Get the object reference of the cloud file in which the downsampled data is stored *)
	downsampleDataObj=Lookup[downsamplePacket,DownsampledDataFile];

	(* Import the downsampled data .MX file into a sparse array, memoizing for performance. *)
	downsampledData=ImportCloudFile[downsampleDataObj];

	(* If the field did not resolve to a sparse array, return an early fail state *)
	If[!MatchQ[downsampledData,_SparseArray],
		Message[Error::DataFormat,downsamplePacket[Object],dataObject[Object]];
		Return[$Failed]
	];

	(* Slicing options from reference peaks *)
	refPeaksOps=optionsFromReferencePeaks[refOption,Lookup[safeOps,SliceReferencePeaks]];

	(* Grab options related to data slicing *)
	slicingOps=Normal@KeyTake[safeOps,{DataSliceDimension,DataSlice,SliceReductionFunction,SliceReferencePeaks}];

	(* DataSlice option. ToList added after changing DataSlice to Span without the unnecessary listedness *)
	slice=ToList[Lookup[slicingOps,DataSlice,Automatic]];

	(* Pattern for a valid data slice. The old way of using UnitsP[] does not work on span *)
	slicePattern=Repeated[
		(_?QuantityQ|_?NumericQ)|
		(_?QuantityQ ;; _?QuantityQ)|(_?NumericQ ;; _?NumericQ)|
		{(_?QuantityQ ;; _?QuantityQ) ..}|{(_?NumericQ ;; _?NumericQ) ..}, dim-2
	];

	(* Need to handle index-matching in its own way because of nested lists *)
	listedSlicingOps=If[MatchQ[slice,{slicePattern..}],

		(* need to separate the single vs. multi-slice cases *)
		{ReplaceRule[slicingOps,
			DataSlice -> Which[
				MatchQ[slice, {_?QuantityQ | _?NumericQ}], slice,
 				MatchQ[slice, _?QuantityQ ;; _?QuantityQ | _?NumericQ ;; _?NumericQ | {_?QuantityQ ;; _?QuantityQ ..} | {_?NumericQ ;; _?NumericQ ..}], {#[[1]], #[[2]]} & /@ slice]
		]},

		{slicingOps}
	];

	(* Only the slicing options which were not explicitly specified (i.e. the Automatics) *)
	automaticOps=First/@Select[slicingOps,(Last[#]==Automatic&)];

	(* Replace automatics with options from reference peaks. slice[[1]] is needed since we added ToList at Ln 1783 *)
	combinedSlicingOps=If[MatchQ[slice[[1]],Automatic],
		Map[
			ReplaceRule[slicingOps,Normal@KeyTake[#,automaticOps]]&,
			refPeaksOps
		],
		Map[
			ReplaceRule[#,Normal@KeyTake[First[refPeaksOps],automaticOps]]&,
			listedSlicingOps
		]
	];

	(* Resolve the input by slicing it according to the option specifications and plot type, slicing as needed *)
	{data,resolvedSlicingOps}=Transpose@Map[
		sliceDownsamplingPacket[refOption,downsampledData,downsamplePacket,#]&,
		combinedSlicingOps
	];

	(* Return resolved inputs. If multiple were resolved due to the reference peaks options, then return as a sequence *)
	Transpose@MapThread[
		{
			refOption,
			Sequence@@unitsAndMagnitudes[#1],
			samplesIn,
			Null,
			#2,
			{}
		}&,
		{data,resolvedSlicingOps}
	]
];


(* Resolve slicing options from reference peaks *)
optionsFromReferencePeaks[ref_,pks:ObjectP[Object[Analysis,Peaks]]]:=Module[
	{pkPacket,pkUnits,pkPos,pkPosUnits,unitsToSliceDimension,defaultOps},

	(* Make sure the peaks object is in clean packet form *)
	pkPacket=stripAppendReplaceKeyHeads@Download[pks];

	(* Get the Peak Units *)
	pkUnits=Computables`Private`peakUnits[
		Sequence@@Lookup[pkPacket,{Reference,ReferenceField,ReferenceDataSliceDimension},Null]
	];

	(* Units of peak position *)
	pkPosUnits=Lookup[pkUnits,Position,Null];

	(* List of peak positions *)
	pkPos=Lookup[pkPacket,Position,{}];

	(* Given a reference field, get a mapping of units to slice dimension. Null defaults to Automatic. *)
	unitsToSliceDimension=Lookup[sliceableFieldUnitLookup,ref,{}];

	(* Default options to use given this reference peaks object *)
	defaultOps={
		DataSliceDimension->ToList[Lookup[unitsToSliceDimension,pkPosUnits,Automatic]],
		SliceReductionFunction->Mean
	};

	(* Create a set of options for each peak *)
	If[MatchQ[pkPos,{}|Null|$Failed],
		{{}},
		Append[defaultOps,DataSlice->{#*pkPosUnits}]&/@pkPos
	]
];

(* If no peaks were supplied, then return an empty list of options *)
optionsFromReferencePeaks[_,_]:={{}};


(* Slice data from a downsampling packet according to the provided slicing options *)
sliceDownsamplingPacket[field:sliceableDataFieldP,data_SparseArray,pkt_,slicingOps:{_Rule..}]:=Module[
	{
		namedDimensions,dataUnits,gridBounds,resolvedSliceDimensionNamed,
		resolvedSliceDimension,resolvedSlicingOps,resolvedSliceFunc,resolvedSlice,
		unitlessSlice,sliceIndices,slicedData,gridPts,slicedDataWithUnits
	},

	(* Number of dimensions of the data *)
	dim=Length[Dimensions[data]]+1;

	(* Check to see if the input field being resolved has named dimensions  *)
	namedDimensions=Lookup[sliceableFieldDimensionLookup,field,{}];

	(* Get the boundaries of sampling points from the downsampling packet *)
	{dataUnits,gridBounds}=Lookup[pkt,{DataUnits,SamplingGridPoints}];

	(* First, resolve which dimension to slice. Default is to slice from the left-most dimensions first *)
	resolvedSliceDimension=Lookup[slicingOps,DataSliceDimension]/.Append[
		namedDimensions,
		Automatic->Range[dim-2]
	];

	(* Use names when possible for the actual resolved option output *)
	resolvedSliceDimensionNamed=resolvedSliceDimension/.(Reverse/@namedDimensions);

	(* Slice reduction function, where Automatic defaults to Mean *)
	resolvedSliceFunc=PadRight[
		ToList[Lookup[slicingOps,SliceReductionFunction]/.{Automatic->Repeat[Mean,dim-2]}],
		dim-2,
		Mean
	];

	(* Make sure all named dimensions have been resolved *)
	If[!MatchQ[resolvedSliceDimension,{_Integer..}],
		Message[Error::InvalidNamedDimension,Lookup[slicingOps,DataSliceDimension],field,First/@namedDimensions];
		Return[{$Failed,slicingOps}];
	];

	(* Ensure that the requested slice dimension is in bounds *)
	If[Min[resolvedSliceDimension]<1||Max[resolvedSliceDimension]>dim,
		Message[Error::SliceDimensionOutOfBounds,Lookup[slicingOps,DataSliceDimension],dim,dim-1];
		Return[{$Failed,slicingOps}];
	];

	(* Ensure that the requested slice dimension results in 2D data *)
	If[Length[DeleteDuplicates[resolvedSliceDimension]]!=(dim-2),
		Message[Error::InvalidSliceDimension,Lookup[slicingOps,DataSliceDimension],dim,dim-2];
		Return[{$Failed,slicingOps}];
	];

	(* If dimensions are okay, then resolve slices. Default is full sampling range *)
	resolvedSlice=Lookup[slicingOps,DataSlice]/.{
		Automatic->Most/@(Part[gridBounds,resolvedSliceDimension]*Part[dataUnits,resolvedSliceDimension])
	};

	(* If the length of slices does not match the number of slicing dimensions, return with error *)
	If[Length[resolvedSlice]!=Length[resolvedSliceDimension],
		Message[Error::InvalidSliceLength,resolvedSlice,Length[resolvedSlice],Length[resolvedSliceDimension]];
		Return[{$Failed,slicingOps}];
	];

	(* Resolved slicing options *)
	resolvedSlicingOps={
		DataSliceDimension->resolvedSliceDimensionNamed,
		DataSlice->resolvedSlice,
		SliceReductionFunction->resolvedSliceFunc,
		SliceReferencePeaks->Lookup[slicingOps,SliceReferencePeaks,None]/.{Automatic->None}
	};

	(* Convert the slice to correct units, or ignore units if provided as unitless *)
	unitlessSlice=MapThread[
		Function[{slice,units,dim},
			Quiet[
				Check[N@Unitless[slice,units],
					Message[Warning::IncompatibleSliceUnits,DeleteDuplicates@Units[slice],units,dim];
					N@Unitless[slice]
				],
				{Quantity::compat}
			]
		],
		{
			Replace[resolvedSlice,n:UnitsP[]:>{n,n},1],
			Part[dataUnits,resolvedSliceDimension],
			resolvedSliceDimensionNamed
		}
	];

	(* Convert slice ranges to indices in each dimension *)
	sliceIndices=MapThread[
		Function[{slice,dim},
			Module[{bounds,maxIndex},
				(* Grid boundaries in the given dimension *)
				bounds=Part[gridBounds,dim];
				(* Maximum index in a given dimension *)
				maxIndex=Part[Dimensions[data],dim];
				(* Make sure index is in bounds *)
				Min[maxIndex,Max[1,
					(1+Round[(#-First[bounds])/Last[bounds]])
				]]&/@slice
			]
		],
		{unitlessSlice,resolvedSliceDimension}
	];

	(* Sort by ascending dimension to get ready for slicing by Fold *)
	processedFoldList=SortBy[
		Transpose@{resolvedSliceDimension,sliceIndices,resolvedSliceFunc},
		First
	];

	(* Adjust the indices to account for a dimension getting removed at every iteration *)
	processedFoldList[[All,1]]=processedFoldList[[All,1]]-Range[Length[processedFoldList]]+1;

	(* Now slice the data *)
	slicedData=Normal@Fold[
		Module[{arr,dim,idxs,func,swappedArr,trimmedArr},
			(* First argument is the previous array *)
			arr=#1;
			(* Second argument is an entry from processed list *)
			{dim,idxs,func}=#2;
			(* Use Transpose to swap the reduced dimension into the first dimension *)
			swappedArr=Transpose[arr,1<->dim];
			(* Slice the reduced dimension *)
			trimmedArr=swappedArr[[Span@@idxs]];
			(* Eliminate the first dimension, and be sad because ArrayReduce isn't in MM 12.0 *)
			Switch[func,
				Mean,Mean[trimmedArr],
				Max,Max/@Transpose[trimmedArr,1<->2],
				Min,Min/@Transpose[trimmedArr,1<->2],
				Total,Total[trimmedArr,1]
			]
		]&,
		data,
		processedFoldList
	];

	(* Grid points of the remaining independent variable dimension after slicing *)
	gridPts=Range@@Part[gridBounds,First@Complement[Range[dim-1],resolvedSliceDimension]];

	(* Append units to the data *)
	slicedDataWithUnits=QuantityArray[
		Transpose@{gridPts,slicedData},
		Part[dataUnits,Complement[Range[dim],resolvedSliceDimension]]
	];

	(* Return the sliced data and resolved slicing options *)
	{slicedDataWithUnits,resolvedSlicingOps}
];


(**********************)
(*** Chromatography ***)
(**********************)

(* Primary Chromatography Overload *)
resolveSingleInput[inputPacket:PacketP[{Object[Data,Chromatography],Object[Data,ChromatographyMassSpectra]}],safeOps_,refOption_,collectTestsBoolean_]:=Module[
	{refFieldLookup,input2D,referenceField,wavelength,wavelengthRangeTest},

	(* User-supplied reference field from safe options *)
	refFieldLookup=safeReferenceField@Lookup[safeOps,ReferenceField];

	(*resolve the chromatography parameters*)
	{referenceField,input2D,wavelength}=resolveChromatography[
		inputPacket,
		safeReferenceField@Lookup[safeOps,ReferenceField],
		Lookup[safeOps,Wavelength]
	];

	(* Create a test for AbsorbanceWavelength if collectTestsBoolean is True, Null otherwise. *)
	wavelengthRangeTest=Quiet[peaksTestOrNull[
		AbsorbanceWavelength,
		collectTestsBoolean,
		"If input data is 3D Chromatography, AbsorbanceWavelength must be between MinAbsorbanceWavelength and MaxAbsorbanceWavelength.",
		If[MatchQ[referenceField,Absorbance3D|$Failed],
			MatchQ[wavelength,Except[$Failed]],
			True
		]
	]];

	(* If the chromatography input failed to resolve, then throw an invalid input error and return $Failed *)
	If[MatchQ[referenceField,$Failed],
		Return[{$Failed,$Failed,$Failed,$Failed,$Failed,$Failed,{wavelengthRangeTest}}]
	];

	(* Return resolved inputs *)
	{referenceField,Sequence@@input2D,Lookup[inputPacket,SamplesIn],wavelength,{},{wavelengthRangeTest}}
];

(* Given a chromatography data object, Download all fields which may contain data and pass to main overload *)
resolveSingleInput[obj:ObjectP[Object[Data,Chromatography]],safeOps_,refOption_,collectTestsBoolean_]:=resolveSingleInput[
	Download[obj,Packet[
		AbsorbanceWavelength,Absorbance,SecondaryAbsorbance,MaxAbsorbanceWavelength,MinAbsorbanceWavelength,
		Fluorescence,SecondaryFluorescence,TertiaryFluorescence,QuaternaryFluorescence,Scattering,
		Conductance,ConductivityFlowCellTemperature,pH,pHFlowCellTemperature,
		MultiAngleLightScattering22Degree,MultiAngleLightScattering28Degree,MultiAngleLightScattering32Degree,MultiAngleLightScattering38Degree,MultiAngleLightScattering44Degree,MultiAngleLightScattering50Degree,MultiAngleLightScattering57Degree,MultiAngleLightScattering64Degree,MultiAngleLightScattering72Degree,MultiAngleLightScattering81Degree,MultiAngleLightScattering90Degree,MultiAngleLightScattering99Degree,MultiAngleLightScattering108Degree,MultiAngleLightScattering117Degree,MultiAngleLightScattering126Degree,MultiAngleLightScattering134Degree,MultiAngleLightScattering141Degree,MultiAngleLightScattering147Degree,
		DynamicLightScattering,RefractiveIndex,Charge,
		FIDResponse,Conductance,SamplesIn,Object,Type
	]],
	safeOps,
	refOption,
	collectTestsBoolean
];

(* Given chromatography mass spec data, download all fields which may contain data and pass to main overload *)
resolveSingleInput[obj:ObjectP[Object[Data,ChromatographyMassSpectra]],safeOps_,refOption_,collectTestsBoolean_]:=resolveSingleInput[
	Download[obj,Packet[
			AbsorbanceWavelength,Absorbance,MinAbsorbanceWavelength,MaxAbsorbanceWavelength,SamplesIn,
			AbsorbanceSelection,MassSpectrum,IonAbundance,TotalIonAbundance,IonAbundanceMass,Object,Type
	]],
	safeOps,
	refOption,
	collectTestsBoolean
];

(*** ResolveChromatography overloads, must return {referenceField, {units2D, data2D}, wavelength} ***)


(* Chromatography reference field is Automatic and must be resolved *)

(* Look for fields according to the priority defined in peaksLookup, in LegacySLL/Constructs.m. Resolve based on the first non-empty field. *)
resolveChromatography[pkt_,field:Automatic,wavelengthOps_] := Module[
	{defaultFields,nonEmptyFields,resolvedRefField,minWL,maxWL,absWL,missingMinMaxWLQ},

	(* Consult lookup table in LegacySLl/Constructs.m to determine default fields to search for data, ordered by priority *)
	defaultFields=LegacySLL`Private`typeToPeaksFields[Lookup[pkt,Type]];

	(* Non-empty fields in the object that are members of default fields *)
	nonEmptyFields=Cases[defaultFields,_?(MatchQ[Lookup[pkt,#,Null],Except[Null|{}|$Failed]]&)];

	(* If all fields are empty, return an invalid input error *)
	If[MatchQ[nonEmptyFields,{}],
		Message[Error::InvalidInput,Lookup[pkt,Object]];
		Return[{$Failed,$Failed,$Failed}]
	];

	(* The first (highest priority) member of defaultFields *)
	resolvedRefField=First[nonEmptyFields];

	(* Look up wavelength fields in packet, returning either Null or $Failed if the fields weren't present in Download *)
	{minWL,maxWL,absWL}=Lookup[pkt,{MinAbsorbanceWavelength,MaxAbsorbanceWavelength,AbsorbanceWavelength},Null];

	(* True if both the minimum and maximum wavelength were either Null or $Failed *)
	missingMinMaxWLQ=And[
		MatchQ[minWL,$Failed|Null],
		MatchQ[maxWL,$Failed|Null]
	];

	(* Resolve the input based on the first non-empty data field *)
	Switch[resolvedRefField,
		(* If absorbance is present, decide if we should use 2D or 3D absorbance data *)
		Absorbance,
		If[And[missingMinMaxWLQ||MatchQ[minWL,maxWL]],
			(* Use 2D Absorbance if minimum and maximum wavelength are missing, or if min and max are the same *)
			resolveChromatography[pkt,Absorbance,wavelengthOps],
			(* Otherwise, resolve as 3D absorbance data *)
			resolveChromatography[pkt,Absorbance3D,wavelengthOps]
		],

		(* Otherwise, assume the data is not 3D and pass to the appropriate resolution *)
		_,
		resolveChromatography[pkt,resolvedRefField,wavelengthOps]
	]
];


(* Reference field is Absorbance (2D Absorbance Data) *)

(* If Null wavelength was provided, return Null, since wavelength does not affect analysis*)
resolveChromatography[pkt_,field:Absorbance,Null]:={field,unitsAndMagnitudes[Lookup[pkt,field]],Null};
(* If wavelength was automatic, then return AbsorbanceWavelength *)
resolveChromatography[pkt_,field:Absorbance,Automatic]:={field, unitsAndMagnitudes[pkt[field]], Round[pkt[AbsorbanceWavelength]]};
(* If wavelength was provided, warn the user if it differs from AbsorbanceWavelength, but return the provided wavelength *)
resolveChromatography[pkt_,field:Absorbance,wavelengthOps_]:=Module[{wavelengthFromData},
	(* Download absorbance wavelength from the input object *)
	wavelengthFromData=Lookup[pkt,AbsorbanceWavelength];

	(* Warn the user if wavelength option does not match the one from data *)
	If[QuantityQ[wavelengthOps]&&!MatchQ[Round@wavelengthOps,Round@wavelengthFromData],
		Message[Warning::WavelengthMismatch,wavelengthFromData]
	];

	(* Return the wavelength from the object, since it is correct *)
	{Absorbance,unitsAndMagnitudes[Lookup[pkt,field]],wavelengthFromData}
];


(* Reference field is Absorbance3D (slice using wavelength) *)

(* If wavelength is automatic, then attempt to use AbsorbanceWavelength to resolve
Wavelength option and pass to other overload of resolveChromatography *)
resolveChromatography[pkt_,field:Absorbance3D,Automatic]:=Module[
	{absWavelength, abs},

	(* pull out the absorbance wavelength and the absorbance *)
	absWavelength = pkt[AbsorbanceWavelength];
	abs = pkt[Absorbance];

	(* check if absorbance and wavelength are populated *)
	(* create booleans to test if wavelength and abs are not null *)
	absQ = MatchQ[abs, Except[Null]];
	absWavelengthQ = MatchQ[absWavelength, Except[Null]];

	(* send message that we are automatically resolving to absWavelength *)
	If[absWavelengthQ,
		Message[Warning::AutomaticWavelength, Round[absWavelength]];
	];

	(* if abs and wavelength are populated, simply use the absorbance *)
	(* if absorbance is not there, but wavelength is, then slice the absorbance3D with another overload *)
	(* if nothing is there, then give up and request a wavelength option *)
	Which[
		And[absQ, absWavelengthQ],
			{Absorbance3D,unitsAndMagnitudes[abs],Round[absWavelength]},
		absWavelengthQ,
			resolveChromatography[pkt, field, Round[absWavelength]],
		(* throw error if it gets to this point *)
		True,
			Message[Error::UnrecognizedWavelength];
			Return[ConstantArray[$Failed, 3]]
	]
];
(* If wavelength was provided, check that it is in range and slice the data at the specified wavelength *)
resolveChromatography[pkt_, Absorbance3D, wavelengthOps_] := Module[
	{abs, absWavelength, unit3D, data3D, out2D, wavelength},

	(* If wavelength option matches primary absorbance wavelength, use the primary 2D data in field Absorbance *)
	abs = Lookup[pkt,Absorbance];
	absWavelength = Round[Lookup[pkt,AbsorbanceWavelength]];
	If[And[Not[MatchQ[abs,Null]], MatchQ[wavelengthOps,absWavelength]],
		Return[{Absorbance3D,unitsAndMagnitudes[Lookup[pkt,Absorbance]],Round[Lookup[pkt,AbsorbanceWavelength]]}]
	];

	(* Check that the wavelength option is in range, and throw and error if it is not *)
	If[!TrueQ[(wavelengthOps>=pkt[MinAbsorbanceWavelength])&&(wavelengthOps<=pkt[MaxAbsorbanceWavelength])],
		Message[Error::UnrecognizedWavelength];
		Message[Error::InvalidOption,Wavelength];
		Return[{$Failed,$Failed,$Failed}]
	];

	(* Download 3D absorbance data *)
	abs3D = Download[Object/.pkt,Absorbance3D];

	(* throw error if 3d data is null *)
	If[MatchQ[abs3D, Null],
		Message[Error::DataNotFound, Absorbance3D, Lookup[pkt, Object]];
		Message[Error::InvalidOption,ReferenceField];
		Return[{$Failed, $Failed, $Failed}]
	];

	(* split the data into units and magnitudes *)
	{unit3D,data3D}=unitsAndMagnitudes[abs3D];

	(* Slice the 3D absorbance data at the specified wavelength *)
	{out2D,wavelength}=sliceChromatogram3D[unit3D,data3D,wavelengthOps,Round[pkt[MinAbsorbanceWavelength]]];

	(* If slicing failed, then return Failed *)
	If[MatchQ[out2D,$Failed],
		Return[{$Failed,$Failed,$Failed}]
	];

	(* Otherwise, return the Absorbance3D field and sliced data*)
	{Absorbance3D, out2D, wavelength}
];


(* List of data fields which are guaranteed to be two-dimensional (wavelength not needed) *)
chromatographyDataFields2D=Alternatives[
	SecondaryAbsorbance,
	Conductance,
	Scattering,
	Fluorescence,
	SecondaryFluorescence,
	TertiaryFluorescence,
	QuaternaryFluorescence,
	FIDResponse,
	IonAbundance,
	DynamicLightScattering,
	MultiAngleLightScattering22Degree,
	MultiAngleLightScattering28Degree,
	MultiAngleLightScattering32Degree,
	MultiAngleLightScattering38Degree,
	MultiAngleLightScattering44Degree,
	MultiAngleLightScattering50Degree,
	MultiAngleLightScattering57Degree,
	MultiAngleLightScattering64Degree,
	MultiAngleLightScattering72Degree,
	MultiAngleLightScattering81Degree,
	MultiAngleLightScattering90Degree,
	MultiAngleLightScattering99Degree,
	MultiAngleLightScattering108Degree,
	MultiAngleLightScattering117Degree,
	MultiAngleLightScattering126Degree,
	MultiAngleLightScattering134Degree,
	MultiAngleLightScattering141Degree,
	MultiAngleLightScattering147Degree,
	RefractiveIndex,
	Conductance,
	ConductivityFlowCellTemperature,
	pH,
	pHFlowCellTemperature,
	TotalIonAbundance,
	MassSpectrum,
	Charge
];


(* Chromatography Reference field is known to be two-dimensional *)
resolveChromatography[pkt_,field:chromatographyDataFields2D,wavelengthOps_]:={field,unitsAndMagnitudes[Lookup[pkt,field]],Null};

(* Warn the user and default to automatic reference field resolution if field is not recognized *)
resolveChromatography[pkt_, _, wavelengthOps_]:=Module[{},
	Message[Warning::UnrecognizedPeaksField];
	resolveChromatography[pkt, Automatic, wavelengthOps]
];


(**********************************)
(*** Special Object Resolutions ***)
(**********************************)

(* CoulterCount overload - there can be multiple diameter distribution curves if NumberOfReadings is greater than 1, so we have to merge the count *)
resolveSingleInput[obj:ObjectP[Object[Data, CoulterCount]], safeOps_, refOption_, collectTestsBoolean_] := Module[{dataField, data, samplesIn, diamCountAssocList, combinedDiameterCountAssoc, mergedData},

	(* Get the default field to search for data in the object *)
	dataField = defaultPeakData[obj, safeReferenceField@Lookup[safeOps, ReferenceField]];

	(* Download data to analyze and SamplesIn *)
	{data, samplesIn} = Download[obj, {dataField, SamplesIn}];

	diamCountAssocList = Map[
		(* We cannot directly Rule@@@ since each distribution is a quantity array, so have to do this weird thing to get rid of the _QuantityArray head *)
		Association[Rule @@@ #]&,
		data
	];

	(* Merge the associations by adding the count up *)
	combinedDiameterCountAssoc = Merge[diamCountAssocList, Total];

	(* Convert the merged association back to quantity arrays *)
	mergedData = QuantityArray[KeyValueMap[{##}&, combinedDiameterCountAssoc]];

	(* Return resolved inputs *)
	{dataField, Sequence @@ unitsAndMagnitudes[mergedData], samplesIn, Null, {}, {}}
];

(* FragmentAnalysis overload *)
resolveSingleInput[obj:ObjectP[Object[Data,FragmentAnalysis]],safeOps_,refOption_,collectTestsBoolean_]:=Module[{dataField,data,samplesIn},
	
	(* Get the default field to search for data in the object *)
	dataField=defaultPeakData[obj,safeReferenceField@Lookup[safeOps,ReferenceField]];
	
	(* Download data to analyze and SamplesIn *)
	{data,samplesIn}=Download[obj,{dataField,SamplesIn}];
	
	(* remove negative x-values from data otherwise issues with logLinear transform *)
	(* use normal and quantity array to pull out list of points for selection but transform back to quantity array *)
	data = QuantityArray[
		Select[Normal[data], QuantityMagnitude[First[#]]>0&]
	];
	
	(* Return resolved inputs *)
	{dataField,Sequence@@unitsAndMagnitudes[data],samplesIn,Null,{},{}}
];


(* DSC overload - there can be multiple heating curves, so the output must be mapped and converted to a sequence *)
resolveSingleInput[obj:ObjectP[Object[Data,DifferentialScanningCalorimetry]],safeOps_,refOption_,collectTestsBoolean_]:=Module[{heatingCurves,samplesIn},
	{heatingCurves,samplesIn}=Download[obj,{HeatingCurves,SamplesIn}];
	Sequence@@({defaultPeakData[obj,safeReferenceField@Lookup[safeOps,ReferenceField]],Sequence@@unitsAndMagnitudes[#],samplesIn,Null,{},{}}&/@heatingCurves)
];

(* FluorescenceSpectroscopy - request for default resolution to check both the EmissionSpectrum and ExcitationSpectrum fields *)
resolveSingleInput[obj:ObjectP[Object[Data,FluorescenceSpectroscopy]],safeOps_,refOption_,collectTestsBoolean_]:=Module[
	{refFieldOption,emissionSpectrum,excitationSpectrum,samplesIn,excitationOutput,emissionOutput,groupedResult},

	(* Reference field option provided *)
	refFieldOption=Lookup[safeOps,ReferenceField];

	(* Download all possible fields for primary data *)
	{emissionSpectrum,excitationSpectrum,samplesIn}=Download[obj,{EmissionSpectrum,ExcitationSpectrum,SamplesIn}];

	(* Populate the emission spectrum if the field is informed *)
	emissionOutput=If[MatchQ[emissionSpectrum,QuantityCoordinatesP[]]&&!MatchQ[refFieldOption,ExcitationSpectrum|{ExcitationSpectrum}],
		{EmissionSpectrum,Sequence@@unitsAndMagnitudes[emissionSpectrum],samplesIn,Null,{},{}},
		Nothing
	];

	(* Populate the excitation spectrum if the field is informed *)
	excitationOutput=If[MatchQ[excitationSpectrum,QuantityCoordinatesP[]]&&!MatchQ[refFieldOption,EmissionSpectrum|{EmissionSpectrum}],
		{ExcitationSpectrum,Sequence@@unitsAndMagnitudes[excitationSpectrum],samplesIn,Null,{},{}},
		Nothing
	];

	(* Group the result *)
	groupedResult={excitationOutput,emissionOutput};

	(* Return the output of both, applying dimensions as necessary *)
	If[Length[groupedResult]>1,
		Transpose[groupedResult],
		FirstOrDefault[groupedResult]
	]
];

(* AgaroseGelElectrophoresis is transformed LogLinearly, which means negative data must be removed *)
resolveSingleInput[obj:ObjectP[Object[Data, AgaroseGelElectrophoresis]],safeOps_,refOption_,collectTestsBoolean_]:=Module[
    {dataField,data,samplesIn},
    
    (* Get the default field to search for data in the object *)
    dataField=defaultPeakData[obj,safeReferenceField@Lookup[safeOps,ReferenceField]];
    
    (* Download data to analyze and SamplesIn *)
    {data,samplesIn}=Download[obj,{dataField,SamplesIn}];

    (* remove negative x-values from data otherwise issues with logLinear transform *)
    (* use normal and quantity array to pull out list of points for selection but transform back to quantity array *)
    data = QuantityArray[
            Select[Normal[data], QuantityMagnitude[First[#]]>0&]
    ];
    
    (* Return resolved inputs *)
    {dataField,Sequence@@unitsAndMagnitudes[data],samplesIn,Null,{},{}}
];

(****************************************)
(*** General Object/Packet Resolution ***)
(****************************************)

(* Default Object Input *)
resolveSingleInput[obj:ObjectP[],safeOps_,refOption_,collectTestsBoolean_]:=Module[{dataField,data,samplesIn},
	(* Get the default field to search for data in the object *)
	dataField=defaultPeakData[obj,safeReferenceField@Lookup[safeOps,ReferenceField]];

	(* Download data to analyze and SamplesIn *)
	{data,samplesIn}=Download[obj,{dataField,SamplesIn}];

	(* Return resolved inputs *)
	{dataField,Sequence@@unitsAndMagnitudes[data],samplesIn,Null,{},{}}
];

(* Default Packet Input *)
resolveSingleInput[pkt:PacketP[],safeOps_,refOption_,collectTestsBoolean_]:=Module[{dataField},
	(* Get the default field to search for data in the object *)
	dataField=defaultPeakData[pkt,safeReferenceField@Lookup[safeOps,ReferenceField]];

	(* Return resolved inputs *)
	{dataField,Sequence@@unitsAndMagnitudes[Lookup[pkt,dataField]],Lookup[pkt,SamplesIn,{}],Null,{},{}}
];


(******************************************)
(*** Helper functions and lookup tables ***)
(******************************************)

(* Slice 3D Chromatography Data *)
sliceChromatogram3D[unit3D_, data3D_, wavelengthOps_, minWavelength_]:=Module[
	{allWavelengths, wavelength, wlPositions, selectedData},

	(* Slice all wavelengths out of the 3D chromatography data *)
	(* make it unitless in all cases to be able to extract positions correctly *)
	allWavelengths = Unitless[data3D[[;;,2]]];

	(* Resolve the wavelength *)
	wavelength = Switch[wavelengthOps,
		(* Strip units if provided in nanometers *)
		UnitsP[Nanometer], Unitless[wavelengthOps, unit3D[[2]]],
		(* Overload for AnalyzePeaks App *)
		_Integer, wavelengthOps,
		(* Default: use the minimum wavelength *)
		_, Unitless[minWavelength, unit3D[[2]]]
	];

	(* Use Position + Extract to slice datas *)
	wlPositions = Position[Round[allWavelengths], wavelength];
	selectedData = Extract[data3D, wlPositions];

	(* Throw an error if no data was selected *)
	If[MatchQ[selectedData,{}],
		Message[Error::UnrecognizedWavelength];
		Message[Error::InvalidOption,Wavelength];
		Return[{$Failed, $Failed}]
	];

	(* Return the sliced data, formatted to be a list of {x,y} data points, and restore the units of the wavelength *)
	{
		{unit3D[[{1,3}]],Transpose[Transpose[selectedData][[{1,3}]]]},
		wavelength*unit3D[[2]]
	}
];

(* Overload to pass Links, Object references, and Packets to just the object type *)
defaultPeakData[in:LinkP[],rest___]:=defaultPeakData[in[Object],rest];
defaultPeakData[in:ObjectReferenceP[],rest___]:=defaultPeakData[in[Type],rest];
defaultPeakData[in:PacketP[],rest___]:=defaultPeakData[in[Type],rest];

(* If ReferenceField option is Automatic, use lookup table typeToPeaksFields to determine default field *)
defaultPeakData[type:TypeP[],Automatic]:=With[
	{defaultPeakFields=LegacySLL`Private`typeToPeaksFields[type]},
	If[defaultPeakFields=!={},First[defaultPeakFields],{}]
];

(* If ReferenceField option was supplied, check that it is valid and use the default field if it is not *)
defaultPeakData[type:TypeP[],userField_] := With[
	{defaultPeakFields=LegacySLL`Private`typeToPeaksFields[type]},
	If[!MemberQ[defaultPeakFields,userField],
		Message[Warning::UnrecognizedPeaksField];First[defaultPeakFields],
		userField
	]
];

(* Make sure that reference field has the correct format *)
safeReferenceField[x:Automatic|_Symbol]:=x;
safeReferenceField[x_]:=Last[x];


(* ::Subsubsection::Closed:: *)
(*resolveAnalyzePeaksImage*)


resolveAnalyzePeaksImage[obj:ObjectP[Object[Data,PAGE]]]:=ImageRotate[Download[obj, OptimalLaneImage]];
resolveAnalyzePeaksImage[_]:=Null;


(* ::Subsubsection::Closed:: *)
(*resolveAnalyzePeaksListInput*)


resolveAnalyzePeaksListInput[in:ObjectReferenceP[peakProtocolTypes]]:=Download[in, Data];
resolveAnalyzePeaksListInput[in:PacketP[peakProtocolTypes]]:=Download[Lookup[in,Data],Object];
resolveAnalyzePeaksListInput[in_List]:=in;


(* ::Subsection::Closed:: *)
(*resolveAnalyzePeaksOptions*)

DefineOptions[resolveAnalyzePeaksOptions,
	Options :> {
		{Output -> Result, ListableP[Result | Tests], "Indicates the return value of the function."}
	}
];

(* Resolve all options which do not require identification of peaks *)
resolveAnalyzePeaksOptions[rawData_, listedData_, xyUnits_, refField_, wavelength_, sliceOps_, combinedOptions_, safeOptions_, ops: OptionsPattern[resolveAnalyzePeaksOptions]] := Module[
	{output, listedOutput, collectTestsBoolean, messagesBoolean, resolvedOptions, tests},

	(* From resolveTacoPreparationOptions's options, get Output value *)
	output = OptionDefault[OptionValue[Output]];
	listedOutput = ToList[output];
	collectTestsBoolean = MemberQ[listedOutput, Tests];
	messagesBoolean = !collectTestsBoolean;

	{resolvedOptions,tests}=Transpose@MapThread[
		resolveAnalyzePeaksOptionsSingle[#1,#2,#3,#4,#5,#6,combinedOptions,safeOptions,collectTestsBoolean,#7]&,
		{rawData,listedData,xyUnits,refField,wavelength,sliceOps,Range[Length[wavelength]]}
	];

	output /. {Tests -> Flatten[tests], Result -> resolvedOptions}
];

(* Handle the case where a single data object resolves multiple reference fields *)
resolveAnalyzePeaksOptionsSingle[xySets:{CoordinatesP..}, in_, xyUnits_, refFields:{_Symbol..}, wavelengths_, sliceOps_, combinedOps_, safeOps_, collectTestsBoolean_, index_] := Module[
	{resolvedOps,tests,updatedOps},

	(* Split up the input when there are multiple reference fields for a single input *)
	{resolvedOps,tests}=Transpose@MapThread[
		resolveAnalyzePeaksOptionsSingle[#1,in,#2,#3,#4,#5,combinedOps,safeOps,collectTestsBoolean,index]&,
		{xySets,xyUnits,refFields,wavelengths,sliceOps}
	];

	(* Return the paired options and tests as a sequence *)
	Sequence@@MapThread[
		{#1,#2}&,
		{resolvedOps,tests}
	]
];

(* Single overload *)
resolveAnalyzePeaksOptionsSingle[xy: CoordinatesP, in_, {xUnit_, yUnit_}, refField_, wavelength_, sliceOps_, combinedOptions_, safeOptions_, collectTestsBoolean_, index_] := Module[
	{
		domains, domainTests, numberOfZones, paddedOptions, zoneBounds, resolvedZoneOptions, paddedOptionsUnitless, xyZones, name, nameTestDescription, nameTest,
		dataQuality, mergedZoneOptions, dataType, resolvedOptions, assignmentsRaw,relativeLabelsQ,assignmentsResolved, assignmentsTests, excludeTests,includes, excludes, blanks,bfw,
		labelsRaw, labels, userTemplateAssignmentTolerance, templateAssignmentTolerance, assignmentRawUnits, assignmentUnitChecks, assignmentIncompatibleUnits,
		safeConvert,peakFields,baselineFunction,peakPositions,defaultLabels,manualRanges,manualPositions,manualOverlapQ,manualPosInBoundsQs,invalidPosIndices,
		parentPeaksRaw,parentPeaksProcessed,parentPeaks,areas,centers,parentIndex,parentIndexList,
		mostlyResolvedOptions,templateRules,resolvedPeakType,peakSplittingOptions,slicingOptions,manualOptions
	},

	(* Resolve the data type of the input *)
	dataType=If[ObjectQ[in],in[Type], Null];
	dataQuality=Null;

	(*
		first resolve Domains to get number of zones
	*)
	domains = resolvePeaksDomains[takeOptionByIndexDomain[Lookup[combinedOptions,Domain],index],xUnit,xy,dataType];
	domainTests = peaksTestOrNull[Domain, collectTestsBoolean, "Domains are valid intervals with left bound smaller than right bound.", AllTrue[domains, #[[1]] <= #[[2]] &]];
	numberOfZones = Length[domains];

	(*
		pad all threhold options to match number of zones
		these look like { {A->1,B->2,..}, {A->3,B->4...}, ..}
		instead of { A->{1,3}, B->{2,4},... }
		so it's easier to get all per zone. they get merged later into one list
	*)
	paddedOptions = Transpose[Map[
		padPeaksOption[#,numberOfZones,takeOptionByIndex[Lookup[combinedOptions,#], index]]&,
		{AbsoluteThreshold,RelativeThreshold,WidthThreshold,AreaThreshold,ConsolidateWidth,ConsolidateHeight,EdgeFraction,SmoothingRadius}
	]];

	(* strip units off everything *)
	paddedOptionsUnitless = Map[
		peakOptionUnitless[#,{xUnit,yUnit}]&,
		paddedOptions,
		{2}
	];

	(* resolve each option in each zone *)
	(* data points in each zone *)
	xyZones = Map[
		Quiet[processDataForPeakPicking[xy, #]]&,
		domains
	];

	(* coordinate bounds for each zone *)
	zoneBounds = MapThread[
		Function[{zoneData,domain},
			(* Try to get the coordinate bounds {{xmin,xmax},{ymin,ymax}} from our data. *)
			coordinateBounds=CoordinateBounds[zoneData];

			(* Were we unable to get coordinate bounds? (Potentially because there are no points in this domain.) *)
			(* Then set the ymin and ymax to zero. *)
			If[MatchQ[coordinateBounds,{}],
				{domain,{0,0}},
				coordinateBounds
			]
		],
		{xyZones,domains}
	];

	(* map over zones *)
	resolvedZoneOptions = MapThread[
		resolvePeaksZoneOptions[#1,{xUnit,yUnit}, #2, dataType, dataQuality, #3]&,
		{xyZones, zoneBounds, paddedOptionsUnitless}
	];

	(* merge options sets across zone into one list, e.g.  { A->{1,3}, B->{2,4},... } *)
	mergedZoneOptions = Normal[Merge[resolvedZoneOptions, Identity]];

	(* Pull assignments from non-template option sets. Template resolution occurs in computeRelativePeaksFields *)
	assignmentsRaw = takeOptionByIndexPeakAssignments[Lookup[combinedOptions,PeakAssignments],index];

	(* List of all units appearing in the positions and tolerances of the PeakAssignmentsOption *)
	assignmentRawUnits=Which[
		(* No units if option is not specified *)
		MatchQ[assignmentsRaw,Automatic|{}|Null],{},
		(* Span units for maximum peak in range spec *)
		MatchQ[assignmentsRaw,{{_Span,_}..}],Units[Flatten@(List@@@Part[assignmentsRaw,All,1])],
		(* Units of position and tolerance for pos,model,tol specs *)
		True,Units[Flatten@Part[assignmentsRaw,All,{1,3}]]
	];

	(* True if relative assignments should be used *)
	relativeLabelsQ=MemberQ[DeleteDuplicates[assignmentRawUnits],(1 RRT)];

	(* Throw an error if both absolute and relative labels are being used *)
	If[relativeLabelsQ&&CountDistinct[assignmentRawUnits]>1,
		Message[Error::MixedAssignment];
		Message[Error::InvalidOption,PeakAssignments];
	];

	(* Check that all units in assignmentsRaw are compatible with the resolved xUnit *)
	assignmentUnitChecks=Map[
		(CompatibleUnitQ[#,xUnit]||MatchQ[#,1])&,
		assignmentRawUnits
	];

	(* A list of all incompatible units in assignmentsRaw, with duplicates removed *)
	assignmentIncompatibleUnits=DeleteDuplicates@Part[
		assignmentRawUnits,
		Flatten@Position[assignmentUnitChecks,False]
	];

	(* Throw an error if any of the units in PeakAssignments are incompatible *)
	If[Not[And@@assignmentUnitChecks]&&Not[relativeLabelsQ],
		Message[Error::IncompatibleUnits,assignmentIncompatibleUnits,PeakAssignments,xUnit,"resolved x-units"];
		Message[Error::InvalidOption,PeakAssignments];
	];

	(* safeConvert convert units if val has compatible units or is dimensionless, otherwise returns the input unchanged. *)
	safeConvert[val_,unit_]:=Which[
		MatchQ[val,Span[NumericP,NumericP]],(#*unit)&/@val,
		MatchQ[Units[val],1],Quantity[val,unit],
		CompatibleUnitQ[val,unit],N@Convert[val,unit],
		True,val
	];

	(* Check/convert the units of the PeakAssignments option position and tolerance *)
	{assignmentsResolved,assignmentsTests}=Which[
		(* Default/automatic assignment resolves to nothing *)
		MatchQ[assignmentsRaw,Automatic|{}|Null],
			{
				{},
				Null
			},

		(* Assignments are specified as range, model*)
		MatchQ[assignmentsRaw,{{_Span,_}..}],
			{
				Map[
					{safeConvert[First[#],xUnit],Last[#]}&,
					assignmentsRaw
				],
				peaksTestOrNull[
					PeakAssignments,
					collectTestsBoolean,
					"Peak should be assigned to an object that exists in the database.",
					AllTrue[Last/@assignmentsRaw,databaseMemberQMemo[#]&]
				]
			},

		(* If labels are provided as a valid list of {position, model, tolerance}, convert units as needed *)
		True,
			{
				MapThread[
					Function[{pos,model,tol},
						{
							safeConvert[pos,xUnit],
							model,
							safeConvert[tol,xUnit]
						}
					],
					Transpose[assignmentsRaw]
				],
				peaksTestOrNull[
					PeakAssignments,
					collectTestsBoolean,
					"Peak should be assigned to an object that exists in the database.",
					AllTrue[#[[2]]&/@assignmentsRaw,databaseMemberQMemo[#]&]
				]
			}
	];

	(* Resolve the exclude and include options *)
	excludeTests = Test[
		"Exclude and Include does not include same point(s).",
		MatchQ[Intersection @@ Lookup[combinedOptions, {Include, Exclude}], {}],
		True
	];

	If[
		!Or[collectTestsBoolean, MatchQ[Intersection @@ Lookup[combinedOptions, {Include, Exclude}], {}]],
		Message[Warning::ExcludeOverwriteInclude]
	];

	excludes = takeOptionByIndex[Lookup[combinedOptions, Exclude], index];
	includes = takeOptionByIndex[Lookup[combinedOptions, Include], index];

	blanks = resolveBlankPeaksOption[Lookup[combinedOptions, BlankPeaks], refField];

	(* BaselineFeatureWidth *)
	bfw = If[Lookup[combinedOptions,Baseline]===DomainNonlinear,
		With[{bfwOption = Lookup[combinedOptions,BaselineFeatureWidth]},
			Switch[bfwOption,
				(* default to 7.5% of data size *)
				Automatic|Null, Ceiling[(xy[[-1,1]]-xy[[1,1]])*0.2],
				_?NumericQ, bfwOption,
				_Quantity, Unitless[bfwOption,xUnit]
			]
		],
		Null
	];

	(* template alignment threshold *)
	userTemplateAssignmentTolerance = Lookup[combinedOptions,TemplateAssignmentTolerance];

	(* Resolve the user-supplied value *)
	templateAssignmentTolerance=Switch[userTemplateAssignmentTolerance,
		(* automatic resolution: 1% of total data width if template provided, Null otherwise *)
		Automatic,
		If[MatchQ[Lookup[combinedOptions,Template],Null],
			Null,
			0.01*MinMax[xy[[;;,1]]].{-1,1}
		],

		(* If provided as Null, return Null *)
		Null,
		Null,

		(* use given value *)
		_?NumericQ,
		userTemplateAssignmentTolerance,

		(* strip units and use given value *)
		UnitsP[],
		Unitless[userTemplateAssignmentTolerance,xUnit]
	];

	(* --- Check if Name existed in DB --- *)
	name = Lookup[combinedOptions, Name];
	nameTestDescription="Check if the given Name already existed in the database:";
	nameTest = peaksTestOrNull[Name, collectTestsBoolean, nameTestDescription,
		NullQ[name] || Length[Search[Object[Analysis, Peaks], Name=name]] == 0];

	(* Get user value, but check if extra list on options. *)
	labelsRaw=If[
		MatchQ[
			Lookup[safeOptions, PeakLabels],
			ReleaseHold[SelectFirst[OptionDefinition[AnalyzePeaks], (#["OptionName"] === "PeakLabels") &]["SingletonPattern"]]
		],
		Lookup[safeOptions, PeakLabels],
		Lookup[safeOptions, PeakLabels][[index]]
	];

	(* Get user value, but check if extra list on options. *)
	parentPeaksRaw=If[
		MatchQ[
			Lookup[safeOptions, ParentPeaks],
			ReleaseHold[SelectFirst[OptionDefinition[AnalyzePeaks], (#["OptionName"] === "ParentPeaks") &]["SingletonPattern"]]
		],
		Lookup[safeOptions, ParentPeaks],
		Lookup[safeOptions, ParentPeaks][[index]]
	];

	(* If any integer string were provided in parent peaks, convert them into Integers *)
	parentPeaksProcessed=parentPeaksRaw/.{intString_?(MatchQ[ToExpression[#],_Integer]&):>ToExpression[intString]};

	(* Resolve the PeakType option. *)
	resolvedPeakType=If[MatchQ[Lookup[combinedOptions,PeakType],Automatic],
		Which[
			MatchQ[Lookup[combinedOptions,ManualPeakRanges], {_Span...}]||MatchQ[Lookup[combinedOptions,ManualPeakPositions], {NumericP...}],Manual,
			MatchQ[in,ObjectP[Object[Data,NMR]]],NMR,
			MatchQ[in,ObjectP[{Object[Data,Chromatography],Object[Data,ChromatographyMassSpectra]}]],Chromatography,
			True,Generic
		],
		Lookup[combinedOptions,PeakType]
	];

	(* Throw a warning if the input data does not have units of PPM *)
	If[MatchQ[resolvedPeakType,NMR]&&MatchQ[xUnit,Except[PPM]],
		Message[Warning::SplittingIgnoreUnits,xUnit];
	];

	(* Throw a hard error if the domain option is set when manual peak selection is used. *)
	If[MatchQ[resolvedPeakType,Manual]&&!MatchQ[Lookup[combinedOptions,Domain],Automatic|Null],
		Message[Error::DomainInvalidForManual];
		Message[Error::InvalidOption, Domain];
		Return[{$Failed,{}}];
	];

	(* Pre-resolved values of the manual range and position options *)
	manualPositions = Lookup[combinedOptions, ManualPeakPositions];
	manualRanges = Lookup[combinedOptions, ManualPeakRanges]/.{
		If[MatchQ[manualPositions, {NumericP...}],
			Null->{},
			Nothing
		]
	};

	(* Throw a hard error if the manual peak options are both specified but of different lengths *)
	If[MatchQ[resolvedPeakType,Manual]&&MatchQ[{manualRanges,manualPositions},{_List,_List}]&&Length[manualRanges]!=Length[manualPositions],
		Message[Error::InvalidManualOptionLengths, Length[manualRanges], Length[manualPositions]];
		Message[Error::InvalidOption, ManualPeakPositions];
		Return[{$Failed,{}}];
	];

	(* If manual ranges were provided, check if any of them overlap *)
	manualOverlapQ = If[MatchQ[resolvedPeakType,Manual]&&MatchQ[manualRanges,{_Span...}]&&Length[manualRanges]>1,
		And@@Map[
			overlappingRangesQ[#[[1]],#[[2]]]&,
			(* Map over adjacent pairs of sorted intervals *)
			Partition[List@@@SortBy[manualRanges,First], 2, 1]
		],
		False
	];

	(* Hard error if manual ranges were specified and overlapping *)
	If[manualOverlapQ,
		Message[Error::InvalidManualRanges,manualRanges];
		Message[Error::InvalidOption, ManualPeakRanges];
		Return[{$Failed,{}}];
	];

	(* For each manual position, make sure it lies within its index-matched manual range *)
	manualPosInBoundsQs = If[MatchQ[resolvedPeakType,Manual]&&MatchQ[manualPositions,{NumericP..}],
		MapThread[
			Function[{rg,pos},
				(pos >= First[rg]) && (pos <= Last[rg])
			],
			{manualRanges, manualPositions}
		],
		Repeat[True,Length[manualRanges]]
	];

	(* Indices of any invalid positions *)
	invalidPosIndices = Flatten@Position[manualPosInBoundsQs, False];

	(* Hard error if manual ranges were specified and overlapping *)
	If[Length[invalidPosIndices]>0,
		Message[Error::InvalidManualPositions,Part[manualPositions, invalidPosIndices], Part[manualRanges, invalidPosIndices]];
		Message[Error::InvalidOption, ManualPeakPositions];
		Return[{$Failed,{}}];
	];

	(* Resolve the RelativeLabeling option *)
	resolvedRelativeLabeling=If[MatchQ[Lookup[combinedOptions,RelativeLabeling],Automatic],
		Which[
			(* Un-hide the option but refault to false if chromatography data *)
			MatchQ[resolvedPeakType,Chromatography],False,
			(* Given CESDS data, default relative labeling to True *)
			MatchQ[refField,ProcessedUVAbsorbanceData],True,
			(* Otherwise, hide this option *)
			True,Null
		],
		Lookup[combinedOptions,RelativeLabeling]
	];

	(* Warn the user if RelativeLabeling was requested, but is unavailable for the selected analysis type *)
	If[MatchQ[Lookup[combinedOptions,RelativeLabeling],True]&&MatchQ[resolvedPeakType,Except[Chromatography|Generic]],
		Message[Warning::OptionUnavailable,RelativeLabeling,resolvedPeakType];
	];

	(* Resolve options for NMR peak splitting algorithm *)
	peakSplittingOptions=If[MatchQ[resolvedPeakType,NMR],
		(* Resolve options if PeakType = NMR *)
		resolvePeakSplittingOptions[in,combinedOptions],
		(* Set all peak splitting options to Null if PeakType is not NMR *)
		Select[combinedOptions,
			MemberQ[
				{
					OperatingFrequency,Nucleus,DeuteratedSolvent,KnownSpecies,MaximumJSplitting,
					PeakGroupDomains,PeakIntegralNormalizationGroup,PeakGroupMultiplicity,
					SplittingAssignments,SplittingSpacingTolerance,SplittingRelativeIntegralTolerance
				},
				First[#]
			]&
		]/.{Automatic->Null}
	];

	(* Options from slicing 3D data/input resolution *)
	slicingOptions=If[MatchQ[sliceOps,{}],
		(* Input was 2D/did not use slicing *)
		{
			DataSliceDimension->Null,
			DataSlice->Null,
			SliceReductionFunction->Null,
			SliceReferencePeaks->Null
		},
		sliceOps
	];

  (* Options for manual peak selection *)
  manualOptions=If[MatchQ[resolvedPeakType,Manual],
		(* Resolution is handled later *)
		{},
		(* Null out the Manual options if peak type is not Manual *)
		{
			ManualPeakRanges->Null,
			ManualPeakPositions->Null
    }
	];

	(* This is the set of options we can resolve prior to identifying peaks *)
	mostlyResolvedOptions = ReplaceRule[
		combinedOptions,
		Join[
			mergedZoneOptions,
			peakSplittingOptions,
			slicingOptions,
      manualOptions,
			{
				Domain -> domains,
				PeakAssignments -> assignmentsResolved,
				PeakLabels -> labelsRaw,
				ParentPeaks -> parentPeaksProcessed,
				ReferenceField -> refField,
				Wavelength -> wavelength,
				Include -> includes,
				Exclude -> excludes,
				BlankPeaks -> blanks,
				BaselineFeatureWidth -> bfw,
				TemplateAssignmentTolerance->templateAssignmentTolerance,
				PeakType->resolvedPeakType,
				RelativeLabeling->resolvedRelativeLabeling
			}
		]
	];

	(* Return the mostly resolved options *)
	{mostlyResolvedOptions, Cases[{domainTests, assignmentsTests, excludeTests}, Except[Null]]}

];


(* Resolve all options required for NMR peak-splitting analysis which do not require peak identification. *)
resolvePeakSplittingOptions[in_,combinedOps_]:=Module[
	{
		resolutionSuccessQ,knownSpeciesQ,resolvedKnownSpecies,resolvedKnownModels,
		validDomainsQ,inputOpFreq,inputNucleus,resolvedOpFreq,resolvedNucleus,
		defaultNMRSolvent,resolvedNMRSolvent,resolvedNMRSolventPeak,
		resolvedMaxJSplitting,resolvedSpacingTolerance,resolvedIntegralTolerance,
		nucleusAtomType,splitAssignmentNuclei,correctAssignmentNucleiQ
	},

	(* Boolean tracks if there have been errors in option resolution *)
	resolutionSuccessQ=True;

	(* True if KnownSpecies option was supplied *)
	knownSpeciesQ=MatchQ[Lookup[combinedOps,KnownSpecies],Except[{}|Null]];

	(* Resolve the KnownSpecies option *)
	{resolvedKnownSpecies,resolvedKnownModels}=If[knownSpeciesQ,
		Transpose@Map[
			If[MatchQ[#,ObjectP[Model[Molecule]]],
				{#[Molecule],#},
				{#,None}
			]&,
			Lookup[combinedOps,KnownSpecies]
		],
		{{},{}}
	];

	(* If the PeakGroupDomains option has been specified, then check it is a valid list of spans. *)
	validDomainsQ=If[MatchQ[Lookup[combinedOps,PeakGroupDomains],Automatic],
		True,
		validPeakDomainsQ[Lookup[combinedOps,PeakGroupDomains]]
	];

	(* Return an InvalidOption error if the supplied PeakGroupDomains are invalid *)
	If[!validDomainsQ,
		resolutionSuccessQ=False;
		Message[Error::InvalidSplittingDomains,Lookup[combinedOps,PeakGroupDomains]];
		Message[Error::InvalidOption,PeakGroupDomains];
	];

	(* Download experimental parameters from NMR data object. *)
	{inputOpFreq,inputNucleus}=If[MatchQ[in,ObjectP[Object[Data,NMR]]],
		Download[in,{Frequency,Nucleus}],
		{Null,Null}
	];

	(* If user-supplied operating frequency is Automatic, use object value. Else, take supplied value. *)
	resolvedOpFreq=If[Lookup[combinedOps,OperatingFrequency]===Automatic,
		inputOpFreq,
		Lookup[combinedOps,OperatingFrequency]
	];

	(* Throw an error if the operating frequency is Null/could not be resolved. *)
	If[MatchQ[resolvedOpFreq,Null],
		resolutionSuccessQ=False;
		Message[Error::ParameterNotFound,OperatingFrequency,Frequency,in];
		Message[Error::InvalidOption,OperatingFrequency];
	];

	(* Warn the user if the resolved operating frequency does not match the one which appears in the input *)
	If[!SameQ[inputOpFreq,resolvedOpFreq]&&MatchQ[inputOpFreq,Except[Null]],
		Message[Warning::ParameterMismatch,resolvedOpFreq,OperatingFrequency,inputOpFreq,in];
	];

	(* If user-supplied operating frequency is Automatic, use object value. Else, take supplied value. *)
	resolvedNucleus=If[Lookup[combinedOps,Nucleus]===Automatic,
		inputNucleus,
		Lookup[combinedOps,Nucleus]
	];

	(* Default value of NMR Solvent *)
	defaultNMRSolvent=If[MatchQ[in,ObjectP[Object[Data,NMR]]],
		Quiet[
			Download[in,SolventModel[Composition][[1,2]][Object]],
			{Download::FieldDoesntExist}
		]/.{$Failed->Null},
		Null
	];

	(* Resolve the NMR Solvent option *)
	resolvedNMRSolvent=If[MatchQ[Lookup[combinedOps,DeuteratedSolvent],Automatic],
		defaultNMRSolvent,
		Lookup[combinedOps,DeuteratedSolvent]
	]/.(Reverse/@solventModelsForNMR);

	(* Fetch the solvent peak information, if available, from the resolved NMR Solvent *)
	resolvedNMRSolventPeak=If[MatchQ[resolvedNMRSolvent,ObjectP[Model[Molecule]]],
		Download[resolvedNMRSolvent,NMRSolventPeak],
		Null
	]/.{{}|$Failed->Null};

	(* Throw an error if the operating frequency is Null/could not be resolved. *)
	If[MatchQ[resolvedNucleus,Null],
		resolutionSuccessQ=False;
		Message[Error::ParameterNotFound,Nucleus,Nucleus,in];
		Message[Error::InvalidOption,Nucleus];
	];

	(* Warn the user if the resolved operating frequency does not match the one which appears in the input *)
	If[!SameQ[inputNucleus,resolvedNucleus]&&MatchQ[inputNucleus,Except[Null]],
		Message[Warning::ParameterMismatch,resolvedNucleus,Nucleus,inputNucleus,in];
	];

	(* Strip the mass number from the desired nucleus *)
	nucleusAtomType=If[MatchQ[resolvedNucleus,Except[Null]],
		StringDelete[resolvedNucleus,DigitCharacter..],
		Null
	];

	(* A list of the nuclei appearing in each entry of splitAssignmentNuclei *)
	splitAssignmentNuclei=Map[
		If[MatchQ[#,Except[Unknown]],
			Part[AtomList[#[[2]]],Last[#]]/.{Atom[x_]:>x},
			{nucleusAtomType}
		]&,
		(Lookup[combinedOps,SplittingAssignments]/.{Automatic->{}})
	];

	(* Check that the SplittingAssignments option corresponds to nuclei which match option Nucleus *)
	correctAssignmentNucleiQ=MatchQ[#,{nucleusAtomType..}]&/@splitAssignmentNuclei;

	(* Return an error and stop if the Splitting Assignments do not correspond to the resolved nucleus *)
	If[Not[And@@correctAssignmentNucleiQ],
		resolutionSuccessQ=False;
		Message[Error::NucleusMismatch,resolvedNucleus];
		Message[Error::InvalidOption,SplittingAssignments];
	];

	(* Use a default value of 30 Hertz as an upper bound. TODO: Conditional on nucleus type. *)
	resolvedMaxJSplitting=If[Lookup[combinedOps,MaximumJSplitting]===Automatic,
		Quantity[30,Hertz],
		Lookup[combinedOps,MaximumJSplitting]
	];

	(* Use a default value for spacing tolerance if it was not specified *)
	resolvedSpacingTolerance=If[Lookup[combinedOps,SplittingSpacingTolerance]===Automatic,
		0.10,
		Lookup[combinedOps,SplittingSpacingTolerance]
	];

	(* Use a default value for the integral tolerance if it was not specified *)
	resolvedIntegralTolerance=If[Lookup[combinedOps,SplittingRelativeIntegralTolerance]===Automatic,
		1.0,
		Lookup[combinedOps,SplittingRelativeIntegralTolerance]
	];

	(* Return the resolved peak splitting options. *)
	{
		OperatingFrequency->resolvedOpFreq,
		Nucleus->resolvedNucleus,
		DeuteratedSolvent->{resolvedNMRSolvent,resolvedNMRSolventPeak},
		KnownSpecies->resolvedKnownSpecies,
		MaximumJSplitting->resolvedMaxJSplitting,
		SplittingSpacingTolerance->resolvedSpacingTolerance,
		SplittingRelativeIntegralTolerance->resolvedIntegralTolerance
	}
];

(* Check to see that a list of spans has no intersections, and each span is increasing *)
validPeakDomainsQ[pkDomains:{Span[UnitsP[PPM],UnitsP[PPM]]..}]:=Module[
	{increasingSpansQ,domainLists,domainIntervals,domainUnion,nonOverlappingQ},

	(* Check that each span is increasing *)
	increasingSpansQ=And[Sequence@@((First[#]<=Last[#])&/@pkDomains)];

	(* Strip units and convert to a list of lists *)
	domainLists=List@@@Unitless[pkDomains];

	(* Convert list of lists into a list of Intervals *)
	domainIntervals=Interval/@domainLists;

	(* Take the union of the list of intervals *)
	domainUnion=IntervalUnion[Sequence@@domainIntervals];

	(* If any of the intervals overlap, their union will be shorter than the input. *)
	nonOverlappingQ=(Length[pkDomains]===Length[domainUnion]);

	(* True if both conditions are satisfied, False otherwise *)
	And[increasingSpansQ,nonOverlappingQ]
];

(* False if the input did not match the pattern *)
validPeakDomainsQ[badFormat_]:=False;

(* Options which require peaks to have been identified already. *)
resolveRemainingOptionsSingle[mostlyResolvedOps_, myPeakFields_, myBaselineFunction_, originalOps_]:=Module[
	{
		parentTest,resolvedPeakType,defaultOptionValueQ,
		finalNMRSolvent,finalPeakLabels,finalParentPeaks,finalPeakAssignments,resolvedOptions
	},

	(* Test if the ParentPeaks object exists in PeaksLabels, PeakAssignments, or Template *)
	parentTest=Test[
		"Values in ParentPeaks option exist in PeaksLabels, PeakAssignments, or Template options:",
		Lookup[myPeakFields,ParentPeak],
		Except[$Failed]
	];

	(* The resolved peak type for this analysis *)
	resolvedPeakType=Lookup[mostlyResolvedOps,PeakType];

	(* True if the original option specification for symbol is Automatic, Null, or {} *)
	defaultOptionValueQ[sym_Symbol]:=MatchQ[Lookup[originalOps,sym,Null],(Automatic|Null|{})];

	(* Strip metadata from the NMR Solvent label *)
	finalNMRSolvent=If[resolvedPeakType===NMR,
		(First@Lookup[mostlyResolvedOps,DeuteratedSolvent])/.solventModelsForNMR,
		Null
	];

	(* Hide unused fields for NMR analysis, if these options were not specified in the function call *)
	finalPeakLabels=If[resolvedPeakType===NMR&&defaultOptionValueQ[PeakLabels],
		Null,
		Lookup[myPeakFields,PeakLabel]
	];
	finalParentPeaks=If[resolvedPeakType===NMR&&defaultOptionValueQ[ParentPeaks],
		Null,
		Lookup[myPeakFields,ParentPeak]/.{$Failed->Lookup[mostlyResolvedOps,ParentPeaks]}
	];
	finalPeakAssignments=If[resolvedPeakType===NMR&&defaultOptionValueQ[PeakAssignments],
		Null,
		Lookup[mostlyResolvedOps,PeakAssignments]
	];

	(* Append the PeakLabel and ParentPeak options from findPeaks to mostly resolved options *)
	resolvedOptions=If[MatchQ[myPeakFields,$Failed|Null],
		$Failed,
		ReplaceRule[
			mostlyResolvedOps,
			{
				DeuteratedSolvent->finalNMRSolvent,
				PeakLabels->finalPeakLabels,
				ParentPeaks->finalParentPeaks,
				PeakAssignments->finalPeakAssignments,
				PeakGroupDomains->Lookup[myPeakFields,PeakGroupDomains],
				PeakIntegralNormalizationGroup->Lookup[myPeakFields,PeakIntegralNormalizationGroup],
				PeakGroupMultiplicity->Lookup[myPeakFields,PeakGroupMultiplicity],
				SplittingAssignments->Lookup[myPeakFields,SplittingAssignments],
				If[MatchQ[Lookup[mostlyResolvedOps,PeakType],Manual],
					Sequence@@{
						ManualPeakRanges->MapThread[Span,Lookup[myPeakFields,{PeakRangeStart,PeakRangeEnd}]],
						ManualPeakPositions->Lookup[myPeakFields,Position]
					},
					Nothing
				]
			}
		]
	];

	(* Return the resolved options and associated tests *)
	{resolvedOptions,{parentTest}}
];


(* temporary, because can't easily un-map the resolve-options-tests right now *)
Clear[databaseMemberQMemo];
databaseMemberQMemo[obj_]:=databaseMemberQMemo[obj] = DatabaseMemberQ[obj];

Clear[downloadAssignmentNames];
downloadAssignmentNames[assignments_]:= downloadAssignmentNames[assignments] = Download[assignments,Name];

(*takeOptionByIndex takes an OptionValue and selects the value index matched to the object.
If the OptionValue is in collasped form, then it returns the OptionValue itself*)
takeOptionByIndexDomain[op: {({_List..} | Automatic)..}, index_] := op[[index]];
takeOptionByIndexDomain[op_, index_] := op;

takeOptionByIndexPeakAssignments[op: {({_List...})..}, index_] := op[[index]];
takeOptionByIndexPeakAssignments[op_,  index_] := op;

takeOptionByIndex[op: {_List..}, index_] := op[[index]];
takeOptionByIndex[op_, index_] := op;


peaksTestOrNull[opsName_, makeTest:BooleanP,description_,expression_]:=If[makeTest,
	Test[description,expression,True],
	If[TrueQ[expression],
		Null,
		If[MatchQ[opsName, Name], Message[Error::DuplicateName, "AnalyzePeaks object"]];
		Message[Error::InvalidOption, opsName]
	]
];


collapsePeaksOption[opName: (Template | Output | Upload), opVal_] := opName -> opVal[[1]];
collapsePeaksOption[opName_, opVal_] := Module[
	{unique},
	unique = DeleteDuplicates[opVal];
	If[MatchQ[Length[unique], 1],
		opName -> unique[[1]],
		opName -> opVal
	]
];


getPeakLabelsList[resolvedOpsList_]:=Module[{templateObjects,templateRules,objsToDownload,templatePackets,downloadedPackets},
	(* download all the template objects ahead of time and swap them back in *)
	templateObjects = FirstCase[Lookup[#,{Template,Options}],ObjectP[Object[Analysis,Peaks]]]& /@ resolvedOpsList;
	objsToDownload = DeleteDuplicates[Cases[templateObjects,ObjectP[Object[Analysis,Peaks]],{1}]];
	downloadedPackets = Download[objsToDownload,Packet[Position,PeakLabel,PeakAssignmentLibrary]];
	templatePackets = Replace[templateObjects,MapThread[Rule,{objsToDownload,downloadedPackets}],{1}];
	MapThread[getPeakLabels[#1,#2]&,{resolvedOpsList,templatePackets}]
];


getPeakLabels[resolvedOps_,templateInfo_] := Module[
	{templateRules,positions,labels,assignments,relativePos},

	(* association with position->Label pairs from template peak data *)
	(* this is used to align template labels with new peaks *)
	templateRules = If[MatchQ[templateInfo,ObjectP[Object[Analysis,Peaks]]],

		positions = Lookup[templateInfo,Position,{}];
		labels = Lookup[templateInfo,PeakLabel,{}];
		assignments = Lookup[templateInfo,PeakAssignmentLibrary,{}];

		If[!MatchQ[templateInfo,_Association],
			{<||>,<||>},
			{
				If[MatchQ[{positions,labels},{$Failed,$Failed}],
					{},
					Association[MapThread[Rule,{positions,labels}]]
				],
				If[MatchQ[{positions,assignments}, {$Failed, $Failed}],
					{},
					Association[Map[
						Lookup[#,Position]->Lookup[#,{Label,Model}]&,
						assignments
					]]
					(* Association[Map[Replace[#[[1]],Thread[Rule[labels,positions]]]->#&,assignments]] *)
				]
			}

		],
		{<||>,<||>}
	];

	(* delete any things with relative labels *)
	relativePos = Keys[Select[First[templateRules],	And[MatchQ[#, _String], StringMatchQ[#,"RRT"|"RMT" ~~ ___]] &]];
	templateRules = Function[assoc,
		KeyDrop[assoc,relativePos]
	]/@templateRules;

	templateRules
];


(* ::Subsection::Closed:: *)
(*findPeaks*)


(* Identify peaks, compute peak fields, and then compute derived quantities using peak fields. *)
findPeaks[xy_, templateRules_, resolvedOps_] := Module[
	{
		peakCoreFields,baselineFunction,peakCoreNoDuplicates,correctedPeakCoreFields,peakAllFields, baselineRanges
	},

	(* Fit a baseline, then identify peaks. For each peak, compute fields like position, height, area, width ranges, tangents, etc... *)
	{peakCoreFields,baselineFunction, baselineRanges}=computePeaksFields[xy,resolvedOps];

	(* Delete any peaks which have been doubly specified, i.e., have overlapping ranges *)
	peakCoreNoDuplicates=deletePeakDuplicates[peakCoreFields];

	(* If tangents have not been calculated, ensure that tangent fields are populated with empty lists *)
	correctedPeakCoreFields=If[MemberQ[Lookup[peakCoreNoDuplicates,TangentWidth],Null],
		ReplaceRule[peakCoreNoDuplicates,{TangentWidth->{},TangentWidthLines->{},TangentWidthLineRanges->{}}],
		peakCoreNoDuplicates
	];

	(* Compute derived fields (e.g. parent peaks, assignments, and multiplets) which require the initial peak identification. *)
	peakAllFields=computeDerivedFields[correctedPeakCoreFields, xy, templateRules, resolvedOps];

	{peakAllFields,baselineFunction, baselineRanges}
];


(* ::Subsection::Closed:: *)
(*analyzePeaksResult*)


analyzePeaksResult[in_, rawData_, xyUnits_, peakPacket_, resolvedOps_] := Module[
	{cleanPacket, secondaryPacket, uploadedPacket},

	(* For cleaner lookups *)
	cleanPacket=stripAppendReplaceKeyHeads@peakPacket;

	(* Any secondary fields which should be uploaded by this peaks analysis *)
	secondaryPacket = Which[
		(* SDS Data - Update the *)
		MatchQ[in,ObjectP[Object[Data,CapillaryGelElectrophoresisSDS]]],
			<|
				Object->Download[in,Object],
				RelativeMigrationData->With[
					{
						parentPeakPosition=First@Part[
							Lookup[cleanPacket,Position,{1}],
							FirstPosition[
								Lookup[cleanPacket,PeakLabel],
								FirstOrDefault[Lookup[cleanPacket,ParentPeak]]
							]/.{_Missing->{1}}
						]
					},
					{#[[1]]/parentPeakPosition,#[[2]]}&/@rawData
				]
			|>,

		(* Default is nothing *)
		True,Nothing
	];

	(* Use helper function to upload single peak packet. Must pass as list. *)
	uploadedPacket=Check[
		Quiet[Part[uploadAnalyzePackets[{{{peakPacket},{secondaryPacket}}}],1,1,1], {Upload::Warning}],
		$Failed
	];

	(* Return either the packet or the uploaded object, depending on the value of the Upload option *)
	If[Lookup[resolvedOps,Upload]&&!MatchQ[uploadedPacket,$Failed],
		uploadedPacket[Object],
		uploadedPacket
	]
];


(* ::Subsection:: *)
(*Resolutions*)


(* ::Subsubsection::Closed:: *)
(*resolvePeaksDomains*)


(*
	resolve Domain option.  strip units
*)

resolvePeaksDomains[val:_?NumericQ;;_?NumericQ|{_?NumericQ;;_?NumericQ..}, xUnit_, xy_, dataType_]:=
	Switch[Head[val],
		Span, {{val[[1]], val[[2]]}},
		List, {#[[1]], #[[2]]}&/@val
];


resolvePeaksDomains[val:{{_?NumericQ, _?NumericQ..}..}, xUnit_, xy_, dataType_]:=val;
resolvePeaksDomains[val:{_?NumericQ, _?NumericQ..}, xUnit_, xy_, dataType_]:={val};

resolvePeaksDomains[val:UnitsP[];;UnitsP[] | {UnitsP[];;UnitsP[]..}, xUnit_, xy_, dataType_]:=Module[{tmpval},
	tmpval = Switch[Head[val],
		Span, {{val[[1]], val[[2]]}},
		List, {#[[1]], #[[2]]}&/@val
	];
	Unitless[tmpval,xUnit]
];

resolvePeaksDomains[Automatic,xUnit_,xy_,dataType:Object[Data,Chromatography]]:=Module[{xmin,xmax},
	{xmin,xmax}=MinMax[xy[[;;,1]]];
	{{If[xmax<5,xmin,xmin + 0.05 * (xmax - xmin)],Min[{xmax,50}]}}
];
resolvePeaksDomains[Automatic,xUnit_,xy_,dataType_] := {MinMax[xy[[;;,1]]]};


(* ::Subsubsection::Closed:: *)
(*padPeaksOption*)


(*
	Pad each option so there's one RULE per zone, e.g.
	 { {A->1,B->2,..}, {A->3,B->4...}, ..}
*)
(* single value - repeat for each zone *)
padPeaksOption[optionName : Except[Domain], numZones_,
	value : Except[_List]] := Table[optionName->value, numZones];
padPeaksOption[Domain, numZones_,
	value : {Except[_List], Except[_List]}] := Table[optionName->value, numZones];
(* list value, pad right *)
padPeaksOption[optionName_, numZones_, values_List] :=
		Map[Rule[optionName,#]&,PadRight[values, numZones, Last[values]]];


(* ::Subsubsection::Closed:: *)
(*peakOptionUnitless*)


(*
	convert and strip units
	different options get converted to different things, depending on whether they apply to x or y
*)
peakOptionUnitless[Rule[op:(WidthThreshold | ConsolidateWidth |SmoothingRadius), value_Quantity], {xUnit_, yUnit_} ] := op->Unitless[value,xUnit];
peakOptionUnitless[Rule[op:(AbsoluteThreshold|RelativeThreshold | ConsolidateHeight), value_Quantity], {xUnit_, yUnit_}] := op->Unitless[value, yUnit];
peakOptionUnitless[Rule[op:(AreaThreshold), value_Quantity], {xUnit_, yUnit_}] := op->Unitless[value,xUnit*yUnit];
peakOptionUnitless[Rule[op_, value_], {xUnit_, yUnit_}]:= op->value;


(* ::Subsubsection::Closed:: *)
(*resolvePeaksZoneOptions*)


(*
	resolve all options for one zone.
	return list of rules
*)

(* map over each zone *)
resolvePeaksZoneOptions[xyZone_List,{xUnit_,yUnit_}, zoneBounds_List, dataType_, dataQuality_, zoneOptionsRules:{___Rule}]:=Module[{},
	Map[
		#->RoundReals[resolvePeaksZoneOptions[#,xyZone,{xUnit,yUnit},zoneBounds,dataType,dataQuality,Lookup[zoneOptionsRules,#,Automatic]],3]&,
		{AbsoluteThreshold,RelativeThreshold,WidthThreshold,AreaThreshold,ConsolidateWidth,ConsolidateHeight,EdgeFraction,SmoothingRadius}
	]

];

(*
	each option resolution looks like this:
		resolvePeaksZoneOptions[ optionName, zoneCoordinates, {xUnit, yUnit}, zoneBounds, dataType, dataQuality, value ]
*)

actualPercentP = _Quantity?PercentQ;

(* already have valid value that is NOT a percent *)
resolvePeaksZoneOptions[optionName_Symbol, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,	dataQuality_, val:Except[Automatic|actualPercentP]]:=val;

(*
	AbsoluteThreshold
*)
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Impurities", Automatic] :=ymin + (ymax - ymin) / 50;
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, MassSpectrometry]|Object[Data, ChromatographyMassSpectra],dataQuality_, Automatic] :=ymin + (ymax - ymin)/10;
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, Chromatography],dataQuality_, Automatic] :=ymin + (ymax - ymin)*.9;
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, TLC],dataQuality_, Automatic] :=ymin + (ymax - ymin)/25;
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, PAGE],dataQuality_, Automatic] :=ymin + (ymax - ymin)/25;
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, CapillaryGelElectrophoresisSDS], dataQuality_, Automatic]:=ymax/12.0;
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:_String|_Symbol, Automatic] :=ymin + (ymax - ymin) / 50;
(* percent *)
resolvePeaksZoneOptions[AbsoluteThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality_, val : actualPercentP] :=  ymin + (ymax - ymin)*Unitless[val, 1];


(*
	RelativeThreshold
*)
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Impurities", Automatic] :=(ymax - ymin) / 50;
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, MassSpectrometry]|Object[Data, ChromatographyMassSpectra],dataQuality_, Automatic] :=(ymax - ymin) / 10;
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, TLC],dataQuality_, Automatic] :=(ymax - ymin)/25;
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, PAGE],dataQuality_, Automatic] :=(ymax - ymin)/25;
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, CapillaryGelElectrophoresisSDS], dataQuality_, Automatic]:=ymax/25;
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:_String|_Symbol, Automatic] :=(ymax - ymin) / 50;
(* percent *)
resolvePeaksZoneOptions[RelativeThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality_, val : actualPercentP] := (ymax - ymin)*Unitless[val, 1];


(*
	WidthThreshold
*)
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Broad peaks", Automatic] :=  (xmax - xmin) / 30;
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Sharp peaks", Automatic] :=  (xmax - xmin) / 1000;
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,TLC],dataQuality_, Automatic] :=(xmax - xmin) / 100;
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,MassSpectrometry],dataQuality_, Automatic] :=(xmax - xmin) / 1500;
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,PAGE],dataQuality_, Automatic] :=(xmax - xmin) / 100;
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,NMR],dataQuality_, Automatic]:=(xmax-xmin)/2000;
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:_String|_Symbol, Automatic] :=  0.;
(* percent *)
resolvePeaksZoneOptions[WidthThreshold, xyZone_List, {xUnit_, yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}},dataType_, dataQuality_, val : actualPercentP] := xmax*Unitless[val, 1]/8.;


(*
	AreaThreshold
*)
resolvePeaksZoneOptions[AreaThreshold, xyZone_List, {xUnit_, yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, CapillaryGelElectrophoresisSDS], dataQuality_, Automatic]:=ymax*(xmax-xmin)/800.0;
resolvePeaksZoneOptions[AreaThreshold, xyZone_List, {xUnit_, yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}},dataType_, dataQuality:_String|_Symbol, Automatic] := 0;
(* percent *)
resolvePeaksZoneOptions[AreaThreshold,xyZone_List, {xUnit_, yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}},dataType_, dataQuality_, val : actualPercentP] := Module[
	{xData, yData, totalArea},
	{xData, yData} = Transpose[xyZone];
	totalArea =
			Total[MapThread[#1 * Mean[#2] &, {Differences[xData],
				Partition[yData, 2, 1]}]];
	totalArea * Unitless[val, 1]
];

(*
	ConsolidateWidth
*)
resolvePeaksZoneOptions[ConsolidateWidth, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality_, "Broad peaks"] :=  (xmax-xmin)/100;
resolvePeaksZoneOptions[ConsolidateWidth, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:_String|_Symbol, Automatic] :=  0;


(*
	ConsolidateHeight
*)
resolvePeaksZoneOptions[ConsolidateHeight, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality_, "Noisy"] :=  (ymax-ymin)/25;
resolvePeaksZoneOptions[ConsolidateHeight, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality_, "Broad peaks"] :=  (ymax-ymin)/25;
resolvePeaksZoneOptions[ConsolidateHeight, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality_, "Sharp peaks"] :=  0;
resolvePeaksZoneOptions[ConsolidateHeight, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,TLC],dataQuality_, Automatic] :=  (ymax-ymin)/50;
resolvePeaksZoneOptions[ConsolidateHeight, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,PAGE],dataQuality_, Automatic] :=  (ymax-ymin)/25;
resolvePeaksZoneOptions[ConsolidateHeight, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:_String|_Symbol, Automatic] :=  0;

(*
	EdgeFraction
*)
resolvePeaksZoneOptions[EdgeFraction, xyZone_List, {xUnit_, yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}},dataType_, dataQuality_, Automatic|_Symbol|_String] :=  0;


(*
	SmoothingRadius
*)
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Noisy", Automatic] := 3;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Broad peaks", Automatic] := 3;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Sharp peaks", Automatic] := 0;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:"Impurities", Automatic] := 1;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,Chromatography],dataQuality_, Automatic] :=  Min[5,Length[xyZone]];
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,PAGE],dataQuality_, Automatic] :=2;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data,TLC],dataQuality_, Automatic] :=2;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, Object[Data, FluorescenceSpectroscopy],dataQuality_, Automatic] :=3;
resolvePeaksZoneOptions[SmoothingRadius, xyZone_List, {xUnit_,yUnit_}, {{xmin_, xmax_}, {ymin_, ymax_}}, dataType_,dataQuality:_String|_Symbol, Automatic] := 0;


(* ::Subsubsection::Closed:: *)
(*processDataForPeakPicking*)


processDataForPeakPicking[rawData_,All]:=SortBy[rawData,First];
processDataForPeakPicking[rawData_,domain:{lower_?NumericQ,upper_?NumericQ}]:=
    SortBy[selectInclusiveMatrixPointsInsideRangeC[rawData,lower,upper],First];



(* ::Subsubsection::Closed:: *)
(*resolveBlankPeaksOption*)

resolveBlankPeaksOption[Automatic,ref:ObjectP[Object[Data, Chromatography]]] := Module[
	{pks},
	pks = Flatten[ref[BlankData][ChromatogramPeaksAnalyses]];
	If[MatchQ[pks, _List],
		Cases[pks, ObjectP[Object[Analysis, Peaks]]],
		Null
	]
];
resolveBlankPeaksOption[bks:ListableP[ObjectP[Object[Analysis, Peaks]]],_]:=ToList[bks];
resolveBlankPeaksOption[___] := Null;


(* ::Subsection::Closed:: *)
(*Core*)


(* ::Subsubsection::Closed:: *)
(*computePeaksFields*)


computePeaksFields[Null, _]:={Null,Null};
computePeaksFields[xy_, Null]:={Null,Null};
computePeaksFields[xy_, ops0_] := computePeaksFields[xy, ops0]=Module[
	{
		method, domains, includes, excludes, baseline, abss, rels, widths, consolWidths,
		consolGlobals, trims, smooths, areas, peakFieldsByZone, mergedPeaks, baselineFunctions,
		mergedBLF, ebgPar, bfw, manualRanges, manualPositions, skipTangentsBoolean, baselineRanges
	},

	(* Unpack option values *)
	{
		method, domains, includes, excludes, baseline, abss, rels,
		widths, consolWidths, consolGlobals, trims, smooths, areas,
		bfw, manualRanges, manualPositions, skipTangentsBoolean
	} = Lookup[ops0,{
		Method, Domain, Include, Exclude, Baseline, AbsoluteThreshold, RelativeThreshold,
		WidthThreshold, ConsolidateWidth, ConsolidateHeight, EdgeFraction, SmoothingRadius, AreaThreshold,
		BaselineFeatureWidth, ManualPeakRanges, ManualPeakPositions, SkipTangentFieldCalculation
	}];

	peakFieldsByZone = MapThread[
		Function[
			{domain,abs,rel,width,consolWidth,consolGlobal,trim,smooth,area},
			peaksOneDomain[
				xy,
				method,
				domain,
				includes,
				excludes,
				baseline,
				abs,
				rel,
				width,
				consolWidth,
				consolGlobal,
				trim,
				smooth,
				area,
				bfw,
				manualRanges,
				manualPositions,
				skipTangentsBoolean
			]
		],
		{domains, abss, rels, widths, consolWidths, consolGlobals, trims, smooths, areas}
	];

	(*Pull out values that will not go into the merged peaks field*)
	baselineFunctions = Lookup[peakFieldsByZone,BaselineFunction];
	baselineRanges = Lookup[peakFieldsByZone, BaselinePeakRanges];

	(*Remove the fields that will not go into the mergedpeaks field*)
	mergedPeaks = mergePeakParameters[DeleteCases[peakFieldsByZone,Rule[BaselineFunction,_]|Rule[BaselinePeakRanges, _],{2}]];

	mergedBLF = With[
		{fspec = Quiet[Simplify[Piecewise[MapThread[Function[{domain,ff},{ff[x],domain[[1]]<=x<=domain[[2]]}],{domains,baselineFunctions}],Indeterminate]]/.x->Slot[1],{Reduce::ratnz}]},
		Function[fspec]
	];

	{
		excludeBlank[Lookup[ops0, BlankPeaks], mergedPeaks],
		mergedBLF,
		baselineRanges
	}
];


excludeBlank[Null, pks_] := pks;
excludeBlank[blanks_, pks_] := Module[
	{bks, var = 0.1, ranges, pkNames, pkVals, excludeQ, excluded},

	bks = Transpose[Flatten /@ Transpose @ Download[blanks, {Position, PeakRangeStart, PeakRangeEnd}]];
	ranges = {#[[1]] - var * (#[[1]] - #[[2]]), #[[1]] + var * (#[[1]] + #[[3]])} & /@ bks;
	If[MatchQ[ranges, {}], Return[pks]];

	pkNames = First /@ pks;
	pkVals = Last /@ pks;
	excludeQ[pos_] := !AnyTrue[ranges, #[[1]] < pos[[1]] < #[[2]] &];

	excluded = Select[Transpose[pkVals], excludeQ];
	excluded = If[MatchQ[excluded, {}], Repeat[{}, Length[pkNames]], Transpose[excluded]];

	MapThread[#1 -> #2 &, {pkNames, excluded}]
];


(* ::Subsubsection::Closed:: *)
(*mergePeakParameters*)


mergePeakParameters[peakParameters_] := Module[{},
	If[MatchQ[peakParameters,Null],
		Null,
		Map[#[[1, 1]] -> Flatten[Join[#[[;;, 2]]], 1] &, Transpose[peakParameters]]
	]
];

(* ::Subsubsection::Closed:: *)
(*peaksOneDomain*)


peaksOneDomain[rawData_, method_, domain_, include_, exclude_, baseline_, abs_, rel_, width_, consolWidth_, consolHeight_, trim_, smooth_, area_, bfw_, mranges_, mpos_, skipTangentsBoolean_]:=Module[
	{dataPts, parameters, splitData},

	(* pre-processing dataPts *)
	dataPts = Quiet[processDataForPeakPicking[rawData,domain]];

	(* Split data points by derivative. If Manual peak ranges were provided, bypass this and use those instead *)
	splitData = If[MatchQ[mranges, {_Span...}],
		(* Split by manual range *)
		Map[
			Select[dataPts, Function[{xy}, First[xy] >= First[#] && First[xy] <= Last[#]]]&,
			mranges
		],
		partitionDataIntoPeaksDerivative[dataPts, include, abs, rel, width, consolWidth, consolHeight, trim, smooth, area]
	];

	(* remove things in exclude list *)
	splitData = Pick[splitData,Map[And@@Table[!And[#[[1,1]]<ex,#[[-1,1]]>ex],{ex,exclude}]&,splitData]];

	(* parameterize peaks *)
	parameters = getPeakParameters[dataPts, splitData, baseline, bfw, mpos, skipTangentsBoolean];

	parameters
];


(* ::Subsubsection::Closed:: *)
(*Derivative Method*)


(* DERIVATIVE *)
partitionDataIntoPeaksDerivative[{}, ___] := {{}, {}};
partitionDataIntoPeaksDerivative[rawData_, include_, abs_, rel_, width_, widthConsol_, heightConsol_, trim_, smooth_, area_] := Module[
	{rawDataSplit, includeDataSplit, dataSplit, debug},
	debug = False;

    (* split dataPts into peak sections *)
    rawDataSplit = splitData[rawData, smooth];
	If[debug===True,Print["init: ",Length[dataSplit]]];

    (* filter peaks *)
    dataSplit = filterSplitData[rawDataSplit, abs, rel, width, area];
	If[debug===True,Print["post filter: ",Length[dataSplit]]];

	(* add things in include list *)
	includeDataSplit = Pick[rawDataSplit,Map[Or@@Table[And[#[[1,1]]<in,#[[-1,1]]>in],{in,include}]&,rawDataSplit]];
	dataSplit = DeleteDuplicates[Join[dataSplit, includeDataSplit]];

	(* consolidate peaks *)
	dataSplit = consolidateSplitData[dataSplit,heightConsol,heightConsol,widthConsol];
	If[debug===True,Print["post consol: ",Length[dataSplit]]];

    (* Shrink partitions around peaks *)
	dataSplit = shrinkSections[dataSplit,trim];
	dataSplit
];


(* Split into section of increasing/decreasing *)
splitData[{{_?NumericQ,_?NumericQ}},___]:={};
splitData[dataPts_]:=splitData[dataPts,0];
splitData[dataRaw_,smooth_] := Module[
	{splits,lengths,positions,ranges,dataSplit,dataPts,partitioned},

	dataPts = gaussianSmooth1D[dataRaw, smooth];

	splits = Split[(#>=0)&/@Differences[dataPts[[All,2]]]]; (*  *)
	splits=ReplacePart[splits,1->Prepend[splits[[1]],True]];

	lengths = Length/@splits;

	positions = Accumulate[lengths];

	ranges = Which[
		Length[lengths]===1,
			{Range[1,Length[dataPts]]},
		dataPts[[2,2]]-dataPts[[1,2]]<0,  (* make sure to get peaks, and not troughs *)
		partitioned = Partition[positions[[1;;-1;;2]],2,1];
		If[Length[partitioned]>0,
			Range@@@partitioned,
			{}
		],
		True,
			Join[
				{Range[1,positions[[2]]]},
				Range@@@Partition[positions[[2;;-1;;2]],2,1]
			]
	];

	If[Length[ranges]>0 && ranges[[-1,1]]=!=Length[dataPts],
		ranges=Append[ranges,Range[ranges[[-1,-1]]+1,Length[dataPts]]]
	];

	ranges=DeleteCases[ranges,{}|{_Integer}|{_Integer,_Integer}];

	dataSplit = Map[dataRaw[[#,;;]]&,ranges];

	dataSplit

]/;Length[dataRaw]>1;


(* filter out non-peaks *)
filterSplitData[data0_, abs_, rel_, width_, area_] := Module[
	{dataPts,debug},
	debug=False;
	dataPts = N[data0];

	If[debug===True,Print["initial count: ",Length[dataPts]]];

	(* abs threshold *)
	dataPts = Select[dataPts,Max[#[[All,2]]]>=abs&];
	If[debug===True,Print["after abs filter: ",Length[dataPts]]];

	(* rel threshold *)
	dataPts = Select[dataPts,Max[#[[All,2]]]-Min[#[[All,2]]]>=rel&];
	If[debug===True,Print["after rel filter: ",Length[dataPts]]];

	(* width *)
	dataPts = Select[dataPts,Max[#[[All,1]]]-Min[#[[All,1]]]>=width&];
	If[debug===True,Print["After width filter: ",Length[dataPts]]];

	(* area *)
	dataPts = Select[dataPts,Total[(Most[#[[;;,2]]-Min[#[[;;,2]]]]+Rest[#[[;;,2]]-Min[#[[;;,2]]]])/2 * Differences[#[[;;,1]]]] >= area&];
	If[debug===True,Print["After area filter: ",Length[dataPts]]];

	dataPts
];


consolidateSplitData[splitData_,heightConsol_,absHeightConsol_,widthConsol_]:=Module[{out,ymax,leftRel,rightRel,maxRel,minRel,width,height,center},
	(* distance from a peak's max height to the height at its left edge *)
	leftRel[dat:{{__}..}]:=(Max[dat[[;;,2]]]-dat[[1,2]]);
	(* distance from a peak's max height to the height at its right edge *)
	rightRel[dat:{{_?NumericQ,_?NumericQ}..}]:=(Max[dat[[;;,2]]]-dat[[-1,2]]);
	(*  *)


	width[dat:{{___}..}]:=dat[[-1,1]]-dat[[1,1]];
	height[dat:{{___}..}]:=Max[dat[[;;,2]]];
	center[dat:{{___}..}]:=Pick[dat,dat[[;;,2]],height[dat]];
	out=splitData;
	ymax=Max[splitData[[;;,;;,2]]];
	(* consolidate from the left *)
	Table[
	    If[And[
	        (*Check if peaks are with two widths of each other*)
	        leftWidth     = out[[ix,-1,1]] - out[[ix,1,1]];
	        rightWidth    = out[[ix+1,-1,1]] - out[[ix+1,1,1]];
	        distanceApart = out[[ix+1,1,1]] - out[[ix,-1,1]];
	        2*Max[leftWidth, rightWidth]>distanceApart,
	        Or[
			(* If the height is under the consolidation height threshold *)
	        rightRel[out[[ix]]]<heightConsol,
			(* Or the width us under the consolidation width threshold *)
	        And[width[out[[ix]]]<=widthConsol,out[[ix,1,2]]<=out[[ix,-1,2]]]
	        ]],
	    out[[ix+1]]=Join[out[[ix]],out[[ix+1]]];
	    out[[ix]]=Null;
	],
	{ix,1,Length[out]-1}];
	out=DeleteCases[out,Null];
	(* consolidate from the right *)
	Table[
	    If[And[
			(*Check if peaks are with two widths of each other*)
	        leftWidth     = out[[ix-1,-1,1]] - out[[ix-1,1,1]];
	        rightWidth    = out[[ix,-1,1]] - out[[ix,1,1]];
	        distanceApart = out[[ix,1,1]] - out[[ix-1,-1,1]];
	        2*Max[leftWidth, rightWidth]>distanceApart,
	        Or[
			(* If the height is under the consolidation height threshold *)
	        leftRel[out[[ix]]]<heightConsol,
			(* Or the width us under the consolidation width threshold *)
	        And[width[out[[ix]]]<=widthConsol,out[[ix,1,2]]>=out[[ix,-1,2]]]
	        ]],
	    out[[ix-1]]=Join[out[[ix-1]],out[[ix]]];
	    out[[ix]]=Null;
	],
	{ix,Length[out],2,-1}];
	out=DeleteCases[out,Null];
	out
];



shrinkSections[{},___]:={};
shrinkSections[splitData_,0|0.]:=splitData;
shrinkSections[splitData:{{{_?NumericQ,_?NumericQ}..}..},coef_] :=shrinkSections[#,coef]&/@splitData;
shrinkSections[splitData:{{_?NumericQ,_?NumericQ}..},coef_] := Module[
	{threshold,peakPoint,grouped},
	threshold=(Max[splitData[[;;,2]]]-Min[splitData[[;;,2]]])*coef;
	If[threshold===0,Return[splitData]];
	grouped=SplitBy[splitData,#[[2]]>=(Min[splitData[[;;,2]]]+threshold)&];
	peakPoint=First[Pick[splitData,splitData[[;;,2]],Max[splitData[[;;,2]]]]];
	First[Select[grouped,MemberQ[#,peakPoint]&]]
];



(* ::Subsubsection::Closed:: *)
(*getPeakParameters*)


(* Get parameters from peaks *)
getPeakParameters[{},___]:={
		Position->{},
		Height->{},
		HalfHeightWidth->{},
		Area->{},
		PeakRangeStart->{},
		PeakRangeEnd->{},
		WidthRangeStart->{},
		WidthRangeEnd->{},
		BaselineIntercept->{},
		BaselineSlope->{},
		AsymmetryFactor->{},
		TailingFactor->{},
		TangentWidth -> {},
		TangentWidthLines -> {},
		TangentWidthLineRanges -> {},
		BaselinePeakRanges->{}
	};
getPeakParameters[dataPts_,dataSplit_,baseline_,bfw_,mpos_,skipTangentsBoolean_]:=Module[
	{
		heights,centers,widths,areas,maxes,peakRanges,widthRanges,return,baselineRules,
		alphas, asymmetryFactorRanges, asymmetryFactors, tailingFactorRanges, tailingFactors,
		tgStuff, peakRangesTrimmed, invalidPeakPositions, dataSplitTrimmed, baselineFunction
	},

	peakRanges = dataSplit[[;;,{1,-1},1]];
	baselineRules = calculateBaselineSpec[baseline, dataPts, dataSplit, peakRanges, bfw];
	baselineFunction = Lookup[baselineRules, BaselineFunction];

	(* trim points outside baseline regions before finding maxes, in case max point is at end and would get trimmed *)
	dataSplitTrimmed = MapThread[trimPeakOutsideBaseline[#1, baselineFunction] &, {dataSplit}];

	invalidPeakPositions = Position[dataSplitTrimmed, $Failed];

	(* Use maxima as peak centers. If manual positions were specified, override them *)
	If[MatchQ[mpos,{NumericP..}]&&Length[mpos]==Length[peakRanges],
		(* Override: Find y-coordinate of each manual position *)
		centers = mpos;
		maxes = MapThread[
			Function[{split, c},
				Part[MinimalBy[split, (First[#]-c)^2&], -1, -1]
			],
			{dataSplitTrimmed, centers}
		],
		(* Calculate maximum vals *)
		maxes = Map[If[MatchQ[#,$Failed],$Failed,Max[#[[All,2]]]]&, dataSplitTrimmed];
		centers = MapThread[ If[MatchQ[#1,$Failed],$Failed,First[Pick[#1[[;;,1]],#1[[;;,2]],#2]]]&, {dataSplitTrimmed,maxes}];
	];

	{dataSplitTrimmed, maxes, centers} =
     Map[Delete[#, invalidPeakPositions] &, {dataSplitTrimmed, maxes, centers}];

	peakRangesTrimmed = MinMax[#[[All, 1]]] & /@ dataSplitTrimmed;

	widthRanges = MapThread[getPeakWidthRanges[#1, #2] &, {dataSplitTrimmed, centers}];

	areas = MapThread[computePeakIntegral[#1,baselineFunction]&,{dataSplitTrimmed}];

	widths=Map[#.{-1,1}&,widthRanges];

	heights=With[{bf=baselineFunction},
		MapThread[#1-bf[#2]&,{maxes,centers}]
		];

	tgStuff=If[skipTangentsBoolean,
		Array[Null&,{Length[centers],3}],
		tgWidth[dataPts, peakRangesTrimmed[[;;,1]], widthRanges[[;;,1]], centers, widthRanges[[;;,2]], peakRangesTrimmed[[;;,2]], baselineFunction]
	];

	(* For each split of data corresponding to a peak, get the average spacing between data points *)
	(* This will be the minimum peak distance measurement, and prevents division by zero for the asymmetry and tailing factor calculations *)
	alphas = Map[Mean[Differences[#[[;;,1]]]]&, dataSplitTrimmed];

	(* Tailing factor calculation at 5% of max peak height *)
	tailingFactorRanges=MapThread[getPeakWidthRanges[#1,#2,0.05]&, {dataSplitTrimmed, centers}];
	tailingFactors=MapThread[
		If[#2!=First[#1],
			(* AB / 2AC, where A is left bound, B is the right bound, and C is the center *)
			#1.{-1,1} / (2*(#2-First[#1])),
			(* If center is at zero (AC = 0) smooth expression using (AB + dx)/2*(0 + dx) *)
			(#1.{-1,1}+#3) / (2*#3)
		]&,
		{tailingFactorRanges, centers, alphas}
	];

	(* Asymmetry factor calculation at 10% of max peak height *)
	asymmetryFactorRanges=MapThread[getPeakWidthRanges[#1,#2,0.10]&, {dataSplitTrimmed, centers}];
	asymmetryFactors=MapThread[
		If[#2!=First[#1],
			(* BC / AC, where A is left bound, B is the right bound, and C is the center *)
			(Last[#1] - #2) / (#2-First[#1]),
			(* If center is at zero (AC = 0) smooth expression using (BC + dx)/(0 + dx) *)
			(Last[#1] - #2 + #3) / #3
		]&,
		{asymmetryFactorRanges, centers, alphas}
	];

	return = {
		Position->centers,
		Height->heights,
		HalfHeightWidth->widths,
		Area->areas,
		PeakRangeStart->peakRangesTrimmed[[;;,1]],
		PeakRangeEnd->peakRangesTrimmed[[;;,2]],
		WidthRangeStart->widthRanges[[;;,1]],
		WidthRangeEnd->widthRanges[[;;,2]],
		BaselineIntercept->Delete[Lookup[baselineRules,BaselineIntercept],invalidPeakPositions],
		BaselineSlope->Delete[Lookup[baselineRules,BaselineSlope],invalidPeakPositions],
		BaselineFunction->Lookup[baselineRules,BaselineFunction],
		AsymmetryFactor->asymmetryFactors,
		TailingFactor->tailingFactors,
		TangentWidth -> tgStuff[[;;, 1]],
		TangentWidthLines -> tgStuff[[;;, 2]],
		TangentWidthLineRanges -> tgStuff[[;;, 3]],
		BaselinePeakRanges->peakRanges
	};

	return
];


calculateBaselineSpec[LocalConstant, dataPts_, dataSplit_, ranges_,bfw_]:=Module[{baselineIntercept,baselineSlope,blf,x},
	baselineIntercept=Map[Min[#[[;;,2]]]&,dataSplit];
	baselineSlope=Table[0.,{Length[dataSplit]}];
	blf = With[
		{fspec = Quiet[Simplify[Piecewise[MapThread[{#1+#2*x,#3<=x<=#4}&,{baselineIntercept,baselineSlope,ranges[[;;,1]],ranges[[;;,2]]}],Indeterminate]]/.x->Slot[1],{Reduce::ratnz}]},
		Function[fspec]
	];
	{
		BaselineIntercept->baselineIntercept,
		BaselineSlope->baselineSlope,
		BaselineFunction->blf
	}
];

calculateBaselineSpec[LocalLinear, dataPts_, dataSplit_, ranges_,bfw_]:=Module[{baselineIntercept,baselineSlope,blf,x},
	baselineIntercept=Map[((#[[1, 1]] * #[[-1, 2]] - #[[-1, 1]] * #[[1, 2]]) / (#[[1, 1]] - #[[-1, 1]])) &, dataSplit];
	baselineSlope=Map[(#[[-1,2]]-#[[1,2]])/(#[[-1,1]]-#[[1,1]])&,dataSplit];
	blf = With[
		{fspec = Quiet[Simplify[Piecewise[MapThread[{#1+#2*x,#3<=x<=#4}&,{baselineIntercept,baselineSlope,ranges[[;;,1]],ranges[[;;,2]]}],Indeterminate]]/.x->Slot[1],{Reduce::ratnz}]},
		Function[fspec]
	];
	{
		BaselineIntercept->baselineIntercept,
		BaselineSlope->baselineSlope,
		BaselineFunction->blf
	}
];

calculateBaselineSpec[EndpointLinear, dataPts_, dataSplit_, ranges_,bfw_]:=Module[{baselineIntercept,baselineSlope,blf,x, minxData, maxxData},

	baselineIntercept= ((dataPts[[1, 1]] * dataPts[[-1, 2]] - dataPts[[-1, 1]] * dataPts[[1, 2]]) / (dataPts[[1, 1]] - dataPts[[-1, 1]]));
	baselineSlope= (dataPts[[-1,2]]-dataPts[[1,2]])/(dataPts[[-1,1]]-dataPts[[1,1]]);
	minxData = dataPts[[1, 1]];
	maxxData = dataPts[[-1, 1]];

	blf = With[
		{fspec = Quiet[Simplify[Piecewise[{{baselineIntercept+baselineSlope*x,minxData<=x<=maxxData}}, Indeterminate]]/.x->Slot[1],{Reduce::ratnz}]},
		Function[fspec]
	];

	baselineInterceptList = Table[baselineIntercept, {Length[dataSplit]}];
	baselineSlopeList = Table[baselineSlope, {Length[dataSplit]}];

	{
		BaselineIntercept->baselineInterceptList,
		BaselineSlope->baselineSlopeList,
		BaselineFunction->blf
	}
];

calculateBaselineSpec[DomainConstant, dataPts_, dataSplit_, ranges_,bfw_] := Module[
	{pointsOutsidePeaks, constant, baselineInterceptList, baselineSlopeList, blf},

	pointsOutsidePeaks = Fold[Analysis`Private`selectInclusiveMatrixPointsOutsideRangeC[#1, Sequence @@ #2] &, dataPts, ranges];

	constant = NonlinearModelFit[pointsOutsidePeaks, a0, {a0}, x]["Function"];
	baselineIntercept = constant[0];
	baselineSlope = 0`;

	minxData = dataPts[[1, 1]];
	maxxData = dataPts[[-1, 1]];

	blf = With[
		{fspec = Quiet[Simplify[Piecewise[{{baselineIntercept+baselineSlope*x,minxData<=x<=maxxData}},Indeterminate]]/.x->Slot[1],{Reduce::ratnz}]},
		Function[fspec]
	];

	baselineInterceptList = Table[baselineIntercept, {Length[dataSplit]}];
	baselineSlopeList = Table[baselineSlope, {Length[dataSplit]}];

	{
		BaselineIntercept->baselineInterceptList,
		BaselineSlope->baselineSlopeList,
		BaselineFunction->blf
	}
];

calculateBaselineSpec[DomainLinear, dataPts_, dataSplit_, ranges_,bfw_] := Module[
	{pointsOutsidePeaks, linearLine, baselineIntercept, baselineSlope, baselineInterceptList, baselineSlopeList, blf},

	pointsOutsidePeaks = Fold[Analysis`Private`selectInclusiveMatrixPointsOutsideRangeC[#1, Sequence @@ #2] &, dataPts, ranges];

	linearLine = NonlinearModelFit[pointsOutsidePeaks, a0 + a1 * x, {a0, a1}, x]["Function"];

	{baselineIntercept, baselineSlope} = {linearLine[0], D[linearLine[x], x]};
	minxData = dataPts[[1, 1]];
	maxxData = dataPts[[-1, 1]];

	blf = With[
		{fspec = Quiet[Simplify[Piecewise[{{baselineIntercept+baselineSlope*x,minxData<=x<=maxxData}},Indeterminate]]/.x->Slot[1],{Reduce::ratnz}]},
		Function[fspec]
	];

	baselineInterceptList = Table[baselineIntercept, {Length[dataSplit]}];
	baselineSlopeList = Table[baselineSlope, {Length[dataSplit]}];

	{
		BaselineIntercept->baselineInterceptList,
		BaselineSlope->baselineSlopeList,
		BaselineFunction->blf
	}
];


calculateBaselineSpec[DomainNonlinear, dataPts_, dataSplit_, ranges_,bfw_] := Module[
	{bg,baselineInterceptList, baselineSlopeList, bgf},

	{bg,bgf}= xyEstimatedBackground[dataPts, bfw];

	baselineInterceptList = Table[Null, {Length[dataSplit]}];
	baselineSlopeList = Table[Null, {Length[dataSplit]}];

	{
		BaselineIntercept -> baselineInterceptList,
		BaselineSlope -> baselineSlopeList,
		BaselineFunction -> With[{bgf=bgf},(bgf[#]&)],
		BaselinePoints -> bg
	}
];

calculateBaselineSpec[baseline:GlobalConstant|GlobalLinear|GlobalNonlinear, dataPts_, dataSplit_, ranges_,bfw_] :=Module[
	{
		newBaseline, newBaselineAssociation
	},

	(* Lookup the correct baseline *)
	newBaselineAssociation = <|
		GlobalConstant -> DomainConstant,
		GlobalLinear -> DomainLinear,
		GlobalNonlinear -> DomainNonlinear
	|>;

	newBaseline = Lookup[newBaselineAssociation, baseline];

	(* Throw warning *)
	Message[Warning::DeprecatedBaseline, baseline, newBaseline];

	(* Call with modified baseline *)
	calculateBaselineSpec[newBaseline, dataPts, dataSplit, ranges,bfw]

];

(*xyEstimatedBackground estimates the background from the input xy-data (xy) and BackgroundFeatureWidth (bfw).
It uses built-in function EstimatedBackground, but is limited to taking only y-values (with x-values = {1, 2, 3...} implicit).
So, if the input xy data does not have uniform x-spacings, we need a new set of y-values (yUniform) that can represent
the input data at regular intervals for input to EstimatedBackground.  This is done by evaluating an interpolation
function of the data at regular intervals.  The function returns {xy-data of the background curve, and the background function}*)
xyEstimatedBackground[xy_,bfw_]:=Module[{xs,ys,xUniform,yUniform,ybg,ybgUniform,xybg,bgf,bfwNormalized},
	{xs,ys}=Transpose[xy];
	xUniform = N@Subdivide[xs[[1]],xs[[-1]],Length[xs]];
	yUniform = Interpolation[xy][xUniform];
	(*Formula determined emperically*)
	bfwNormalized = bfw * .2* .197*Length[xy]^0.696;
	ybgUniform = EstimatedBackground[yUniform,bfwNormalized];
	bgf = Interpolation[Transpose[{xUniform,ybgUniform}]];
	ybg = bgf[xs];
	xybg = Transpose[{xs,ybg}];
	{xybg,bgf}
];


trimPeakOutsideBaseline[dataInsideRange_, baselineFunction_] := Module[
	{trimmedData, singlePeakPosition},

	trimmedData = Select[dataInsideRange, baselineFunction[#[[1]]] < #[[2]] &];

	(* If the peak is only length 1, we need to add points around it *)
	If[MatchQ[Length[trimmedData],1],

		(* include points to the left and right *)
		(* find position of single peak *)
		singlePeakPosition = Position[dataInsideRange, trimmedData[[1]]];

		singlePeakPosition = singlePeakPosition /. List -> Sequence;

		(* if it is not the first or last point*)
		If[!MatchQ[singlePeakPosition, 1] && !MatchQ[singlePeakPosition, Length[dataInsideRange]],

			(*grab values to the left and right of the trimmed data *)
			trimmedData = dataInsideRange[[singlePeakPosition-1;;singlePeakPosition+1]]

		]

	];

	If[Length[trimmedData] <= 1, Return[$Failed]];

	trimmedData
];


(* ::Subsubsection::Closed:: *)
(*getPeakWidthRanges*)


getPeakWidthRanges[dataPts_]:=getPeakWidthRanges[dataPts,First[First[Select[dataPts,#[[2]]===Max[dataPts[[;;,2]]]&]]]];
getPeakWidthRanges[dataPts_,center_]:=getPeakWidthRanges[dataPts,center,0];
getPeakWidthRanges[dataPts_,center_,heightRatio_]:=Module[{method,max,min,hh,left,right,dataleft,dataright},
	method="closest";
	{max,min}={Max[dataPts[[;;,2]]],(dataPts[[1,2]]+dataPts[[-1,2]])/2};
	hh=(max+min)/2;
	dataleft=selectInclusiveMatrixPointsLeftOfValueC[dataPts,center];
	dataright=selectInclusiveMatrixPointsRightOfValueC[dataPts,center];

	(* remove points with position center if list has more than one element *)
	dataleft=If[Length[dataleft]>1,DeleteCases[dataleft,_?(First[#]==center&)],dataleft];
	dataright=If[Length[dataright]>1,DeleteCases[dataright,_?(First[#]==center&)],dataright];

	{left, right} = Switch[method,

	"mean",
		{ Mean[{First[First[Select[dataPts,And[#[[2]]>=hh,#[[1]]<=center]&]/.{{}->{dataPts[[1]]}}]],
			First[Last[Select[dataPts,And[#[[2]]<=hh,#[[1]]<=center]&]/.{{}->{dataPts[[1]]}}]]}] ,
		Mean[{First[Last[Select[dataPts,And[#[[2]]>=hh,#[[1]]>=center]&]/.{{}->{dataPts[[-1]]}}]],
			First[First[Select[dataPts,And[#[[2]]<=hh,#[[1]]>=center]&]/.{{}->{dataPts[[-1]]}}]]}] },

	"closest",
		{ safeNearest[dataleft, dataright, hh, Left],
		safeNearest[dataleft, dataright, hh, Right] }
	];

	{left+heightRatio*(center-left),right-heightRatio*(right-center)}
];
safeNearest[leftPool_, rightPool_, target_, Left] := If[MatchQ[leftPool, {}],
	Min[rightPool[[;;, 2]]],
	Mean[Cases[leftPool, {x_, Alternatives @@ Nearest[leftPool[[;;, 2]], target]} :> x]]
];
safeNearest[leftPool_, rightPool_, target_, Right] := If[MatchQ[rightPool, {}],
	Max[leftPool[[;;, 2]]],
	Mean[Cases[rightPool, {x_, Alternatives @@ Nearest[rightPool[[;;, 2]], target]} :> x]]
];


(* ::Subsubsection::Closed:: *)
(*computePeakIntegral*)


computePeakIntegral[dataPts_]:=computePeakIntegral[dataPts,Function[Function[Min[dataPts[[;;,2]]]]]];
computePeakIntegral[dataPts_,All]:=computePeakIntegral[dataPts,dataPts[[{1,-1},1]]];
computePeakIntegral[dataPts_,baselineFcnFcn_Function]:=computePeakIntegral[dataPts,dataPts[[{1,-1},1]],baselineFcnFcn];
computePeakIntegral[dataPts_,domain:{lower_,upper_}]:=computePeakIntegral[dataPts,domain,Function[Function[Min[dataPts[[;;,2]]]]]];
computePeakIntegral[dataPts_,domain:{lower_,upper_},baselineFcn_Function]:=Module[{xdata,ydata,baselinedata},

	(* select dataPts within the domain *)
	{xdata,ydata}=Transpose[selectInclusiveMatrixPointsInsideRangeC[dataPts,lower,upper]];

	baselinedata=MapThread[Min[{#1,#2}]&,{ydata,baselineFcn/@xdata}];

	(* compute area *)
	Total[(Most[ydata-baselinedata]+Rest[ydata-baselinedata])/2*Differences[xdata]]
];



(* ::Subsubsection::Closed:: *)
(*deletePeakDuplicates*)


deletePeakDuplicates[Null]:=Null;
deletePeakDuplicates[peakFields_]:=Module[{peakRanges,peakKeepIndices,peakKeep},
	(* if empty peaks, return empty list *)
	If[MatchQ[Lookup[peakFields,Position],{}],
		Return[peakFields]
	];

	peakRanges = Transpose[Lookup[peakFields,{PeakRangeStart,PeakRangeEnd}]];

	peakKeepIndices = DeleteDuplicates[Range[Length[peakRanges]],overlappingRangesQ[peakRanges[[#1]],peakRanges[[#2]]]&];

	peakKeep = Transpose[Transpose[Values[peakFields]][[peakKeepIndices]]];

	MapThread[Rule[#1,#2]&,{Keys[peakFields],peakKeep}]
];

overlappingRangesQ[{startA_,endA_},{startB_,endB_}]:=(startB < endA && startA < endB);


(* ::Subsubsection::Closed:: *)
(*computeRelativePeaksFields*)


computeRelativePeaksFields[Null, __] := Null;

computeRelativePeaksFields[peakFields_, templateRules_, resolvedOps_] := Module[
	{areas, centers, n,
		relativeAreas,relativePositions,assignmentLabels, finalAssignments, libraryAssignments,
		alignedLabels, parentLabelList,ind,kept={}, opLabel,
		finalLabels, finalParents, nonNullLibrary, finalLibraryAssignments,
		rawAssignments, userAssignments, userAssignmentUnits, userLabels, userParents, intermediateLabels,
		alignmentTemplateRules, alignedTemplateLabels, alignedTemplateAssignments,
		alignmentUserRules,
		indexLabels, rrtLabels, debug=False, rrtLabeling,
		userAssignmentsProcessed, parentPeaks, parentIndexList, indexDefaultParentPeak,
		assignmentTimes, assignmentNames, assignmentTolerances, assignmentModels,
		alignedAssignmentsModels, alignedAssignmentLabels,
		userRelativeAssignments, relativeAssignmentRatios, relativeAssignmentModels,
		relativeAssignmentNames, relativeAssignmentTolerances, relativeAlignmentUserRules,
		alignedRelativeAssignmentsModels, alignedRelativeAssignmentLabels, relativeAssignmentLabels,
		postIntermediateLabels
	},

	areas = Area /. peakFields;
	centers = Position /. peakFields;
	n = Length[areas];

	(*
		If no peaks found, all relative fields will be empty
	*)
	If[MatchQ[areas,{}],
		Return[{
			RelativeArea -> {},
			RelativePosition -> {},
			PeakLabel -> {},
			ParentPeak -> {}
		}]
	];


	(*
		--------------- user-specified starting points  -----------------------
	*)
	opLabel = Lookup[resolvedOps,PeakLabels];

	If[And[MatchQ[opLabel,Except[{}|Automatic|Null]],!MatchQ[n,Length[opLabel]]],
		Message[Warning::PeakLabelsMismatch];
	];

	(* user given labels, padded with Automatics to correct size *)
	userLabels = PadRight[
		Replace[opLabel,(Automatic|Null)->{}],
		n,
		Automatic
	];

	(* user given parent peaks, where automatic is replaced with an empty list *)
	userParents = Lookup[resolvedOps,ParentPeaks]/.{(Automatic|Null)->{}};

	(* Raw value of the PeakAssignments option *)
	rawAssignments=If[MatchQ[Lookup[resolvedOps,PeakAssignments],Null],
		{},
		Lookup[resolvedOps,PeakAssignments]
	];

	(* List of all units appearing in the resolved PeakAssignments Option *)
	userAssignmentUnits=Which[
		(* No units if option is not specified *)
		MatchQ[rawAssignments,Automatic|{}|Null],{},
		(* Span units for maximum peak in range spec *)
		MatchQ[rawAssignments,{{_Span,_}..}],Units[Flatten@(List@@@Part[rawAssignments,All,1])],
		(* Units of position and tolerance for pos,model,tol specs *)
		True,Units[Flatten@Part[rawAssignments,All,{1,3}]]
	];

	(* Resolve assignments vs relative assignments. Empty list means unused. *)
	{userAssignments,userRelativeAssignments}=If[MatchQ[DeleteDuplicates[userAssignmentUnits],{1 RRT}],
		(* Use relative labeling and disable absolute assignments *)
		{
			{},
			SortBy[Lookup[resolvedOps,PeakAssignments],First]
		},

		(* Do not use relative labeling and use absolute assignments *)
		{
			SortBy[Lookup[resolvedOps,PeakAssignments],First],
			{}
		}
	];

	(* Populate absolute user assignments. These will be empty lists if userAssignments was an empty list. *)
	assignmentTimes = Unitless[userAssignments[[;;,1]]];
	assignmentModels = userAssignments[[;;,2]];
	assignmentNames = downloadAssignmentNames[assignmentModels];
	assignmentTolerances = If[MatchQ[userAssignments,{{_Span,_}..}],
		Repeat[Null,Length[userAssignments]],
		Unitless[userAssignments[[;;,3]]]
	];

	(* Populate the relative user assignments, again using empty lists if relative assignments were disabled. *)
	relativeAssignmentRatios = Unitless[userRelativeAssignments[[;;,1]]];
	relativeAssignmentModels = userRelativeAssignments[[;;,2]];
	relativeAssignmentNames = downloadAssignmentNames[relativeAssignmentModels];
	relativeAssignmentTolerances = If[MatchQ[userRelativeAssignments,{{_Span,_}..}],
		Repeat[Null,Length[userRelativeAssignments]],
		Unitless[userRelativeAssignments[[;;,3]]]
	];

	(*
		--------------- template stuff  -----------------------
	*)

	(* Align peaks with template *)
	alignmentTemplateRules = Rule@@@ListAlignment[
		centers,
		Keys[First[templateRules]],
		Threshold->Lookup[resolvedOps,TemplateAssignmentTolerance]
	];

	(* labels from aligned peaks *)
	alignedTemplateLabels = Values[ReplaceRule[
		Thread[centers->ToString/@Range[n]],
		Map[#[[1]]->Replace[#[[2]],First[templateRules]]&,alignmentTemplateRules] (* only replace correct spot... /. breaks things *)
	][[;;n]]];


	(*
		--------------- labels and models from assignments  -----------------------
	*)

	{alignedAssignmentsModels, alignedAssignmentLabels} = alignUserAssignments[
		centers,areas,assignmentTimes,assignmentTolerances,assignmentModels,assignmentNames
	];

	(* labels from assignments *)
	assignmentLabels = If[
		And[
			userAssignments=={}, (* no user-specified assignemnts *)
			templateRules=!={<||>, <||>}  (* yes template *)
		],
		alignedTemplateLabels, (* use template assignments *)
		alignedAssignmentLabels (* use other assignments *)
	];

	(*
		--------------- update labels using template & alignment -----------------------
	*)

	intermediateLabels = MapThread[
		If[MatchQ[#1,_String],
			#1,
			#2
		]&,
		{userLabels,assignmentLabels}
	];


	(*
		--------------- parent peaks -----------------------
	*)

	(* If input is CESDS data, use the first peak, otherwise use the largest peak by area*)
	indexDefaultParentPeak = If[Lookup[resolvedOps,ReferenceField]===ProcessedUVAbsorbanceData,
		1,
		FirstPosition[areas, Max[areas]][[1]]
	];

	(* ParentPeaks labels must exist in the known labels at this point *)
	If[MatchQ[Complement[Cases[userParents,_String],intermediateLabels],Except[{}]],
		Message[Warning::ParentPeaksMismatch,Complement[DeleteCases[userParents,_Integer],intermediateLabels],intermediateLabels/.{Null->Nothing},indexDefaultParentPeak];
	];

	(* ParentPeaks indices must be within the range [1,n] *)
	If[(Min[Cases[userParents,_Integer]]<1)||(Max[Cases[userParents,_Integer]]>n),
		Message[Warning::ParentPeakIndices,Select[Cases[userParents,_Integer],(#>n||#<1)&],n,indexDefaultParentPeak];
	];

	(* index of each parent peak *)
	parentIndexList=Which[
		(* Valid list of peak labels or peak indices *)
		MatchQ[userParents,{(_String|_Integer)..}],
			Module[{userParentPositions},
				(* Locate index of string labels, otherwise use the integer index *)
				userParentPositions=Map[
					If[MatchQ[#,_Integer],
						(* Integer *)
						If[(#>0)&&(#<=n),#,indexDefaultParentPeak],
						(* String Label *)
						First[FirstPosition[intermediateLabels,#]]/.{"NotFound"->indexDefaultParentPeak}
					]&,
					userParents
				];

				(* Warn the user if the length of userParentPositions is inconsistent *)
				If[Length[userParentPositions]=!=n,
					Message[Warning::ParentPeaksPadded,Length[userParentPositions],n]
				];

				(* Trim extraneous parent peaks if there are too many, pad with largest peak if too few *)
				PadRight[userParentPositions,n,indexDefaultParentPeak]
			],

		(* Anything else, use the largest peak by area as the parent for all peaks *)
		True,
			Table[indexDefaultParentPeak, n]
	];


	(*
		--------------- relative fields -----------------------
	*)

	(* RelativeArea field - fraction of parent area *)
	relativeAreas = areas / areas[[parentIndexList]];

	(* RelativePosition field - fraction of parent position *)
	relativePositions = centers / centers[[parentIndexList]];

	(*
		--------------- relative alignment -----------------------
	*)

	{alignedRelativeAssignmentsModels, alignedRelativeAssignmentLabels} = alignUserAssignments[
		relativePositions,relativeAreas,relativeAssignmentRatios,relativeAssignmentTolerances,
		relativeAssignmentModels,relativeAssignmentNames
	];

	(* labels from assignments *)
	relativeAssignmentLabels = If[
		And[
			userRelativeAssignments=={}, (* no user-specified assignemnts *)
			templateRules=!={<||>, <||>}  (* yes template *)
		],
		alignedTemplateLabels, (* use template assignments *)
		alignedRelativeAssignmentLabels (* use other assignments *)
	];

	(*
		--------------- update labels using template & relative alignment -----------------------
	*)

	postIntermediateLabels = MapThread[
		Which[
			And[MatchQ[#1,ToString[#3]],#2=!=Null],
				#2,
			MatchQ[#1,_String],
				#1,
			True,
				#2
		]&,
		{intermediateLabels,relativeAssignmentLabels,Range[n]}
	];


	(*
		--------------- final everything -----------------------
	*)

	(* PeakLabel field *)

	(* True if RelativeLabeling was requested in input options *)
	rrtLabeling = TrueQ[(Lookup[resolvedOps,RelativeLabeling]/.{Null->False})];

	(* Generate positions for relative labels *)
	rrtLabels = Map[If[Lookup[resolvedOps,ReferenceField]===ProcessedUVAbsorbanceData,"RMT ","RRT "]<>ToString[#]&,Round[relativePositions,.01]];

	(* Swap in default labels for anything unlabeled, using rrtlabels if relative positions are required. *)
	finalLabels = MapThread[
		Function[{currentLabel,rrtLabel,parentInd,ind},
			If[MatchQ[currentLabel,Automatic|Null|ToString[ind]],
				If[MatchQ[rrtLabel,Null]||(rrtLabeling===False),ToString[ind],rrtLabel],
				currentLabel
			]
		],
		{postIntermediateLabels,rrtLabels,parentIndexList,Range[n]}
	];

	(* ParentPeak field *)
	finalParents = finalLabels[[parentIndexList]];

	(* New resolution also stores position and tolerance *)
	libraryAssignments = Module[{chosenAssignmentModels,chosenAssignmentTolerances},

		chosenAssignmentModels = If[MatchQ[alignedAssignmentsModels,{Null..}],
			alignedRelativeAssignmentsModels,
			alignedAssignmentsModels
		];

		chosenAssignmentTolerances = If[MatchQ[alignedAssignmentsModels,{Null..}],
			MapThread[If[MatchQ[FirstPosition[relativeAssignmentNames,#1],_Missing],
					Null,
					#2*Part[
						relativeAssignmentTolerances,
						First@FirstPosition[relativeAssignmentNames,#1]
					]
				]&,
				{alignedRelativeAssignmentLabels,Lookup[peakFields,Position][[parentIndexList]]}
			],
			Map[If[MatchQ[FirstPosition[assignmentNames,#],_Missing],
					Null,
					Part[
						assignmentTolerances,
						First@FirstPosition[assignmentNames,#]
					]
				]&,
				alignedAssignmentLabels
			]
		];

		(* Create an entry for all non-null elements *)
		MapThread[
			<|
				Label->#1,
				Model->Link[#2],
				Position->#3,
				Tolerance->#4
			|>&,
			{finalLabels,chosenAssignmentModels,Lookup[peakFields,Position],chosenAssignmentTolerances}
		]
	];

	(* Post migration: only keep links to the models required *)
	finalAssignments=Lookup[#,Model]&/@libraryAssignments;

	(* Keep only library entries which have a model assigned *)
	nonNullLibrary=DeleteCases[libraryAssignments,<|_,Model->Null,_,_|>];

	(* If no library/template assignments could be aligned, then return the template option unchanged *)
	finalLibraryAssignments=If[And[nonNullLibrary==={},templateRules=!={<||>,<||>}],
		(* Strip existing link IDs for the new upload *)
		Download[Lookup[resolvedOps,Template],PeakAssignmentLibrary]/.{Link[x:ObjectP[], _String]:>Link[x]},
		nonNullLibrary
	];

	(* final set of stuff to return *)
	{
		RelativeArea -> relativeAreas,
		RelativePosition -> relativePositions,
		PeakLabel -> finalLabels,
		ParentPeak -> finalParents,
		PeakAssignment->finalAssignments,
		PeakAssignmentLibrary->finalLibraryAssignments
	}

];

(* Align by maximum peak in range *)
alignUserAssignments[posList_List,areaList_List,ranges:{_Span..},tolerances_List,models_,names_]:=Module[
	{indexPosAreas, peaksInRange, maxPeaksInRange, maxPeakIndex, alignedAssignmentModels, alignedAssignmentLabels, dupeIndices, dupeAssignIndices},

	(* Group positions with areas and add an index *)
	indexPosAreas=Transpose@{Range[Length[posList]],posList,areaList};

	(* For each span, get the position-area pairs which fall within that span *)
	peaksInRange=Map[
		Select[indexPosAreas,
			Function[{indexPosArea},
				indexPosArea[[2]]>=First[#]&&indexPosArea[[2]]<=Last[#]
			]
		]&,
		ranges
	];

	(* Get the index-pos-area pair for the largest-area peak in each range, defaulting to {} if there were none *)
	maxPeaksInRange=FirstOrDefault[MaximalBy[#,Last]]&/@peaksInRange;

	(* Index of maximal-area peak in each assignment range mapping to their model spec *)
	maxPeakIndices=MapThread[
		If[MatchQ[#1,Null],
			Nothing,
			FirstOrDefault[#1]->#2
		]&,
		{maxPeaksInRange,models}
	];

	(* Indices of peaks which multiple assignments map to *)
	dupeIndices=Part[#,1,1]&/@Select[
		GatherBy[maxPeakIndices,First],
		Length[#]>1&
	];

	(* Indices of the assignments which map to the same peak *)
	dupeAssignIndices=DeleteDuplicates@Flatten@Map[
		Position[First/@maxPeakIndices,#]&,
		dupeIndices
	];

	(* If there are duplicates, then warn the user *)
	If[Length[dupeAssignIndices]>0,
		Message[Warning::ConflictingPeakAssignments,Part[ranges,dupeAssignIndices]]
	];

	(* Pre-allocate the aligned models to Null *)
	alignedAssignmentModels=Map[
		Lookup[maxPeakIndices,#,Null]&,
		Range[Length[posList]]
	];

	(* get list of labels from models that were just aligned *)
	alignedAssignmentLabels = Map[
		If[MatchQ[#,Null],
			Null,
			Extract[names,FirstPosition[models,#]]
		]&,
		alignedAssignmentModels
	];

	{alignedAssignmentModels, alignedAssignmentLabels}
];

(* Align by closest peaks, i.e. position + tolerance *)
alignUserAssignments[realValues_List,areas_,guesses_List,tolerances_List,models_,names_]:=Module[
	{alignmentUserRules,alignedAssignmentsModels,alignedAssignmentLabels},

	(* align peaks with assignment specification *)
	alignmentUserRules = Rule@@@ListAlignment[
		realValues,
		guesses,
		Threshold->tolerances
	];

	(* get list of models from PeakAssignments after aligning to found peaks *)
	alignedAssignmentsModels = Module[{timeToModelRules,alignedTimesToModelRules,alignedPeakTimes,alignedModels,replacedModels},
		timeToModelRules = MapThread[#2->#1&,{models,guesses}];
		alignedPeakTimes = alignmentUserRules[[;;,2]];
		alignedModels = alignedPeakTimes /. timeToModelRules;
		alignedTimesToModelRules = MapThread[First[#1]->#2&,{alignmentUserRules,alignedModels}];
		(* Don't delete duplicate assignments *)
		replacedModels=Flatten[ReplaceRule[{#},alignedTimesToModelRules,Append->False]&/@Map[#->Null&,realValues]];
		(* only return the values *)
		Values[replacedModels]
	];

	(* get list of labels from models that were just aligned *)
	(* pull from previously donwloaded names to save time *)
	alignedAssignmentLabels = Map[
		If[MatchQ[#,Null],
			Null,
			Extract[names,FirstPosition[models,#]]
		]&,
		alignedAssignmentsModels
	];

	{alignedAssignmentsModels, alignedAssignmentLabels}
];



(* ::Subsubsection::Closed:: *)
(*resolutionAnsPlates*)


resolutionAnsPlates[Null] := Null;
resolutionAnsPlates[pks_] := With[{halfHeightRes = fullResolutionMatrixHalfHeight[pks]},
{
	HalfHeightResolution -> halfHeightRes,
	TangentResolution -> fullResolutionMatrixTG[pks],
	AdjacentResolution -> If[MatchQ[halfHeightRes,{}],{},Prepend[Diagonal[halfHeightRes, -1], 0.]],
	computeHalfHeightPlates[pks],
	computeTGHeightPlates[pks]
}];


(* Half Height Width *)
(* left parent, top child *)
fullResolutionMatrixHalfHeight[Null] := Null;
fullResolutionMatrixHalfHeight[pk_List] := PeakResolution[Append[Association[pk],Type->Object[Analysis,Peaks]]];
fullResolutionMatrixHalfHeight[pksAsso_] := PeakResolution[Append[pksAsso,Type->Object[Analysis,Peaks]]];
(* Tangent Width *)
(* left parent, top child *)
fullResolutionMatrixTG[Null] := Null;
fullResolutionMatrixTG[pk_List] := PeakResolution[Append[Association[pk],Type->Object[Analysis,Peaks]], Method -> TangentWidth];
fullResolutionMatrixTG[pksAsso_] := PeakResolution[Append[pksAsso,Type->Object[Analysis,Peaks]], Method -> TangentWidth];


(* Half Height Width *)
computeHalfHeightPlates[Null] := Null;
computeHalfHeightPlates[pk_List] := computeHalfHeightPlates[Association[pk]];
computeHalfHeightPlates[pksAsso_] := Module[
	{pkPositions, halfHeightWidth},
	{pkPositions, halfHeightWidth} = {Position, HalfHeightWidth} /. pksAsso;
	HalfHeightNumberOfPlates -> Table[5.54 * (pkPositions[[i]] / halfHeightWidth[[i]])^2, {i, 1, Length[pkPositions]}]
];
(* Tangent Width *)
computeTGHeightPlates[Null] := Null;
computeTGHeightPlates[pk_List] := computeTGHeightPlates[Association[pk]];
computeTGHeightPlates[pksAsso_] := Module[
	{pkPositions, tangentWidth},
	{pkPositions, tangentWidth} = {Position, TangentWidth} /. pksAsso;
	If[MatchQ[tangentWidth, {}], Return[TangentNumberOfPlates -> {}]];
	TangentNumberOfPlates -> Table[computeTGHeightPlatesCore[pkPositions[[i]], tangentWidth[[i]]], {i, 1, Length[pkPositions]}]
];
computeTGHeightPlatesCore[_, Null] := Null;
computeTGHeightPlatesCore[tr_, w_] := 16 * (tr / w)^2;


(* ::Subsubsection::Closed:: *)
(*tgWidth*)


tgWidth[dt_, pkLeft_, pkLeftMid_, pkHigh_, pkRightMid_, pkRight_, baselineFunction_] := Module[
	{lefts, rights},
	lefts = MapThread[tgWidthLeft[dt, #1, #2, #3, baselineFunction[x]] &, {pkLeft, pkLeftMid, pkHigh}];
	rights = MapThread[tgWidthRight[dt, #1, #2, #3, baselineFunction[x]] &, {pkHigh, pkRightMid, pkRight}];
	If[MemberQ[Flatten[{lefts, rights}], $Failed|Null],
		Return[Table[{Null, Null, Null}, Length[lefts]]],
		processOneTGWidth /@ Transpose[{lefts, rights}]
	]
];


tgWidthLeft[dt_, left_, mid_, high_, baseline_] := Module[
	{leftPkBottom, leftPkTop, leftPk, quadraticLine, inflection, inflectionIndex, fitXY, tgLine, xPosition},

	leftPkBottom = Quiet[Analysis`Private`selectInclusiveMatrixPointsInsideRangeC[dt, left, mid], CompiledFunction::cfnlts];
	leftPkTop = Quiet[Analysis`Private`selectInclusiveMatrixPointsInsideRangeC[dt, mid, high], CompiledFunction::cfnlts];
	leftPk = Join[leftPkBottom[[Round[Length[leftPkBottom] * 0.4] ;;]], leftPkTop[[2;; Round[Length[leftPkTop] * 0.75]]]];

	quadraticLine = Quiet @ NonlinearModelFit[leftPk,a0 + a1*x + a2*x^2 + a3*x^3 + a4*x^4 + a5*x^5, {a0, a1, a2, a3, a4,a5}, x]["Function"];

	If[!MatchQ[quadraticLine, _Function], Return[$Failed]];

	inflection = Quiet @ Solve[quadraticLine''[x] == 0 && x >= left && x <= high, x, Reals];

	If[MatchQ[inflection, {} | {{}}], Return[$Failed]];

	inflection = x /. Last[Sort[inflection]];
	inflectionIndex = First[FirstPosition[leftPk, {GreaterEqualP[inflection], _}]];

	If[MatchQ[inflectionIndex, "NotFound"], Return[$Failed]];

	fitXY = leftPk[[Max[1, inflectionIndex - 5] ;; Min[Length[leftPk], inflectionIndex + 5]]];
	tgLine = NonlinearModelFit[fitXY, a0 + a1 * x, {a0, a1}, x]["Function"];

	xPosition = Quiet[Check[Solve[baseline == tgLine[x], x],{}]];
	xPosition = If[xPosition==={},
		Null,
		Last[First[xPosition]]
	];
	(*xPosition = Last[First[First[Solve[baseline == tgLine[x], x]]]];*)

	If[xPosition > First[leftPk[[inflectionIndex]]], Return[$Failed]];

	{xPosition, {tgLine, {xPosition, First[leftPk[[inflectionIndex]]]}}}
];


tgWidthRight[dt_, high_, mid_, right_, baseline_] := Module[
	{rightPkBottom, rightPkTop, rightPk, quadraticLine, inflection, inflectionIndex, fitXY, tgLine, xPosition},

	rightPkBottom = Quiet[Analysis`Private`selectInclusiveMatrixPointsInsideRangeC[dt, mid, right], CompiledFunction::cfnlts];
	rightPkTop = Quiet[Analysis`Private`selectInclusiveMatrixPointsInsideRangeC[dt, high, mid], CompiledFunction::cfnlts];
	rightPk = Join[rightPkTop[[Round[Length[rightPkTop] * 0.25] ;;]], rightPkBottom[[;; Round[Length[rightPkBottom] * 0.6]]]];

	quadraticLine = Quiet @ NonlinearModelFit[rightPk,a0 + a1*x + a2*x^2 + a3*x^3 + a4*x^4 + a5*x^5, {a0, a1, a2, a3, a4,a5}, x]["Function"];
	If[!MatchQ[quadraticLine, _Function], Return[$Failed]];

	inflection = Quiet @ Solve[quadraticLine''[x] == 0 && x >= high && x <= right, x, Reals];
	If[MatchQ[inflection, {} | {{}}], Return[$Failed]];

	inflection = x /. Last[Sort[inflection]];
	inflectionIndex = First[FirstPosition[rightPk, {LessEqualP[inflection], _}]];

	If[MatchQ[inflectionIndex, "NotFound"], Return[$Failed]];

	fitXY = rightPk[[Max[1, inflectionIndex - 5] ;; Min[Length[rightPk], inflectionIndex + 5]]];
	tgLine = NonlinearModelFit[fitXY, a0 + a1 * x, {a0, a1}, x]["Function"];

	xPosition = Quiet[Check[Solve[baseline == tgLine[x], x],{}]];
	xPosition = If[xPosition==={},
		Null,
		Last[First[xPosition]]
	];
	(*xPosition = Last[First[First[Solve[baseline == tgLine[x], x]]]];*)

	If[First[rightPk[[inflectionIndex]]] > xPosition, Return[$Failed]];

	{xPosition, {tgLine, {First[rightPk[[inflectionIndex]]], xPosition}}}
];


processOneTGWidth[{{left_, {leftLine_, leftRange_}}, {right_, {rightLine_, rightRange_}}}] := Module[
	{tgWidth, tgLines, tgLineRanges},
	tgWidth = right - left;
	If[!MatchQ[tgWidth, GreaterEqualP[0]], Return[{Null, Null, Null}]];
	tgLines = {leftLine, rightLine};
	tgLineRanges = {leftRange, rightRange};
	{tgWidth, tgLines, tgLineRanges}
];
processOneTGWidth[___] := {Null, Null, Null};


(* ::Subsubsection::Closed:: *)
(* computePeakSplittingFields *)

(* If no peaks were identified, all splitting fields are null *)
computePeakSplittingFields[pks:{Rule[_,{}]..},resolvedOps_]:={
	SplittingData->Null,
	SplittingPeakIndices->Null,
	SplittingAssignments->Null,
	NMRFunctionalGroup->Null,
	PeakGroupDomains->Null,
	PeakIntegralNormalizationGroup->Null,
	PeakGroupMultiplicity->Null
};

(* Compute fields associated with peak splitting, e.g. chemical shifts, multiplicities, J-factors, etc. *)
computePeakSplittingFields[pks_,resolvedOps_]:=Module[
	{
		pkPositionsAreas,sortedPkData,maxJSplitting,opFreq,splittingThreshold,
		pkGroups,pkGroupDomains,pkGroupIndices,rawSplits,normalizedSplits,pkGroupNormalization,
		updatedSplits,pkMultiplicity,splitLabels,splitAssignments,splitFuncGroups,knownAssigns
	},

	(* Extract peak positions and peak heights from peak fields *)
	pkPositionsAreas=Transpose@Lookup[pks,{Position,Area}];

	(* Sort the peaks by increasing chemical shift *)
	sortedPkData=SortBy[pkPositionsAreas,First];

	(* Look up the maximum J-splitting threshold from the resolved options. *)
	maxJSplitting=Lookup[resolvedOps,MaximumJSplitting];

	(* Look up the operating frequency the data was collected at, and convert it to megahertz *)
	opFreq=UnitConvert[Lookup[resolvedOps,OperatingFrequency],Megahertz];

	(* If not already, convert the threshold into units of PPM *)
	splittingThreshold=If[CompatibleUnitQ[maxJSplitting,Hertz],
		(10^6 PPM)*Unitless[UnitConvert[maxJSplitting,Hertz]/opFreq],
		UnitConvert[maxJSplitting,PPM]
	];

	(* Split peaks into groups, which will be further analyzed for splitting *)
	{pkGroups,pkGroupDomains,pkGroupIndices}=If[MatchQ[Lookup[resolvedOps,PeakGroupDomains],Automatic],
		(* If peak group ranges were not provided, divide peak groups if the distance between them exceeds the maximum J Splitting *)
		splitByThreshold[sortedPkData,splittingThreshold],

		(* If peak group ranges were provided, *)
		splitByDomains[sortedPkData,Lookup[resolvedOps,PeakGroupDomains],splittingThreshold]
	];

	(* Assign a peak-splitting to each group and return the assignments, with everything in units of PPM *)
	rawSplits=assignSplitting[#,
		Lookup[resolvedOps,SplittingSpacingTolerance],
		Lookup[resolvedOps,SplittingRelativeIntegralTolerance]
	]&/@pkGroups;

	(* Normalize peak group integrals according to the PeakIntegralNormalizationGroup option *)
	{normalizedSplits,pkGroupNormalization}=normalizePeakGroups[
		rawSplits,
		Lookup[resolvedOps,PeakIntegralNormalizationGroup]
	];

	(* Apply user-specified multiplicities and compute J-factors when possible *)
	updatedSplits=applyPeakGroupMultiplicity[
		normalizedSplits,
		DeleteCases[pkGroups,{}],
		Lookup[resolvedOps,SplittingSpacingTolerance],
		Lookup[resolvedOps,SplittingRelativeIntegralTolerance],
		Lookup[resolvedOps,PeakGroupMultiplicity]
	];

	(* Resolve the Peak Multiplicity option after it has been applied *)
	pkMultiplicity=resolvePeakGroupMultiplicity[updatedSplits];

	(* Format the updated splits to get the final splitting labels *)
	splitLabels=formatSplitting[updatedSplits,opFreq];

	(* Match the SplittingAssignments option to the identified peak group domains *)
	knownAssigns=matchKnownAssignments[Lookup[resolvedOps,SplittingAssignments],pkGroupDomains];

	(* Check if any of the unknown assignments correspond to a solvent peak *)
	knownAssignsWithSolvent=checkSolventPeak[knownAssigns,updatedSplits,resolvedOps];

	(* Use the final splitting labels to automatically generate assignments. *)
	{splitAssignments,splitFuncGroups}=assignToKnownSpecies[
		splitLabels,
		Lookup[resolvedOps,KnownSpecies],
		Lookup[resolvedOps,Nucleus],
		knownAssignsWithSolvent
	];

	(* Format the splitting data for output *)
	{
		SplittingData->splitLabels,
		SplittingPeakIndices->pkGroupIndices,
		SplittingAssignments->splitAssignments,
		NMRFunctionalGroup->splitFuncGroups,
		PeakGroupDomains->pkGroupDomains,
		PeakIntegralNormalizationGroup->pkGroupNormalization,
		PeakGroupMultiplicity->pkMultiplicity
	}
];

(* Divides peaks into groups, splitting where the distance between adjacent peaks exceeds a threshold *)
splitByThreshold[pkData:{{_?NumericQ,_?NumericQ}..},splittingThreshold:UnitsP[PPM]]:=Module[
	{pkPos,pkAreas,pkSpacings,pkSplitIndices,pkSplitIndicesPadded,pkSplitSpans,pkGroups,pkGroupShifts,pkGroupDomains},

	(* Isolate peak positions, heights, and areas from peak data input *)
	{pkPos,pkAreas}=Transpose[pkData];

	(* Compute distances between adjacent peaks *)
	pkSpacings=Differences[pkPos];

	(* Get the index of each peak spacing which exceeds the maximum J splitting threshold *)
	pkSplitIndices=Position[pkSpacings,_?(#>Unitless[splittingThreshold]&)];

	(* Pad the indices with a divider before the first peak, and after the last peak *)
	pkSplitIndicesPadded=Flatten[{0,pkSplitIndices,Length[pkData]}];

	(* Generate a list of index spans corresponding to peaks separated by a distance greater than MaximumJSplitting *)
	pkSplitSpans=Most@MapThread[Span[#+1,#2]&,{pkSplitIndicesPadded,RotateLeft[pkSplitIndicesPadded]}];

	(* Slice the peak data using the spans to split the peaks into groups *)
	pkGroups=pkData[[#]]&/@pkSplitSpans;

	(* Extract the minimum and maximum chemical shift from each peak groups *)
	pkGroupShiftBounds=Map[
		MinMax[(1.0 PPM)*First/@#]&,
		pkGroups
	];

	(* Pad each shift range with threshold/10, then convert each set of bounds to a span *)
	pkGroupDomains=Map[
		Span@@SafeRound[(#+splittingThreshold/{-2.2,2.2}),0.001]&,
		pkGroupShiftBounds
	];

	(* Return the split peak groupings, their domains, and convert indexx spans into actual integers *)
	{pkGroups,pkGroupDomains,Range@@@pkSplitSpans}
];

(* Return empty lists if the input peak data is empty *)
splitByThreshold[pkData:{},splittingThreshold_]:={{},{},{}};

(* Given a list of non-overlapping PPM spans, divide peaks into groups based on the spans. *)
splitByDomains[
	pkData:{{_?NumericQ,_?NumericQ}..},
	pkDomains:{Span[UnitsP[PPM],UnitsP[PPM]]..},
	splittingThreshold:UnitsP[PPM]
]:=Module[
	{
		myPkGroups,emptySpans,nonEmptyPkDomains,cleanedPkGroups,pkIndices,unassignedPks,unassignedPkGroups,
		unassignedDomains,unassignedIndices,joinedPkGroups,joinedPkDomains,
		indexInsertHelper,joinedIndices
	},

	(* Group peak data by the provided input spans. If there are no peaks in a span, return {{First[emptySpan]}} to help with sorting. *)
	myPkGroups=Map[
		Function[{pkSpan},
			Select[pkData,spanContainsQ[pkSpan,First[#]]&]/.({}->{{Unitless@First[pkSpan]}})
		],
		pkDomains
	];

	(* Get the indices of the peaks in each peak group *)
	pkIndices=Map[
		Function[{peakGroup},
			Flatten[Position[pkData,#]&/@peakGroup]
		],
		myPkGroups
	];

	(* Collect any pkDomains in which no peaks were found *)
	emptySpans=Part[
		pkDomains,
		Flatten@Position[myPkGroups,{{UnitsP[PPM]}}]
	];

	(* Remove the empty spans *)
	nonEmptyPkDomains=DeleteCases[pkDomains,Alternatives@@emptySpans];

	(* Warn the user if any of the supplied spans are empty *)
	If[Length[emptySpans]>0,
		Message[Warning::EmptySplittingDomain,emptySpans]
	];

	(* List of peaks which were not assigned based on the supplied peak domains. *)
	unassignedPks=Complement[pkData,Flatten[myPkGroups,1]];

	(* For peaks which were not supplied by the user option, split by threshold *)
	{unassignedPkGroups,unassignedDomains,unassignedIndices}=splitByThreshold[unassignedPks,splittingThreshold];

	(* Join the provided peak groups with the unassigned pkGroups, sorting by chemical shift. Get rid of the {{SpanStart PPM}} wildcard for empty spans. *)
	joinedPkGroups=SortBy[Join[myPkGroups,unassignedPkGroups],First[First[#]]&]/.({{UnitsP[PPM]}}->{});

	(* Join the newly identified peak domains with option-supplied pkDomains *)
	joinedPkDomains=SortBy[Join[nonEmptyPkDomains,unassignedDomains],First];

	(* The subfunction call to splitByThreshold returns indices for the subset of unassigned peaks. This helper function fixes those indices. *)
	indexInsertHelper[autoList:{{_Integer..}..},idxGroup:{(_Integer|None)..}]:=Module[
		{insertIdx},

		(* Index to insert identified group at. If not found in list, append to end. *)
		insertIdx=(Sequence@@FirstPosition[
			First/@autoList,
			_?(#==First[idxGroup]&)
		])/.{"NotFound"->(Length[autoList]+1)};

		(* Insert idxGroup into autoList at correct position, offsetting the following elements *)
		Insert[
			Join[
				autoList[[;;insertIdx-1]],
				autoList[[insertIdx;;]]+Length[idxGroup]
			],
			idxGroup,
			insertIdx
		]
	];

	(* If the first list is empty, return the second *)
	indexInsertHelper[emptyList:{},idxGroup:{(_Integer|None)..}]:={idxGroup};

	(* Join the newly identified peak indices with option-supplied indices, correcting indices and sorting by PPM *)
	joinedIndices=Fold[indexInsertHelper,
		unassignedIndices,
		SortBy[(pkIndices/.Rule[{},Nothing]),First]
	];

	(* Return the peak groups and peak domains *)
	{joinedPkGroups,joinedPkDomains,joinedIndices}
];

(* Return empty lists of the input data or domains are empty *)
splitByDomains[pkData:{},pkDomains_,threshold_]={{},{},{}};
splitByDomains[pkData_,pkDomains:{},threshold_]={{},{},{}};

(* Helper function to check if a PPM span contains a unitless number (PPM units will be added) *)
spanContainsQ[s_Span,n:_?NumericQ]:=And[(n*PPM)>=First[s],(n*PPM)<=Last[s]];
spanContainsQ[s_Span,n:UnitsP[PPM]]:=And[n>=First[s],n<=Last[s]];
spanContainsQ[sp1_Span,sp2_Span]:=And[First[sp2]>=First[sp1],Last[sp2]<=Last[sp1]];

(* Given a group of peaks, assign it a splitting pattern, defaulting to generic 'Multiplet' if nothing can be assigned. *)
assignSplitting[
	pkGroup:{{_?NumericQ,_?NumericQ}..},
	spacingTolerance:_?NumericQ,
	relativeIntegralTolerance:_?NumericQ
]:=Module[
	{simpleSplit,multiSplit},

	(* First, check if the peak group has a simple, first-order splitting pattern *)
	simpleSplit=checkSimpleSplitting[pkGroup,spacingTolerance,relativeIntegralTolerance];

	(* If the peak group is a simple splitting, e.g. doublet/triplet/etc., return early *)
	If[MatchQ[simpleSplit,Except[False]],Return[simpleSplit]];

	(* Recursively check if the peak group is a multiple splitting, e.g. doublet of triplets. *)
	multiSplit=checkMultiSplitting[pkGroup,spacingTolerance,relativeIntegralTolerance];

	(* If the peak group is identified as a multiple splitting, return early *)
	If[MatchQ[multiSplit,Except[False]],Return[multiSplit]];

	(* If no identification was possible, return a generic multiplet *)
	formatMultiplet[pkGroup]
];

(* If the peak group is empty, return None *)
assignSplitting[emptyPkGroup:{},spacingTolerance_,relativeIntegralTolerance_]:={None};

(* Given a group of peaks, check if it is a simple multiplet *)
checkSimpleSplitting[
	pkGroup:{{Repeated[_?NumericQ,{2}]}..},
	spacingTolerance:_?NumericQ,
	relativeIntegralTolerance:_?NumericQ
]:=Module[
	{
		numPeaks,pkLocations,pkSpacings,JSplitting,uniformSpacingQ,
		pkAreas,totalArea,expectedAreaRatio,normalizedAreas,normalAreaRatioQ
	},

	(* Get number of peaks in peak group *)
	numPeaks=Length[pkGroup];

	(* Get the locations of each peak in the peak group *)
	pkLocations=First/@pkGroup;

	(* Get the distance between adjacent peaks in the peak group *)
	pkSpacings=Differences[pkLocations];

	(* Get the J splitting factor for the simple multiplet *)
	JSplitting=If[numPeaks==1,
		Nothing,
		Mean[pkSpacings]
	];

	(* True if the peak spacing is uniform. This is true by default if there are only one or two peaks. *)
	uniformSpacingQ=If[numPeaks>2,
		((Max[pkSpacings]-Min[pkSpacings])/Min[pkSpacings]<spacingTolerance),
		True
	];

	(* Get the area of each peak in the peak group *)
	pkAreas=Last/@pkGroup;

	(* Get the total peak area of all the peaks in the peak group *)
	totalArea=Total[pkAreas];

	(* The ratio of expected peak areas in the multiplet, from Pascal's triangle *)
	expectedAreaRatio=Table[Binomial[numPeaks-1,i],{i,0,numPeaks-1}];

	(* The normalized areas should all be approximately the same reduced value if the multiplet is clean *)
	normalizedAreas=MapThread[(#1/(Total[pkAreas]*#2))&,{pkAreas,expectedAreaRatio}];

	(* True if the peak areas are in the expected ratios for a simple multiplet *)
	normalAreaRatioQ=If[numPeaks>1,
		((Max[normalizedAreas]-Min[normalizedAreas])/Min[normalizedAreas]<relativeIntegralTolerance),
		True
	];

	(* Return the multiplet information if checks pass, otherwise return False. *)
	If[uniformSpacingQ&&normalAreaRatioQ,
		{Mean[pkLocations],{numPeaks},totalArea,{JSplitting}},
		False
	]
];

(* Recursively check if the peak group is a multiple splitting, e.g. doublet of triplets. *)
checkMultiSplitting[
	pkGroup:{{Repeated[_?NumericQ,{2}]}..},
	spacingTolerance:_?NumericQ,
	relativeIntegralTolerance:_?NumericQ
]:=Module[
	{
		numPeaks,pkLocations,pkDistMatrix,pkDistMatrixIndices,pkDistUpperTriangle,
		uniquePeakSpacings,gatheredPeakSpacings,gatheredPeakIndices,
		potentialSubsplitIndices,validSubsplitIndices,subsplits,finalSubsplits,
		subMultJSplit,mainSplits,finalSplits
	},

	(* Number of peaks in the peak group being analyzed *)
	numPeaks=Length[pkGroup];

	(* Get the locations of each peak in the peak group *)
	pkLocations=First/@pkGroup;

	(* Compute the distance matrix for all possible peak separations *)
	pkDistMatrix=DistanceMatrix[pkLocations];

	(* Generate indices describing the peaks separated by dist in pkDistMatrix *)
	pkDistMatrixIndices=Outer[{#1,#2}&,Range[numPeaks],Range[numPeaks]];

	(* The upper triangular portion of the distance matrix, with entries {peak i, peak j}->distance *)
	pkDistUpperTriangle=UpperTriangularize@MapThread[
		MapThread[Function[{dist,indices},indices->dist],{#1,#2}]&,
		{pkDistMatrix,pkDistMatrixIndices}
	];

	(* A list of all unique, non-zero peak spacings with the format {peak i, peak j}->distance *)
	uniquePeakSpacings=DeleteCases[Flatten[pkDistUpperTriangle],0.|(_->0.)];

	(* Gather pairs of peaks with similar spacings. The most common spacings appear first in the list. *)
	gatheredPeakSpacings=Reverse@SortBy[
		Gather[uniquePeakSpacings,Abs[Last[#1]-Last[#2]]/(Min[Last[#1],Last[#2]])<(2.*spacingTolerance)&],
		Length
	];

	(* Extract only the {peak i, peak j} indices from the gathered peak spacings *)
	gatheredPeakIndices=Map[Function[{group},First/@group],gatheredPeakSpacings];

	(* List of potential ways to decompose the peak group into several multiplets *)
	potentialSubsplitIndices=findContiguousSplittings/@gatheredPeakIndices;

	(* A valid subsplitting must include all peaks and consist of subsplittings of the same multiplicity *)
	validSubsplitIndices=Select[potentialSubsplitIndices,
		And[(Length[Flatten[#]]==numPeaks),(Length[Union[Length/@#]]==1)]&
	];

	(* Check if each subsplitting is a simple multiplet. Outer map is over list of valid subsplittings. *)
	subsplits=Map[
		(* Inner map is over each splitting in the list of valid subsplittings. *)
		Map[
			Function[{pkIndices},
				checkSimpleSplitting[pkGroup[[pkIndices]],spacingTolerance,relativeIntegralTolerance]
			],
			#
		]&,
		validSubsplitIndices
	];

	(* Select only splittings where each subsplit is as a simple splitting *)
	finalSubsplits=Select[subsplits,!MemberQ[#,False]&];

	(* The multiplicity of subsplittings (e.g. 3 for a doublet of triplets), and the average J factor among them *)
	subMultJSplit=Map[
		Function[{splitData},
			{First[Part[#,2]&/@splitData],Mean[Part[#,4]&/@splitData]}
		],
		finalSubsplits
	];

	(* TODO: Make recursive, switch checkSimpleSplitting -> assignSplitting *)
	(* Given valid subsplits (e.g. multiple triplets), check that they follow a regular splitting pattern *)
	mainSplits=Map[
		Function[{splitData},
			checkSimpleSplitting[
				Part[#,{1,3}]&/@splitData,
				spacingTolerance,
				relativeIntegralTolerance
			]
		],
		finalSubsplits
	];

	(* Final nested splitting assignments *)
	finalSplits=MapThread[
		If[MatchQ[#1,False],
			Nothing,
			{
				#1[[1]],
				Join[#1[[2]],First[#2]],
				#1[[3]],
				Join[#1[[4]],Last[#2]]}
		]&,
		{mainSplits,subMultJSplit}
	];

	(* Return false if there were no valid nested splittings, otherwise return the first valid assignment *)
	If[MatchQ[finalSplits,{}],
		False,
		First[finalSplits]
	]
];


(* Initialize contiguousRuns as an empty list, and if the input list is empty, return all contiguous runs *)
findContiguousSplittings[idxPairList:{{_Integer,_Integer}..}]:=findContiguousSplittings[idxPairList,{}];
findContiguousSplittings[idxPairList:{},contiguousRuns:{{_Integer..}...}]:=contiguousRuns;

(* Given a list of index pairs representing equal splitting, groups adjacent indices (e.g. {{1,4},{2,3},{4,5}} -> {1,4,5},{2,3} *)
findContiguousSplittings[idxPairList:{{_Integer,_Integer}..},contiguousRuns:{{_Integer..}...}]:=Module[
	{contiguousRun,usedIdxPairs,leftovers},

	(* Check the first element for contiguous splittings *)
	contiguousRun=Fold[
		If[Last[#1]==First[#2],Append[#1,Last[#2]],#1]&,
		idxPairList
	];

	(* Elements in idxPairList which were used to construct the contiguous run *)
	usedIdxPairs=Most@Transpose[{contiguousRun,RotateLeft@contiguousRun}];

	(* Elements in idxPairList which were not incorporated into the contiguous run *)
	leftovers=Complement[idxPairList,usedIdxPairs];

	(* Recursive call until the input list is empty *)
	findContiguousSplittings[leftovers,Append[contiguousRuns,contiguousRun]]
];

(* Given a group of peaks, assign them a generic multiplet when no further identification is possible *)
formatMultiplet[pkGroup:{{_?NumericQ,_?NumericQ}..}]:=Module[
	{chemicalShifts,chemicalShiftRange,peakAreas},

	(* List of chemical shifts for each peak in the peak group *)
	chemicalShifts=First/@pkGroup;

	(* Construct a span of chemical shifts for the multiplet *)
	chemicalShiftRange=Span[Min[chemicalShifts],Max[chemicalShifts]];

	(* List of areas of each peak in the peak group *)
	peakAreas=Last/@pkGroup;

	(* Output {shift,multiplicity,totalarea,J} for the multiplet *)
	{chemicalShiftRange,{"m"},Total[peakAreas],{}}
];

(* Normalize peak group integrals based on the value of the option PeakIntegralNormalizationGroup *)
normalizePeakGroups[
	rawSplittings:{(None|{Repeated[_,4]})..},
	pkNormalization:Automatic|{_Integer,GreaterP[0.0]}
]:=Module[
	{rawPeakIntegrals,refGroup,refArea,normalizationConstant,normalizedSplits},

	(* Extract the area of each peak splitting group *)
	rawPeakIntegrals=Part[Transpose[rawSplittings/.({None}->Nothing)],3];

	(* Get the index of the peak splitting group used as a reference for normalization, and its reference area  *)
	{refGroup,refArea}=If[MatchQ[pkNormalization,Automatic],
		(* If option was Automatic, find the normalization which makes all peak areas as close to integers as possible *)
		bestNormalizationGroup[rawPeakIntegrals],
		(* Use option directly if it was specified *)
		pkNormalization
	];

	(* Calculate the normalization constant *)
	normalizationConstant=Part[rawPeakIntegrals,refGroup]/refArea;

	(* Normalize the raw splittings *)
	normalizedSplits=Map[
		Function[{split},
			{
				split[[1]],
				split[[2]],
				split[[3]]/normalizationConstant,
				split[[4]]
			}
		],
		DeleteCases[rawSplittings,{None}]
	];

	(* Return the normalized splits and the resolved normalization option *)
	{
		normalizedSplits,
		{refGroup,refArea}
	}
];

(* Given a list of peak areas, returns the {index, normalized area} of the peak group which results in all normalized areas being as close to integers as possible *)
bestNormalizationGroup[areas:{_?NumericQ..}]:=Module[
	{candidateNormalizationConstants,integernessScores,minPosition},

	(* For each area, compute the normalization constants which result in a normalized area of 1.0, 2.0, and 3.0 *)
	candidateNormalizationConstants=Map[
		Function[{singleArea},(singleArea/#)&/@{1,2,3}],
		areas
	];

	(* For each candidate constant, assign a score (lower is better) based on how close the normalized areas are to integers *)
	integernessScores=Map[
		Function[{constants},scoreIntegerness[areas/#]&/@constants],
		candidateNormalizationConstants
	];

	(* Position of the best (lowest) integerness score *)
	minPosition=Flatten@Position[integernessScores,Min[integernessScores]];

	(* Return the {index, normalized area} of the best normalization *)
	{First[minPosition],N@Last[minPosition]}
];

(* Mean squared displacement between a list of numbers and the closest integers to them *)
scoreIntegerness[xlist:{_?NumericQ..}]:=Total[(Round[xlist,1]-xlist)^2];

(* If the Peak Multiplicity option is not specified, then convert splittings spans to PPM and return without further updates *)
applyPeakGroupMultiplicity[rawSplittings_,pkGroups_,spacingTol_,areaTol_,Automatic|Null]:=rawSplittings/.{
	{shift:_?NumericQ,rest___}:>{shift*PPM,rest},
	{shiftSpan:_Span,rest___}:>{(PPM*#)&/@shiftSpan,rest}
};

(* Apply user-specified multiplicities and recalculate J-factors accordingly *)
applyPeakGroupMultiplicity[
	rawSplittings:{(None|{Repeated[_,4]})..},
	pkGroups:{{{_?NumericQ,_?NumericQ}...}..},
	spacingTolerance:_?NumericQ,
	relativeIntegralTolerance:_?NumericQ,
  pkMultiplicity:{(ListableP[_Integer|"m"]|multiplicityStringP)...}
]:=Module[
	{
		integerMults,paddedMults,multiplicityChecks,
		rawPeakCounts,peakCountChecks,mismatchedPeakCounts,
		resolvedMults,splitsToUpdate,resolvedJs
	},

	(* Check that each entry in pkMultiplicity is valid. *)
	multiplicityChecks=Function[{singleMult},
		If[!MatchQ[singleMult,multiplicityStringP]&&Length[singleMult]>1,
			And@@(((#>1)===True)&/@singleMult),
			True
		]
	]/@pkMultiplicity;

	(* If any of the multiplicities in PeakGroupMultiplicity are invalid, then throw an invalid option error *)
	If[!(And@@multiplicityChecks),
		Message[Error::InvalidMultiplicity,pkMultiplicity];
		Message[Error::InvalidOption,PeakGroupMultiplicity];
	];

	(* Convert all multiplicity specifications into listed integer format *)
	integerMults=pkMultiplicity/.multiplicityStringToIntegerRules;

	(* Check that the length of the PeakGroupMultiplicity option matches the number of splitting groups *)
	If[Length[pkMultiplicity]=!=Length[rawSplittings],
		Message[Warning::PeakGroupMultiplicityMismatch,Length[pkMultiplicity],Length[rawSplittings]];
	];

	(* Pad the peak multiplicity option in case there was a length mismatch *)
	paddedMults=PadRight[integerMults,Length[rawSplittings],Null];

	(* Get the number of peaks identified in each peak group *)
	rawPeakCounts=Length/@pkGroups;

	(* For each splitting, verify that the number of identified peaks is consistent with the specified multiplicity *)
	peakCountChecks=MapThread[
		Switch[#1,
			(* If multiplicity was multiplet, anything goes *)
			{"m"},True,

			(* If multiplicity was singlet, then the number of peaks should match exactly *)
			{_Integer},First[#1]===#2,

			(* For multiple splitting patterns, the number of peaks should be greater than (max splitting + #splits), and less than the product of splittings *)
			{_Integer..},And[#2>=(Max[#1]+(Length[#1]-1)), #2<=Times@@#1],

			(* Skip padded entries *)
			Null,True
		]&,
		{paddedMults,rawPeakCounts}
	];

	(* List of multiplicity specifications inconsistent with peak counts *)
	mismatchedPeakCounts=Part[paddedMults,Flatten@Position[peakCountChecks,False]];

	(* Warn the user if the number of peaks in groups is inconsistent with the provided multiplicites *)
	If[Not[And@@peakCountChecks],
		Message[Warning::MismatchedPeakCounts,
			mismatchedPeakCounts/.(Reverse/@multiplicityStringToIntegerRules),
			Flatten@Position[peakCountChecks,False],
			Part[rawPeakCounts,Flatten@Position[peakCountChecks,False]]
		]
	];

	(* A list of peak groups whose automatic multiplicities will be changed by the PeakGroupMultiplicity option *)
	splitsToUpdate=MapThread[
		If[!MatchQ[#2,Null]&&Part[#1,2]=!=#2,
			#3,
			Null
		]&,
		{rawSplittings,paddedMults,pkGroups}
	];

	(* Recompute J-coupling constants according to new assignments, returning Null if the old value should be used *)
	resolvedJs=MapThread[
		computeNewJCoupling[#1,#2,spacingTolerance,relativeIntegralTolerance]&,
		{splitsToUpdate,paddedMults}
	];

	(* Update rawSplittings with the resolved multiplicities and J Couplings *)
	MapThread[
		Function[{split,newMult,newJ},
			{
				(* Append PPM units to the chemical shift *)
				If[MatchQ[split[[1]],_Span],(PPM*#)&/@split[[1]],PPM*split[[1]]],
				(* Use the old (default) multiplicity if the new multiplicity has not been specified *)
				If[MatchQ[newMult,Null],split[[2]],newMult],
				(* Do not change normalized integrals *)
				split[[3]],
				(* Use the old (default) multiplicity if J recalculation is not required *)
				If[MatchQ[newJ,Null],split[[4]],newJ]
			}
		],
		{rawSplittings,paddedMults,resolvedJs}
	]
];

(* Null indicates that the J-coupling recalculation is not required, and the old value will be used *)
computeNewJCoupling[Null|{},_,_,_]:=Null;
computeNewJCoupling[_,Null,_,_]:=Null;

(* If the group is identified as a singlet or generic multiplet, then return no J-couplings *)
computeNewJCoupling[_,{1}|{"m"},_,_]:={};

(* Single splitting overload *)
computeNewJCoupling[
	pkGroup:{{_?NumericQ,_?NumericQ}..},
  pkMultiplicity:{GreaterP[0,1]},
	spacingTolerance:_?NumericQ,
	relativeIntegralTolerance:_?NumericQ
]:=Module[
	{numPeaks,userMult,pkSpacings,pkAreas,expectedAreaRatio,normalizedAreas},

	(* Number of peaks in the peak group*)
	numPeaks=Length[pkGroup];

	(* The type of multiplicity the user wants to identify this peak group as *)
	userMult=pkMultiplicity/.(Reverse/@multiplicityStringToIntegerRules);

	(* Return an empty list if the number of peaks does not match. See Warning::MismatchedPeakCounts. *)
	If[numPeaks=!=First[pkMultiplicity],
		Return[{}]
	];

	(* Spacing between adjacent peaks *)
	pkSpacings=Differences[First/@pkGroup];

	(* Area of each peak in the peak group *)
	pkAreas=Last/@pkGroup;

	(* Warn the user if the spacing tolerance has not been met *)
	If[((Max[pkSpacings]-Min[pkSpacings])/Min[pkSpacings]>spacingTolerance),
		Message[Warning::SpacingToleranceExceeded,userMult,Reverse@SafeRound[PPM*(First/@pkGroup),0.001 PPM]]
	];

	(* The ratio of expected peak areas in the multiplet, from Pascal's triangle *)
	expectedAreaRatio=Table[Binomial[numPeaks-1,i],{i,0,numPeaks-1}];

	(* The normalized areas should all be approximately the same reduced value if the multiplet is clean *)
	normalizedAreas=MapThread[(#1/(Total[pkAreas]*#2))&,{pkAreas,expectedAreaRatio}];

	(* Warn the user if the area tolerance has not been met *)
	If[((Max[normalizedAreas]-Min[normalizedAreas])/Min[normalizedAreas]>relativeIntegralTolerance),
		Message[Warning::AreaToleranceExceeded,userMult,Reverse@SafeRound[PPM*(First/@pkGroup),0.001 PPM],Reverse@pkAreas/First[pkAreas]]
	];

	(* Return the average spacing between adjacent peaks *)
	{Mean[pkSpacings]}
];

(* Multiple splitting overload *)
computeNewJCoupling[
	pkGroup:{{_?NumericQ,_?NumericQ}..},
  pkMultiplicity:{GreaterP[1,1],GreaterP[1,1]..},
	spacingTolerance:_?NumericQ,
	relativeIntegralTolerance:_?NumericQ
]:=Module[
	{numPeaks,userMult,pkPositions,partitions,pkSpacingsPerLevel,pkSpacingTests},

	(* Number of peaks in the peak group*)
	numPeaks=Length[pkGroup];

	(* The type of multiplicity the user wants to identify this peak group as *)
	userMult=pkMultiplicity/.(Reverse/@multiplicityStringToIntegerRules);

	(* If peaks overlap (i.e. a convoluted multiple splitting pattern), return a warning since this isn't supported yet *)
	If[numPeaks=!=(Times@@pkMultiplicity),
		Message[Warning::ReverseComplexCoupling,Times@@pkMultiplicity,userMult,numPeaks];
		Return[{}]
	];

	(* Extract peak positions from the peak group *)
	pkPositions=First/@pkGroup;

	(* Recursively partition according to the multiple splitting *)
	partitions=Rest@FoldList[
		Partition[(Mean/@#1),#2]&,
		List/@pkPositions,
		Reverse@pkMultiplicity
	];

	(* Peak Spacings per level of the multiple splitting  *)
	pkSpacingsPerLevel=Map[
		Flatten[Differences/@#]&,
		partitions
	];

	(* Test spacings for consistency at each level *)
	pkSpacingTests=Map[
		(((Max[#]-Min[#])/Min[#])<spacingTolerance)&,
		pkSpacingsPerLevel
	];

	(* Warn the user if the spacing tolerance has not been met *)
	If[!(And@@pkSpacingTests),
		Message[Warning::SpacingToleranceExceeded,userMult,Reverse@SafeRound[PPM*(First/@pkGroup),0.001 PPM]]
	];

	(* Return the J-coupling constants *)
	Reverse[Mean/@pkSpacingsPerLevel]
];

(* Catch-all overload *)
computeNewJCoupling[pkGroup:{{_?NumericQ,_?NumericQ}...},_,_,_]:={};

(* Resolve the Peak Multiplicity option for return in the builder *)
resolvePeakGroupMultiplicity[updatedSplittings:{(None|{Repeated[_,4]})..}]:=Module[
	{updatedMults},

	(* Pull updated multiplicites from the *)
	updatedMults=Part[#,2]&/@updatedSplittings;

	(* Convert back to text labels when possible *)
	updatedMults/.(Reverse/@multiplicityStringToIntegerRules)
];

(* Helper function to assign peak indices to labels, when multiple labels map to the same splitting group *)
dividePeaksAmongLabels[oldPkIdxs_,labels_]:=Module[
	{mults,pkCounts,newPkIdxs,pkSpans,paddedIdxs,idxAssignments},

	(* Multiplicity of each label in labels *)
	mults=Part[#,2]&/@labels;

	(* Number of peaks in each label *)
	pkCounts=(Times@@(#/.{"m"->0}))&/@mults;

	(* Cumulative sum of pkCounts are indices *)
	newPkIdxs=Accumulate[pkCounts];

	(* Consecutive spans containing the correct number of peaks *)
	pkSpans=MapThread[
		Span[Mod[#1,Total[pkCounts]]+1,#2]&,
		{RotateRight[newPkIdxs],newPkIdxs}
	];

	(* Pad the input indexes to match peak counts. *)
	paddedIdxs=PadRight[oldPkIdxs,Total[pkCounts],None];

	(* Index assignments *)
	idxAssignments=Part[paddedIdxs,#]&/@pkSpans;

	(* Replace None placeholders with Nothing, and return as a sequence *)
	idxAssignments/.{None->Nothing}
];

(* Round chemical shifts to the nearest 0.01 PPM, try to convert integrations to integers, and convert J-splittings to Hz *)
formatSplitting[
	singleSplit:{Span[UnitsP[PPM],UnitsP[PPM]]|UnitsP[PPM],{"m"}|{_Integer..},_?NumericQ,{(_?NumericQ|UnitsP[Hertz])...}},
	opFrequency_
]:=Module[
	{chemicalShift,multis,roundedTotalArea,Jfactors,roundedShift,scaledTotalArea,opFrequencyFactor,JfactorsHz},

	(* Pull individual components from the peak assignment *)
	{chemicalShift,multis,totalArea,Jfactors}=singleSplit;

	(* Round the chemical shift to the nearest 0.1 PPM *)
	roundedShift=If[MatchQ[chemicalShift,_Span],
		Span[
			Round[First@chemicalShift,0.01 PPM],
			Round[Last@chemicalShift,0.01 PPM]
		],
		Round[chemicalShift,0.01 PPM]
	];

	(* Round the integral of each peak to the nearest hundreth. These should be integers. *)
	roundedTotalArea=Round[totalArea,0.01];

	(* NMR Instrument Operating Frequency, in units of 10^6 Hertz *)
	opFrequencyFactor=UnitConvert[opFrequency/(10^6),Hertz];

	(* Convert J-splittings from PPM to Hertz *)
	JfactorsHz=Map[
		If[MatchQ[#,UnitsP[Hertz]],
			#,
			(Round[#*opFrequencyFactor,0.01 Hertz])
		]&,
		Jfactors
	];

	(* Return the formatted peak assignment *)
	{roundedShift,multis,roundedTotalArea,JfactorsHz}
];

(* Listable overload *)
formatSplitting[pkSplittings:{({}|{Repeated[_,4]})..},opFrequency_]:=formatSplitting[#,opFrequency]&/@pkSplittings;

(* If the splitting group is empty return nothing *)
formatSplitting[singleSplit:{},opFreq_]:=Nothing;


(* ::Subsubsection::Closed:: *)
(* NMR Structure information - match chemical structure to expected chemical shift range, multiplicity, etc. *)

(*** 1H NMR ***)
(* Define useful atomic patterns *)
wildcardP=Atom["AtomicNumber"->GreaterThan[0]];
nonHydrogenP=Atom["AtomicNumber"->GreaterThan[2]];

(* Molecule Patterns for 1H NMR Substructures *)
TMSP=MoleculePattern[{"Si","C","C","C","C","H","H","H","H","H","H","H","H","H","H","H","H"},
	{
		Bond[{1,2}],Bond[{1,3}],Bond[{1,4}],Bond[{1,5}],
		Bond[{2,6}],Bond[{2,7}],Bond[{2,8}],
		Bond[{3,9}],Bond[{3,10}],Bond[{3,11}],
		Bond[{4,12}],Bond[{4,13}],Bond[{4,14}],
		Bond[{5,15}],Bond[{5,16}],Bond[{5,17}]
	}
];
CH3P=MoleculePattern[{"C","H","H","H"},{Bond[{1,2}],Bond[{1,3}],Bond[{1,4}]}];
CH2P=MoleculePattern[{"C","H","H"},{Bond[{1,2}],Bond[{1,3}]}];
CHP=MoleculePattern[{"C","H"},{Bond[{1,2}]}];
fluorineCP=MoleculePattern[{"F","C","H"},{Bond[{1,2}],Bond[{2,3}]}];
chlorineCP=MoleculePattern[{"Cl","C","H"},{Bond[{1,2}],Bond[{2,3}]}];
bromineCP=MoleculePattern[{"Br","C","H"},{Bond[{1,2}],Bond[{2,3}]}];
iodineCP=MoleculePattern[{"I","C","H"},{Bond[{1,2}],Bond[{2,3}]}];
etherP=MoleculePattern[{"O","C","H"},{Bond[{1,2}],Bond[{2,3}]}];
allylP=MoleculePattern[{"C","C","C","H"},{Bond[{1,2},"Double"],Bond[{2,3}],Bond[{3,4}]}];
vinylP=MoleculePattern[{"C","C","H"},{Bond[{1,2},"Double"],Bond[{2,3}]}];
alkynylP=MoleculePattern[{"C","C","H"},{Bond[{1,2},"Triple"],Bond[{2,3}]}];
ketoneP=MoleculePattern[{"O","C","C","H"},{Bond[{1,2},"Double"],Bond[{2,3}],Bond[{3,4}]}];
aldehydeP=MoleculePattern[{"O","C","H"},{Bond[{1,2},"Double"],Bond[{2,3}]}];
adjNP=MoleculePattern[{"N","C","H"},{Bond[{1,2}],Bond[{2,3}]}];
aromaticP=MoleculePattern[{"C","C","H"},{Bond[{1,2},"Aromatic"],Bond[{2,3}]}];
adjAromaticP=MoleculePattern[{"C","C","C","C","H"},{Bond[{1,2},"Aromatic"],Bond[{2,3},"Aromatic"],Bond[{2,4}],Bond[{4,5}]}];
alcoholP=MoleculePattern[{"O","H"},{Bond[{1,2}]}];
phenolP=MoleculePattern[{"C","C","O","H"},{Bond[{1,2},"Aromatic"],Bond[{2,3}],Bond[{3,4}]}];
carboxyP=MoleculePattern[{"C","O","O","H"},{Bond[{1,2},"Double"],Bond[{1,3}],Bond[{3,4}]}];
amineP=MoleculePattern[{"N","H"},{Bond[{1,2}]}];
anilineP=MoleculePattern[{"C","C","N","H","H"},{Bond[{1,2},"Aromatic"],Bond[{2,3}],Bond[{3,4}],Bond[{3,5}]}];
amideP=MoleculePattern[{"C","O","N","H"},{Bond[{1,2},"Double"],Bond[{1,3}],Bond[{3,4}]}];
aminoAlphaP=MoleculePattern[{"C","O","O","C","H","N"},{Bond[{1,2},"Double"],Bond[{1,3}],Bond[{1,4}],Bond[{4,5}],Bond[{4,6}]}];

(* Given a molecule and molecule pattern, get the indices of atoms in the molecule which match the pattern *)
findSubstructureH[mol_Molecule,mp_MoleculePattern]:=Module[
	{substructs,subHindices},

	(* List of associations mapping substructure indicies to molecule indices *)
	substructs=FindMoleculeSubstructure[mol,mp,All];

	(* Substructure indices of any hydrogen atoms *)
	subHindices=Flatten@Position[First[mp],"H"];

	(* Return molecular indices of hydrogens matching pattern *)
	Flatten[Lookup[#,subHindices]&/@substructs]
];

(* Given a molecule and the indices of hydrogens, return the expected chemical shift of the 1H NMR signal *)
chemicalShiftRangeH[mol_Molecule,inds:{_Integer..}]:=Module[
	{stdMol,indsInPatternQ},

	(* Standardize the molecule input so that aromatic bonds are highlighted *)
	stdMol=Molecule[mol,IncludeAromaticBonds->True];

	(* Helper function checks if the hydrogens specified by inds correspond to the molecule pattern mp *)
	indsInPatternQ[mp_MoleculePattern]:=Apply[And,
		MemberQ[findSubstructureH[mol,mp],#]&/@inds
	];

	(* Check membership of each of the functional groups in order of most to least specific. *)
	Which[
		(* TMS is defined to have a chemical shift of zero *)
		indsInPatternQ[TMSP],{Span[-0.1PPM,0.1PPM],TMSP},

		(*** Hydrogens on Oxygen/Hydrogen. These interchange rapidly and often do not appear in spectra ***)

		(* Carboxylic acid hydrogen *)
		indsInPatternQ[carboxyP],{Span[10.0PPM,13.0PPM],carboxyP},

		(* Phenol hydrogen (close to aromatics) *)
		indsInPatternQ[phenolP],{Span[4.0PPM,7.0PPM],phenolP},

		(* Alcohol hydrogen *)
		indsInPatternQ[alcoholP],{Span[-1.0PPM,-0.5PPM](*Span[0.5PPM,5.0PPM]*),alcoholP},

		(* Amide hydrogen *)
		indsInPatternQ[amideP],{Span[5.0PPM,9.0PPM],amideP},

		(* Aniline hydrogen *)
		indsInPatternQ[anilineP],{Span[3.0PPM,5.0PPM],anilineP},

		(* Amine hydrogen *)
		indsInPatternQ[amineP],{Span[-1.0PPM,-0.5PPM](*Span[0.5PPM,5.0PPM]*),amineP},

		(*** Hydrogens on Carbon ***)

		(* Hydrogen on an aromatic carbon *)
		indsInPatternQ[aromaticP],{Span[6.5PPM,8.0PPM],aromaticP},

		(* Hydrogen on a carbon bonded to an aromatic carbon *)
		indsInPatternQ[adjAromaticP],{Span[2.2PPM,3.5PPM],adjAromaticP},

		(* Alpha carbon in an amino acid *)
		indsInPatternQ[aminoAlphaP],{Span[3.5PPM,4.1PPM],aminoAlphaP},

		(* Aldehyde hydrogen *)
		indsInPatternQ[aldehydeP],{Span[9.0PPM,10.0PPM],aldehydeP},

		(* Alkynyl C#C-H hydrogen  *)
		indsInPatternQ[alkynylP],{Span[2.3PPM,2.7PPM],alkynylP},

		(* Hydrogen on carbon next to oxygen *)
		indsInPatternQ[etherP],{Span[3.2PPM,4.3PPM],etherP},

		(* Hydrogen on carbon in ketone *)
		indsInPatternQ[ketoneP],{Span[2.0PPM,2.6PPM],ketoneP},

		(* Hydrogen on carbon next to nitrogen *)
		indsInPatternQ[adjNP],{Span[2.0PPM,3.1PPM],adjNP},

		(* Vinyl hydrogen, i.e. H on double bonded C *)
		indsInPatternQ[vinylP],{Span[4.5PPM,6.0PPM],vinylP},

		(* Allyl hydrogen, i.e. H on C bonded to double bonded C *)
		indsInPatternQ[allylP],{Span[1.6PPM,2.8PPM],allylP},

		(* Hydrogen on Carbon next to Fluorine *)
		indsInPatternQ[fluorineCP],{Span[4.3PPM,4.7PPM],fluorineCP},

		(* Hydrogen on Carbon next to Chlorine*)
		indsInPatternQ[chlorineCP],{Span[3.3PPM,4.2PPM],chlorineCP},

		(* Hydrogen on Carbon next to Bromine *)
		indsInPatternQ[bromineCP],{Span[2.7PPM,4.2PPM],bromineCP},

		(* Hydrogen on Carbon next to Iodine *)
		indsInPatternQ[iodineCP],{Span[2.2PPM,4.2PPM],iodineCP},

		(* CH3 (do not change the order of these) *)
		indsInPatternQ[CH3P],{Span[0.7PPM,1.3PPM],CH3P},

		(* CH2 *)
		indsInPatternQ[CH2P],{Span[1.0PPM,1.75PPM],CH2P},

		(* CH *)
		indsInPatternQ[CHP],{Span[1.5PPM,2.0PPM],CHP},

		(* Default is full PPM range *)
		True,{Span[0.0PPM,15.0PPM],Unknown}
	]
];

(* Given an input molecule and NMR nucleus type, return a list of possible signals for each active nucleus *)
molToPossibleSignals[mol_Molecule,nuc:Nucleus1DP]:=Switch[nuc,
	(* Hydrogen NMR *)
	"1H",possibleSignals1H[mol],

	(* Automatic peak assignment not yet supported. Warn user and return empty list. *)
	_,Message[Warning::AutomaticAssignmentNotAvailable,nuc];{}
];

(* Given a list of counts, expands any possibilities into separate lists, e.g. 0,2,{2,0}}\[Rule]{{0,2,2},{0,2,0}} *)
expandPossibility[lst:{(_Integer|_Hold)..}]:=lst;
expandPossibility[lst_List]:=Module[
	{listIndices,possibleLists},

	(* List of any elements of the input list which are lists *)
	listIndices=Flatten@Position[lst,_List,{1}];

	(* Expand sublists denoting multiple possibilities *)
	possibleLists=ReplacePart[lst,First[listIndices]->#]&/@Part[lst,First[listIndices]];

	Sequence@@(expandPossibility/@possibleLists)
];

possibleSignals1H[mol_Molecule]:=Module[
	{
		hydrogenIndices,nonHydrogenIndices,hydrogenNearestIndices,
		bondedToHydrogenIndices,partialHCounts,hydrogenCounts,ONIndices,ONRules,
		updatedHCounts,nonHydrogenAllNeighbors,nonHydrogenNeighbors,hydrogenNeighbors,
		neighborHCounts,possibleSignals,stereocenterNeighbors,nonequivalentHydrogens,
		stereoCorrectedHCounts,nonequivalentHydrogenAppend,stereoCorrectedSignals
	},

	(* Get the indices of each hydrogen atom in the molecule mol *)
	hydrogenIndices=Flatten@Position[AtomList[mol],Atom["H"]];

	(* If there are no hydrogen atoms, return early *)
	If[Length[hydrogenIndices]===0,Return[{}]];

	(* Get indices of non-hydrogen atoms *)
	nonHydrogenIndices=Flatten@Position[AtomList[mol],Atom[Except["H"]]];

	(* Get the atoms involved in each bond to a hydrogen atom. *)
	hydrogenNearestIndices=FindMoleculeSubstructure[
		mol,
		MoleculePattern[
			{_,"H"},
			{Bond[{1,2}]}
		],
		All
	];

	(* For each hydrogen, index of the atom it is bonded to *)
	bondedToHydrogenIndices=Lookup[hydrogenNearestIndices,1];

	(* Count of the number of hydrogens on each non-hydrogen atom with at least one hydrogen *)
	partialHCounts=Rule@@@Tally[bondedToHydrogenIndices];

	(* List of rules mapping atom index \[Rule] # of hydrogens connected *)
	hydrogenCounts=Map[
		If[KeyExistsQ[partialHCounts,#],
			#->Lookup[partialHCounts,#],
			#->0
		]&,
		nonHydrogenIndices
	];

	(* Get indices of Oxygen and Nitrogen. Hydrogen on these atoms can interchange with solvent. *)
	ONIndices=Flatten@Position[AtomList[mol],Atom["N"]|Atom["O"]];

	(* Replacement rules which append a possible count of zero to attached hydrogens of oxygen and nitrogen *)
	ONRules=Map[
		Rule[#,y_]:>Rule[#,{y,0}]&,
		ONIndices
	];

	(* Updated hydrogen counts, with alternatives for exchangeable hydrogen counts. Remove duplicate zeros. *)
	updatedHCounts=(hydrogenCounts/.ONRules)/.Rule[{0..},0];

	(* Get all neighbors of each non-hydrogen atom in the molecule *)
	nonHydrogenAllNeighbors=Map[
		(* For each non-hydrogen atom, select its neighbors *)
		Flatten@Select[
			(* First element of a bond is the two atoms it connects *)
			First/@BondList[mol],
			(* Select if one of the bond elements is the current atom *)
			MemberQ[#]
		]/.{
			(* Delete any occurences of self *)
			#->Nothing
		}&,
		nonHydrogenIndices
	];

	(* Remove hydrogen atoms from the nonHydrogenNeighbors *)
	nonHydrogenNeighbors=MapThread[Rule,
		{nonHydrogenIndices,nonHydrogenAllNeighbors}
	]/.(
		(#->Nothing)&/@hydrogenIndices
	);

	(* Map nuclei to hydrogen atomic indices *)
	hydrogenNeighbors=MapThread[
		Rule[
			First[#2],
			Complement[#1,Last[#2]]
		]&,
		{nonHydrogenAllNeighbors,nonHydrogenNeighbors}
	];

	(* All non-hydrogen atoms which are bonded to a stereocenter *)
	stereocenterNeighbors=Flatten@Lookup[
		nonHydrogenNeighbors,
		mol["PossibleStereocenters"]
	];

	(* All hydrogen atoms bonded to the stereocenter neighbors, stripping empty lists *)
	nonequivalentHydrogens=Lookup[
		hydrogenNeighbors,
		stereocenterNeighbors
	]/.{Rule[{},Nothing]};

	(* Mark nonequivalent hydrogen (e.g. two nonequivalent H goes from 2 \[Rule] {{1,1}} )*)
	stereoCorrectedHCounts=updatedHCounts/.{
		RuleDelayed[
			Rule[x_?(MemberQ[stereocenterNeighbors,#]&),y_],
			Rule[x,y/.{Hcount:GreaterP[0,1]:>Hold@@Repeat[1,Hcount]}]
		]
	};

	(* Number of hydrogen atoms on each of the neighbors of non-hydrogen atoms *)
	neighborHCounts=Map[
		Rule[
			First[#],
			expandPossibility@Lookup[stereoCorrectedHCounts,Last[#]]
		]&,
		nonHydrogenNeighbors
	]/.{Sequence->List,0->Nothing,Hold->Sequence};

	(* For each group of hydrogens, generate an expected PPM range, splitting, and integrals *)
	possibleSignals=Map[
		Lookup[hydrogenNeighbors,#]->{
			(* Chemical Shift *)
			chemicalShiftRangeH[mol,Lookup[hydrogenNeighbors,#]],
			(* Multiplicity *)
			Lookup[neighborHCounts,#],
			(* Peak Integral *)
			N@Lookup[hydrogenCounts,#]
		}&,
		nonHydrogenIndices
	]/.{
		Rule[_,{_,_,0.}]->Nothing
	};


	(* Helper function for stereochemistry correction; adds n additional coupled non-equivalent hydrogens *)
	nonequivalentHydrogenAppend[any_,n:0]:=any;
	nonequivalentHydrogenAppend[singleCouplings:{_Integer...},n:GreaterP[0,1]]:=Join[singleCouplings,Repeat[1,n]];
	nonequivalentHydrogenAppend[multipleCouplings:{{_Integer...}..},n:GreaterP[0,1]]:=nonequivalentHydrogenAppend[#,n]&/@multipleCouplings;

	(* Correct the possible signals for any hydrogens which are non-equivalent due to stereochemistry *)
	stereoCorrectedSignals=possibleSignals/.{
		RuleDelayed[
			Rule[hinds_?(MemberQ[nonequivalentHydrogens,#]&),{shift_,mult_,integral_}],
			Sequence@@Map[
				Rule[{#},{shift,nonequivalentHydrogenAppend[mult,Length[hinds]-1],integral/Length[hinds]}]&,
				hinds
			]
		]
	};

	(* Return the possible signals *)
	stereoCorrectedSignals
];


(* ::Subsubsection::Closed:: *)
(* NMR peak assignment to molecular structure *)

(* Define useful patterns *)
singlePeakSplittingP={UnitsP[PPM]|Span[UnitsP[PPM],UnitsP[PPM]],{"m"}|{_Integer..},_?NumericQ,{UnitsP[Hertz]...}};
possibleSplitRuleP=Rule[{_Integer..},{{Span[UnitsP[PPM],UnitsP[PPM]],MoleculeP|_MoleculePattern|Unknown},ListableP[{_Integer...}],_?NumericQ}];

(* If no assignments were given in options, then default all of them to unknown *)
matchKnownAssignments[opAssigns:Automatic|Null,pkDomains:{Span[UnitsP[PPM],UnitsP[PPM]]..}]:=Repeat[Unknown,Length[pkDomains]];

(* Match assignments given in SplittingAssignments to peak group domains *)
matchKnownAssignments[
	opAssigns:Automatic|Null|{(Unknown|{UnitsP[PPM],_Molecule,{_Integer...}})..},
	pkDomains:{Span[UnitsP[PPM],UnitsP[PPM]]..}
]:=Module[
	{alignedAssigns,duplicateAssignDomains,unmatchedAssigns},

	(* Remove any occurences of Unknown from the option assignments *)
	knownAssigns=opAssigns/.{Unknown->Nothing};

	(* Align assignments to resolved peak domain groups *)
	alignedAssigns=Select[knownAssigns,Function[{assgn},spanContainsQ[#,First[assgn]]]]&/@pkDomains;

	(* A list of peak group domains where duplicate assignments were made *)
	duplicateAssignDomains=Part[pkDomains,
		Flatten@Position[alignedAssigns,_?(Length[#]>1&),1]
	];

	(* A list of any option assignments that didn't get matched to any domains  *)
	unmatchedAssigns=Complement[knownAssigns,DeleteDuplicates@Flatten[alignedAssigns,1]];

	(* Warn the user of any of the assignments in options were mapped to the same domain *)
	If[Length[duplicateAssignDomains]>0,
		Message[Warning::DuplicateAssignment,duplicateAssignDomains]
	];

	(* Warn the user if any of the assignments in options could not be mapped to a domain *)
	If[Length[unmatchedAssigns]>0,
		Message[Warning::UnmatchedAssignment,Map[{#[[1]],"Molecule["<>#[[2]]["SMILES"]<>"]",#[[3]]}&,unmatchedAssigns]]
	];

	(* Return aligned assignments, replacing {} with Unknown and keeping only the first of duplicate assignments *)
	First/@(alignedAssigns/.{{}->{Unknown}})
];

(* Check for the presence of any solvent peaks and update the Known Assignments if they are detected *)
checkSolventPeak[
	knownAssignments:Automatic|Null|{(Unknown|{UnitsP[PPM],_Molecule,{_Integer...}})..},
	updatedSplits:{(None|{Repeated[_,4]})..},
	mostlyResolvedOps:{(_Rule|_RuleDelayed)..}
]:=Module[
	{
		solventModel,solv,solventPeakInfo,solventMolecule,activeNucleus,activeIndices,
		solventInfoByNucleus,solventPeakShift,solventPeakAssignment
	},

	(* Get the NMR solvent and solvent peak information from the DeuteratedSolvent option *)
	{solventModel,solventPeakInfo}=Lookup[mostlyResolvedOps,DeuteratedSolvent];

	(* Short form string representing the solvent *)
	solv=solventModel/.solventModelsForNMR;

	(* Download the molecule from the solvent *)
	solventMolecule=Quiet@Download[solventModel,Molecule];

	(* Lookup the resolved nucleus option *)
	activeNucleus=Lookup[mostlyResolvedOps,Nucleus];

	(* Return knownAssignments unchanged if no solvent peak info could be found *)
	If[MatchQ[solventPeakInfo,Null]||(!MatchQ[solventMolecule,_Molecule]),
		Return[knownAssignments]
	];

	(* Indices of atoms in the molecule which match resolved Nucleus type *)
	activeIndices=Flatten@Position[
		AtomList[solventMolecule]/.{Atom[x_,___]:>x},
		StringDelete[activeNucleus,DigitCharacter..]
	];

	(* Isolate the solvent peak information for the NMR nucleus being probed in this experiment *)
	solventInfoByNucleus=First@Select[solventPeakInfo,
		(#[Nucleus]===activeNucleus)&
	];

	(* Look up the chemical shift of the solvent for the given NMR type, according to the Nucleus option *)
	solventPeakShift=Lookup[solventInfoByNucleus,ChemicalShift];

	(* Generate a Peak Assignment label for the solvent *)
	solventPeakAssignment=If[MatchQ[activeNucleus,"1H"],
		(* Draw the resonance structure for a deuterated solvent with impurities *)
		{
			solventPeakShift,
			MoleculeModify[solventMolecule,{"ReplaceAtom",FirstOrDefault[activeIndices,Null]->Atom["H"]}],
			ToList@FirstOrDefault[activeIndices,{}]
		},
		(* Directly list the atoms if the nucleus type is different *)
		{
			solventPeakShift,
			solventMolecule,
			activeIndices
		}
	];

	(* Update known assignments. Assign a group to a solvent peak if it falls in range, and if the multiplicity matches *)
	MapThread[
		If[MatchQ[#1,Unknown]&&checkSolventShift[solv,solventPeakShift,#2[[1]]]&&checkSolventMultiplicity[solv,#2[[2]]],
			solventPeakAssignment,
			#1
		]&,
		{knownAssignments,updatedSplits}
	]
];

(* True if the solvent multiplicity falls within tolerance of the identified shift *)
checkSolventShift[solvent_,solvShift_,shiftSpan:_Span]:=Switch[solvent,
	(* Water has a temperature dependence so broaden its range *)
	"Water",spanContainsQ[4.69PPM;;4.8PPM,shiftSpan],
	(* Otherwise, *)
	_,spanContainsQ[shiftSpan,solvShift]

];
checkSolventShift[solvent_,solvShift_,shift:UnitsP[PPM]]:=Switch[solvent,
	(* Water has a temperature dependence so broaden its range *)
	"Water",spanContainsQ[4.69PPM;;4.8PPM,shift],
	(* Otherwise, *)
	_,Abs[shift-solvShift]<0.02PPM
];

(* True if the solvent multiplicity is consistent with the solvent, False otherwise *)
checkSolventMultiplicity[solvent_,mult_]:=Switch[solvent,
	"Chloroform",MatchQ[mult,{1}],
	"DMSO",MatchQ[mult,{5}],
	"Benzene",MatchQ[mult,{1}|{5}],
	"Acetone",MatchQ[mult,{5}],
	"Acetonitrile",MatchQ[mult,{5}],
	"Methanol",MatchQ[mult,{5}],
	"Water",MatchQ[mult,{1}],
	(* If multiplicity wasn't identified, return False so the solvent peak does not get assigned *)
	_,False
];


(* If there are no known species, then return known assignments, automatically resolving to Null if no known assignments provided. *)
assignToKnownSpecies[
	splitLabels:{singlePeakSplittingP..},
	mol:Null|{},
	nuc:Nucleus1DP,
	knownAssign:Automatic|Null|{(Unknown|{UnitsP[PPM],_Molecule,{_Integer...}})..}
]:={knownAssign/.{Automatic->Repeat[Unknown,Length[splitLabels]]},Null};

(* Given splitting labels and a molecule, assign nuclei of type nucleus to the splittings, giving any SplittingAssignments specified by option preference. *)
assignToKnownSpecies[
	splitLabels:{singlePeakSplittingP..},
	mols:{_Molecule..},
	nuc:Nucleus1DP,
	knownAssignments:Automatic|Null|{(Unknown|{UnitsP[PPM],_Molecule,{_Integer...}})..}
]:=Module[
	{
		knownAssgnsWithGroups,possibleSignals,knownAssgnPerMol,possibleAssignments,assignsWithMols,
		replaceUnknowns,combinedAssigns,expandedCombinedAssigns,assignedMols,unassignedMols,
		finalAssigns,finalGroups,finalAssignsWithPos
	},

	(* Identify and append the functional group associated with each known assignment *)
	knownAssgnsWithGroups=Map[
		If[MatchQ[#,Except[Unknown]],
			{#,Last[chemicalShiftRangeH[Sequence@@#]]},
			Unknown
		]&,
		knownAssignments/.{{pos:UnitsP[PPM],mol_Molecule,inds:{_Integer...}}:>{mol,inds}}
	];

	(* Given a molecule and a nucleus, generate a list of possible signals each nucleus may produce (shift range, mult, integral) *)
	possibleSignals=molToPossibleSignals[#,nuc]&/@mols;

	(* For each molecule, keep all known assignments corresponding to that molecule and replace assignments to other molecules with {{},Unknown} *)
	knownAssgnPerMol=Map[
		knownAssgnsWithGroups/.{
			Null->Automatic,
			{{mol:#,inds_},fnc_}:>{inds,fnc},
			{{_,_},_}:>{{},Unknown}
		}&,
		mols
	];

	(* For each set of possible signals per molecule, assign splittings to those possible signals *)
	possibleAssignments=MapThread[
		assignSplittingsToMolecule[#1,splitLabels,#2]&,
		{possibleSignals,knownAssgnPerMol}
	];

	(* Prepend the molecules to each possible assignment *)
	assignsWithMols=MapThread[
		(#2/.RuleDelayed[
			{assgn:{_Integer..},rest:Unknown|_MoleculePattern|MoleculeP},
			{{#1,assgn},rest}
		])&,
		{mols,possibleAssignments}
	];

	(* Given two lists with equal length, replace each occurrence of Unknown in list 1 with the corresponding element in list 2 *)
	replaceUnknowns=Function[{list1,list2},MapThread[If[MatchQ[#1,Unknown],#2,#1]&,{list1,list2}]];

	(* Combine the known assignments, replacing unknowns at each step *)
	combinedAssigns=If[MatchQ[knownAssignments,Automatic|Null],
		Fold[replaceUnknowns,assignsWithMols],
		Fold[replaceUnknowns,knownAssgnsWithGroups,assignsWithMols]
	];

	(* If any unknowns remain, expand them into {assignment,functional group} duples *)
	expandedCombinedAssigns=Replace[combinedAssigns,Unknown->{Unknown,Unknown},1];

	(* A list of all molecules that assignments were made to *)
	assignedMols=DeleteDuplicates[First/@((First/@expandedCombinedAssigns)/.{Unknown->Nothing})];

	(* A list of all molecules we tried to assign peaks to, but could not find any matches for *)
	unassignedMols=Complement[mols,assignedMols];

	(* Warn the user if any of the molecules mols in option KnownSpecies could not be assigned to any peaks *)
	If[Length[unassignedMols]>0,
		Message[Warning::MolecularAssignment,("Molecule["<>#["SMILES"]<>"]")&/@unassignedMols];
	];

	(* Final Assignments and functional groups *)
	{finalAssigns,finalGroups}=Transpose[expandedCombinedAssigns];

	(* Insert the chemical shift back into the final assignments *)
	finalAssignsWithPos=MapThread[
		If[MatchQ[#2,Unknown],Unknown,Prepend[#2,#1/.{Span[x_,y_]:>Mean[{x,y}]}]]&,
		{First/@splitLabels,finalAssigns}
	];

	(* Return the final processed output *)
	{finalAssignsWithPos,finalGroups}
];

(* True if the number of neighboring hydrogens matches the assigned multiplicity. *)
multMatchQ[mult_,neighborHCounts:{_Integer...}]:=Which[
	(* Skip this check if the splitting was assigned a multiplet s*)
	MatchQ[mult,{"m"}],True,

	(* Single splitting *)
	MatchQ[mult,{_Integer}],(Total[neighborHCounts]+1)===(Sequence@@mult),

	(* Multiple splitting *)
	MatchQ[mult,{_Integer,_Integer..}],Sort[mult]===Sort[neighborHCounts+1]
];

(* Check if a peak splitting lies within a chemical shift range and has consistent splitting and integral *)
splitMatchQ[
	singleSplitting:singlePeakSplittingP,
	shiftRange:Span[UnitsP[PPM],UnitsP[PPM]],
	neighborHCounts:ListableP[{_Integer...}],
	integral:_?NumericQ
]:=Module[
	{shift,mult,int,Js,peakInRangeQ,consistentSplittingsQ,integralMatchQ},

	(* Extract fields from the single splitting *)
	{shift,mult,int,Js}=singleSplitting;

	(* Check if the splitting is in the expected chemical shift range *)
	peakInRangeQ=spanContainsQ[shiftRange,shift];

	(* Check that the number of neighboring hydrogens matches the assigned multiplicity (loose check) *)
	consistentSplittingsQ=If[MatchQ[neighborHCounts,{{_Integer...}..}],
		Or@@(multMatchQ[mult,#]&/@neighborHCounts),
		multMatchQ[mult,neighborHCounts]
	];

	(* True if the integration in the singleSplitting matches *)
	integralMatchQ=(Round[integral,1]===Round[int,1]);

	(* True if all conditions are satisfied *)
	And[peakInRangeQ,consistentSplittingsQ,integralMatchQ]
];

(* Given a list of peak splittings and a possible split rule, return a list of possible sets of atoms the splitting could correspond to *)
getPotentialAssignments[
	unassignedSplits:{singlePeakSplittingP..},
	molSplitRule:possibleSplitRuleP
]:=Module[
	{hydrogenIndices,shiftRange,molFrag,neighborHCounts,integral},

	(* List of molecular indices for the hydrogen in the possible split rule *)
	hydrogenIndices=First[molSplitRule];

	(* Extract necessary information from the molecular split rule *)
	{{shiftRange,molFrag},neighborHCounts,integral}=Last[molSplitRule];

	(* Map over the unassigned splits, saving it in the list*)
	Map[
		If[splitMatchQ[#,shiftRange,neighborHCounts,integral],
			#->{hydrogenIndices,molFrag},
			Nothing
		]&,
		unassignedSplits
	]
];

(* If there are no known assignments pass an empty list on *)
assignSplittingsToMolecule[
	possibleSignals:{possibleSplitRuleP...},
	allSplits:{singlePeakSplittingP..},
	assgn:Automatic
]:=assignSplittingsToMolecule[possibleSignals,allSplits,{}];

(* If there are no known assignments in an empty list expand to match the length of all splits *)
assignSplittingsToMolecule[
	possibleSignals:{possibleSplitRuleP...},
	allSplits:{singlePeakSplittingP..},
	emptyAssignments:{}
]:=assignSplittingsToMolecule[possibleSignals,allSplits,Repeat[Unknown,Length[allSplits]]];

(* Assign a list of possible splittings (from a molecule) to those identified from spectrum data *)
assignSplittingsToMolecule[
	possibleSplits:{possibleSplitRuleP...},
	allSplits:{singlePeakSplittingP..},
	knownAssignments:{(Unknown|{{_Integer...},_MoleculePattern|MoleculeP|Unknown})..}
]:=Module[
	{
		unassignedSplits,unassignedAtoms,remainingPossibleSplits,potentialAssignments,
		updatedAssignmentRules,assignmentsMade,recursiveAssignments
	},

	(* Get a list of splits which do not yet have an assignment *)
	unassignedSplits=MapThread[
		If[MatchQ[#2,Except[Unknown]],
			Nothing,
			#1
		]&,
		{allSplits,knownAssignments}
	];

	(* If everything has been assigned already, then return the known assignments *)
	If[MatchQ[unassignedSplits,{}],
		Return[knownAssignments]
	];

	(* Atomic indices of all atoms in the molecule which were not assigned in KnownAssignments *)
	unassignedAtoms=Complement[
		Flatten[First/@possibleSplits],
		Flatten[First/@DeleteCases[knownAssignments,Unknown]]
	];

	(* Exclude any possible splits which have already been covered by KnownAssignments *)
	remainingPossibleSplits=Select[
		possibleSplits,
		Function[{rule},
			And@@(MemberQ[unassignedAtoms,#]&/@First[rule])
		]
	];

	(* Get a list of potential assignments *)
	potentialAssignments=Replace[
		Map[
			getPotentialAssignments[unassignedSplits,#]&,
			remainingPossibleSplits
		],
		Rule[{},Nothing],
		{1}
	];

	(* Join the newly identified assignments with KnownAssignments *)
	updatedAssignmentRules=MapThread[
		If[MemberQ[First/@First/@potentialAssignments,#1],
			#1->Flatten[Lookup[(First/@potentialAssignments),{#1}],1],
			#1->#2
		]&,
		{allSplits,knownAssignments}
	];

	(* Only the assignments *)
	assignmentsMade=Last/@updatedAssignmentRules;

	(* TODO: Split different possibilities, warn user and ask them to verify if this is case. *)
	(* If new assignments were made, then recursively call the function to keep assigning valid labels*)
	recursiveAssignments=If[Length[assignmentsMade/.{Unknown->Nothing}]>Length[knownAssignments/.{Unknown->Nothing}],
		assignSplittingsToMolecule[possibleSplits,allSplits,assignmentsMade],
		assignmentsMade
	];

	(* Return the updated peak assignments *)
	recursiveAssignments
];


(* ::Subsubsection::Closed:: *)
(* Tools for converting between peak label representations *)

(* Convert a peak splitting tuple into an ACS label string *)
splittingToAnnotation[splitNoNucleus:ListableP[singlePeakSplittingP]]:=splittingToAnnotation[splitNoNucleus,"1H"];
splittingToAnnotation[splittingList:{singlePeakSplittingP..},nucleus:Nucleus1DP]:=splittingToAnnotation[#,nucleus]&/@splittingList;
splittingToAnnotation[singleSplitting:singlePeakSplittingP,nucleus:Nucleus1DP]:=Module[
	{shift,mult,integral,Jsplits,multipletLabelRules,shiftLabel,multiplicityLabel,intNumString,integrationLabel,JSplitLabel},

	(* Extract individual fields from the peak splitting *)
	{shift,mult,integral,Jsplits}=singleSplitting;

	(* Lookup table for assigning multiplicities to String labels. This includes all labels recognized by ACS publications. *)
	multipletLabelRules=<|
		{"m"}->"m",
		{1}->"s",
		{2}->"d",
		{3}->"t",
		{4}->"q",
		{5}->"quint",
		{6}->"sx",
		{7}->"hep",
		{8}->"oct",
		{9}->"non",
		{10}->"dec",
		{2,2}->"dd",
		{2,3}->"dt",
		{2,4}->"dq",
		{3,2}->"td",
		{3,3}->"tt",
		{3,4}->"tq",
		{4,2}->"qd",
		{4,3}->"qt",
		{4,4}->"qq"
	|>;

	(* Format the chemical shift string, stripping units and replacing the Span ;; with a hyphen *)
	shiftLabel=If[MatchQ[shift,_Span],
		StringReplace[(ToString[Unitless[#]&/@shift])," ;; "-> "-"],
		ToString[Unitless[shift]]
	];

	(* If the peak-splitting is an ACS recognized format, return the appropriate label, otherwise return 'm' for multiplet. *)
	multiplicityLabel=If[KeyExistsQ[multipletLabelRules,mult],
		multipletLabelRules[mult],
		StringRiffle[Flatten[Lookup[multipletLabelRules,{{#}}]&/@mult],""]
	];

	(* Convert the normalized integral to a string, rounding to 1 decimal point and adding the trailing zero if needed. *)
	intNumString=ToString[Round[integral,0.1]]/.{s_?(StringTake[#,-1]==="."&):>s<>"0"};

	(* Format the nucleus integration string, by rounding to the nearest integer *)
	integrationLabel=intNumString<>" "<>StringTake[nucleus,-1];

	(* Format the J split label, returning an empty string if the peak is a singlet or unidentified multiplet *)
	JSplitLabel=If[MatchQ[multiplicityLabel,Except["s"|"m"]],
		", J = "<>StringReplace[
			StringJoin@Riffle[ToString[Round[#,0.1 Hertz]]&/@Jsplits,", "],
		"hertz"->"Hz"],
		""
	];

	(* Format the return string *)
	shiftLabel<>" "<>"("<>multiplicityLabel<>", "<>integrationLabel<>JSplitLabel<>")"
];


(* ::Subsubsection::Closed:: *)
(*computePurity*)


computePurity[areas_, xy_, baseline_, labels_] := Module[
	{totalArea},
	totalArea = computePeakIntegral[xy, baseline];
	computePurityCore[areas, totalArea, labels]
];
computePurityCore[{}, ___] := {
	Area -> {0},
	RelativeArea -> {100 Percent},
	PeakLabels -> {"Background"}
};
computePurityCore[areas_, totalArea_, labels_] := Module[
	{areaOut, relativeAreaOut, labelsOut},

	areaOut = Append[areas, totalArea - Total[areas]];
	relativeAreaOut = (areaOut / totalArea) * 100 * Percent;
	labelsOut = Append[labels, "Background"];

	{
		Area -> areaOut,
		RelativeArea -> relativeAreaOut,
		PeakLabels -> labelsOut
	}
];


(* ::Subsubsection::Closed:: *)
(*computeDerivedFields*)


(* Compute derived fields (e.g. parent peaks, assignments, and multiplets) which require the initial peak identification. *)
computeDerivedFields[Null, ___] := Null;
computeDerivedFields[pks_, rawData_, templateRules_, resolvedOps_] := Module[
	{peakRelativeFields,peakResolutionFields,peakSplittingFields,dataNotInPeaks,globalBaseline,purityField},

	(* Fields that depend on relative location of peaks, i.e. RelativeArea, RelativePosition, PeakLabel, ParentPeak, etc. *)
	peakRelativeFields=computeRelativePeaksFields[pks,templateRules,resolvedOps];

	(* Peak resolution quantities computed from peaks identified in pks, i.e. Resolution and number of theoretical plates *)
	peakResolutionFields=resolutionAnsPlates[pks];

	(* If requested by input options, identify multiplets and compute splitting parameters for NMR spectra. *)
	peakSplittingFields=If[MatchQ[Lookup[resolvedOps,PeakType],NMR],
		computePeakSplittingFields[pks,resolvedOps],
		{
			PeakGroupDomains->Null,
			SplittingData->Null,
			SplittingPeakIndices->Null,
			SplittingAssignments->Null,
			NMRFunctionalGroup->Null,
			PeakIntegralNormalizationGroup->Null,
			PeakGroupMultiplicity->Null
		}
	];

	(* Select all data from raw data which is NOT in one of the identified peak ranges *)
	dataNotInPeaks=Fold[Analysis`Private`selectInclusiveMatrixPointsOutsideRangeC[#1,Sequence @@ #2]&,rawData,Transpose[Lookup[pks,{PeakRangeStart,PeakRangeEnd}]]];

	(* Fit a line to the data points which were not included in peaks, to represent the global baseline *)
	globalBaseline=LinearModelFit[dataNotInPeaks,x,x]["Function"];

	(* Returns index-matched list of Areas, RelativeAreas, and PeakLabels for each peak + the global baseline *)
	purityField=computePurity[Lookup[pks,Area],Sort@rawData,globalBaseline,Lookup[peakRelativeFields,PeakLabel]];

	(* Join and return the derived fields. If peakRelativeFields or peakResolutionFields failed, return Null. *)
	If[Or[MatchQ[peakRelativeFields,Null],MatchQ[peakResolutionFields,Null]],
		Null,
		Join[pks,peakRelativeFields,peakResolutionFields,peakSplittingFields,{Purity->purityField}]
	]
];


(* ::Subsection::Closed:: *)
(*Packet*)


(* ::Subsubsection::Closed:: *)
(*mergePeakParameters*)


mergePeakParameters[peakParameters_] := Module[{},
	If[MatchQ[peakParameters,Null],
		Null,
		Map[#[[1, 1]] -> Flatten[Join[#[[;;, 2]]], 1] &, Transpose[peakParameters]]
	]
];


(* ::Subsubsection:: *)
(*formatPeakPacket*)


formatPeakPacket[in_, peakParameters0_, baselineFunction_, standardFieldsStart_, resolvedOps_, samples_, cntForName_] := Module[
	{
		dataRef,peakParameters,mergedParameters,purity,assignments,libraryNew,
		splitData,chshifts,ints,mults,Js,splitIndices,numPeaks,reverseSplitIndexMap,reverseSplitIndices,
		splitAssignments,splitFunctionalGroups,domains,finalDomains,finalResolvedOps,
		x,optionsResolved,out,resolutionHalfHeight,platesHalfHeight,resolutionTG,platesTG,parentPeak
	},

	If[Or[MatchQ[resolvedOps,Null],MatchQ[peakParameters0,Null]],
		Return[Null]
	];

	(* Data reference resolution *)
	dataRef = If[MatchQ[in, ObjectP[]], in[Object], Null];

	(* Extract purity from peak fields *)
	purity=Lookup[peakParameters0,Purity];

	(* Extract new molecular assignments from peak fields (links to Model[Molecule]) *)
	assignments=Lookup[peakParameters0,PeakAssignment,Null];

	(* Extract new library assignments from peak fields *)
	libraryNew=Lookup[peakParameters0,PeakAssignmentLibrary,Null];

	(* Extract the split data from peak fields *)
	splitData=Lookup[peakParameters0,SplittingData];

	(* Divide the split data into separate fields *)
	{chshifts,mults,ints,Js}=If[MatchQ[splitData,Except[Null]],
		Transpose@splitData,
		{Null,Null,Null,Null}
	];

	(* Extract the splitting peak indices from peak fields. These map peak group to peak indices *)
	splitIndices=Lookup[peakParameters0,SplittingPeakIndices];

	(* Extract atomic assignments from peak fields. Process the unknowns so fields match their upload patterns. *)
	splitAssignments=If[MatchQ[Lookup[peakParameters0,SplittingAssignments],Null],
		Null,
		Part[Lookup[peakParameters0,SplittingAssignments]/.{Unknown->{Null,Unknown,{}}},All,2;;]
	];

	(* Extract the NMR functional groups as well *)
	splitFunctionalGroups=Lookup[peakParameters0,NMRFunctionalGroup];

	(* Remove the fields above *)
	peakParameters=DeleteCases[peakParameters0,
		Alternatives[
			Purity->_,
			PeakAssignment->_,
			PeakAssignmentLibrary->_,
			SplittingData->_,
			PeakGroupDomains->_,
			PeakIntegralNormalizationGroup->_,
			PeakGroupMultiplicity->_,
			SplittingPeakIndices->_,
			SplittingAssignments->_,
			NMRFunctionalGroup->_
		]
	];

	(* Parameters (position, height, area, etc.) for each identified peak *)
	mergedParameters = MapAt[Replace[#]&,peakParameters,{;;,1}];
	mergedParameters = mergedParameters //. {Null..} -> Null;

	(* Length of the number of peaks which have a recorded position, for index matching *)
	numPeaks=Length[Lookup[mergedParameters,Replace[Position]]];

	(* Reverse index map maps peak indices to peak group indices *)
	reverseSplitIndexMap=AssociationMap[
		Function[{idx},
			Flatten@Position[splitIndices,_?(MemberQ[#,idx]&)]
		],
		Range[numPeaks]
	];

	(* Convert the association into a list of indices *)
	reverseSplitIndices=Map[
		(Lookup[reverseSplitIndexMap,#]/.{List->Sequence,{}->Null})&,
		Range[numPeaks]
	]/.{{Null..}->{}};

	(* convert domain list into span *)
	domains=Lookup[resolvedOps, Domain];

	finalDomains=If[Length[domains]==1, Span[#[[1]], #[[2]]]&/@domains, {Span[#[[1]], #[[2]]]}&/@domains];


	finalResolvedOps=resolvedOps/.Lookup[resolvedOps,Domain]->domains;

	Association[Join[
		{Type -> Object[Analysis, Peaks]},
		{Name -> If[MatchQ[Lookup[resolvedOps, Name], Null],
					Null,
					If[cntForName==1,
						Lookup[resolvedOps, Name],
						Lookup[resolvedOps, Name] <> " " <> ToString[cntForName]
					]
				]},

		standardFieldsStart,
		mergedParameters,
		{
			BaselineFunction -> baselineFunction,
			Replace[RelativeRetentionTime] -> Lookup[mergedParameters, Replace[RelativePosition]],
			Replace[Reference] -> If[MatchQ[dataRef, Null],
				{},
				{Link[dataRef, LegacySLL`Private`peaksFieldToPeaksSourceField[dataRef[Type], Lookup[resolvedOps, ReferenceField]]]}
			],
			ReferenceField -> Lookup[resolvedOps, ReferenceField],
			ResolvedOptions -> Replace[finalResolvedOps, {
				(DataType -> Automatic) -> (DataType -> Null),
				(PeakAssignments -> Automatic|Null) -> (PeakAssignments -> {})
			},{1}],
			Replace[ReferenceDataSliceDimension] -> Lookup[resolvedOps, DataSliceDimension]/.Lookup[sliceableFieldDimensionLookup,Lookup[resolvedOps, ReferenceField],{}],
			Replace[ReferenceDataSlice] -> Replace[Lookup[resolvedOps, DataSlice],{n:UnitsP[]:>{n,n},{n:UnitsP[]}:>{n,n}},1],
			Replace[SliceReductionFunction] -> Lookup[resolvedOps, SliceReductionFunction],
			Replace[PeakSamples] -> Map[Link,samples],
			Replace[Domain] -> RoundReals[domains, 3],
			Replace[AbsoluteThreshold] -> Lookup[resolvedOps, AbsoluteThreshold],
			Replace[RelativeThreshold] -> Lookup[resolvedOps, RelativeThreshold],
			Replace[WidthThreshold] -> Lookup[resolvedOps, WidthThreshold],
			Replace[AreaThreshold] -> Lookup[resolvedOps, AreaThreshold],
			Replace[PeakAssignment] -> assignments,
			Replace[PeakAssignmentLibrary] -> libraryNew,
			Purity -> purity,
			NMROperatingFrequency -> Lookup[resolvedOps,OperatingFrequency],
			NMRNucleus -> Lookup[resolvedOps,Nucleus],
			Replace[NMRChemicalShift] -> chshifts,
			Replace[NMRNuclearIntegral] -> ints,
			Replace[NMRSplittingGroup] -> reverseSplitIndices,
			Replace[NMRMultiplicity] -> mults,
			Replace[NMRJCoupling] -> Js,
			Replace[NMRAssignment] -> splitAssignments,
			Replace[NMRFunctionalGroup] -> splitFunctionalGroups
		}
	]]

];


(* ::Subsection::Closed:: *)
(*getPeaksCoreFields*)


(* ::Subsubsection::Closed:: *)
(*getPeaksCoreFields*)


getPeaksCoreFields[pkPkt_] := Module[
	{coreFields},
	coreFields={
		Position,Height,HalfHeightWidth,Area,PeakRangeStart,PeakRangeEnd,WidthRangeStart,
		WidthRangeEnd,BaselineIntercept,BaselineSlope,AsymmetryFactor,TailingFactor,RelativeArea,RelativePosition,
		PeakLabel,TangentWidth,TangentWidthLines,TangentWidthLineRanges,
		HalfHeightResolution,HalfHeightNumberOfPlates,TangentResolution,TangentNumberOfPlates
	};
	<|Map[# -> Lookup[stripAppendReplaceKeyHeads[pkPkt], #] &, coreFields]|>
];


(* ::Subsection::Closed:: *)
(*Peak Picking*)


(* ::Subsubsection::Closed:: *)
(*combineListOfRules*)


combineListOfRules[in:{{_Rule...}...}]:= Table[one->Flatten[(one/.in),1],{one,in[[1,;;,1]]}];



(* ::Subsubsection::Closed:: *)
(*Domains*)


Options[Domains]={
	PlotRange->Automatic
};

(* --- Core Function Explicit Ranges --- *)
(*Domains[plotData:{{_?NumericQ,_?NumericQ}..},ranges:{{_?NumericQ,_?NumericQ}..},ops:OptionsPattern[Domains]]:=Function[range,Select[plotData,First[#]>=First[range]&&First[#]<=Last[range]&]]/@ranges*)
Domains[plotData:{{_?NumericQ,_?NumericQ}..},ranges:{{_?NumericQ,_?NumericQ}..},ops:OptionsPattern[Domains]]:=Function[range,selectInclusiveMatrixPointsInsideRangeC[plotData,range[[1]],range[[2]]]]/@ranges;

(* --- Reverse Listable Explicit Ranges --- *)
Domains[plotData:{{_?NumericQ,_?NumericQ}..},range:{_?NumericQ,_?NumericQ},ops:OptionsPattern[Domains]]:=First[Domains[plotData,{range},ops]];

(* --- Plot Range Option Form --- *)
Domains[dataPoints:CoordinatesP,ops:OptionsPattern[Domains]]:=Module[{xmin,xmax,ymin,ymax,rangeRules},

	(* expland the plot range to its full form *)
	{{xmin,xmax},{ymin,ymax}}=FullPlotRange[OptionValue[PlotRange]];

	(* Determine the list of rules for what is in range *)
	rangeRules=And[
		First[#]>=(xmin/.{All->-\[Infinity],Full->0,Automatic->-\[Infinity]}),
		First[#]<=(xmax/.{All->\[Infinity],Full->\[Infinity],Automatic->\[Infinity]}),
		Last[#]>=(ymin/.{All->-\[Infinity],Full->0,Automatic->-\[Infinity]}),
		Last[#]<=(ymax/.{All->\[Infinity],Full->\[Infinity],Automatic->\[Infinity]})
	]&;

	(* Select out only the points that meet the rules *)
	Select[dataPoints,rangeRules]

];

(* --- Plot Range Option Form that takes in DateCoordinateP--- *)
Domains[dataPoints:DateCoordinateP,ops:OptionsPattern[Domains]]:=Module[{xmin,xmax,ymin,ymax,xminFinal,xmaxFinal,yminFinal,ymaxFinal,rangeRules},

	(* expland the plot range to its full form *)
	{{xmin,xmax},{ymin,ymax}}=FullPlotRange[OptionValue[PlotRange]];

	(*pull out the xmin,xmax,ymin,ymax to their values*)
	xminFinal = (xmin/.{All->(DateList[0]),Full->(DateList[0]),Automatic->(DateList[0])});
	xmaxFinal = (xmax/.{All->{9999,12,31,11,59,59.},Full->{9999,12,31,11,59,59.},Automatic->{9999,12,31,11,59,59.}});
	yminFinal = (ymin/.{All->-\[Infinity],Full->0,Automatic->-\[Infinity]});
	ymaxFinal = (ymax/.{All->\[Infinity],Full->\[Infinity],Automatic->\[Infinity]});

	(* Determine the list of rules for what is in range *)
	rangeRules=Quiet@And[
		QuantityMagnitude[DateDifference[First[#],xminFinal]]<=0,
		QuantityMagnitude[DateDifference[First[#],xmaxFinal]]>=0,
		Last[#]>=yminFinal,
		Last[#]<=ymaxFinal
	]&;

	(* Select out only the points that meet the rules *)
	Select[dataPoints,rangeRules]

];


(* --- Listable --- *)
Domains[dataPoints:{(CoordinatesP|DateCoordinateP)..},ops:OptionsPattern[Domains]]:=Domains[#,ops]&/@dataPoints;

Domains[plotDatas:{{{_?NumericQ,_?NumericQ}..}..},ranges:({{_?NumericQ,_?NumericQ}..}|{_?NumericQ,_?NumericQ}),ops:OptionsPattern[Domains]]:=Domains[#,ranges,ops]&/@plotDatas;



(* ::Subsubsection::Closed:: *)
(*addUnitsToPeaks*)


addUnitsToPeaks[pks_,{xUnit:1,yUnit:1}]:=pks;
addUnitsToPeaks[pks_,{xUnit_,yUnit_}]:=Map[addUnitsToPeaksField[#,{xUnit,yUnit}]&,pks];
addUnitsToPeaksField[Rule[s:Position,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit];
addUnitsToPeaksField[Rule[s:Height,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*yUnit];
addUnitsToPeaksField[Rule[s:HalfHeightWidth,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit];
addUnitsToPeaksField[Rule[s:Area,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit*yUnit];
addUnitsToPeaksField[Rule[s:PeakRangeStart,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit];
addUnitsToPeaksField[Rule[s:PeakRangeEnd,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit];
addUnitsToPeaksField[Rule[s:WidthRangeStart,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit];
addUnitsToPeaksField[Rule[s:WidthRangeEnd,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*xUnit];
addUnitsToPeaksField[Rule[s:BaselineIntercept,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*yUnit];
addUnitsToPeaksField[Rule[s:BaselineSlope,vals_],{xUnit_,yUnit_}]:=Rule[s,vals*yUnit/xUnit];
addUnitsToPeaksField[r_Rule,{xUnit_,yUnit_}]:=r;


(* ::Subsection::Closed:: *)
(*PeakResolution*)


(* ::Subsubsection:: *)
(*helper and resolutions*)

OnLoad[
	General::AmbiguousPeaksFields = "PeakField is set to automatic, but there are more than one fields in `1` that contain relations to Object[Analysis, Peaks] objects. Please select from one of the following for PeaksField: `2`.";
	General::InvalidPeaksField = "PeakField `1` is not a valid peaks field for object `2`.";
	General::BadPeaksField = "PeakField `1` in object `2` does not contain any references to Object[Analysis, Peaks] objects.";
	General::NoPeaksFields = "PeakField is set to automatic, but there are no fields in `1` that contain relations to Object[Analysis, Peaks] objects.";
]

peaksInputSingleP = Alternatives[
	ObjectP[Object[Analysis, Peaks]],
	ObjectP[Object[Data]]
];


validSpanQ[L_Integer,m_Integer,n_Integer] := Max[Abs[m],Abs[n]]<=L && ((m<=n&&Sign[m]==Sign[n]) || (m>n&&Sign[m]!=Sign[n]));


resolvePeaksInput[f_, in_, fieldOps_] := resolvePeaksInput[f, in, fieldOps, False];
resolvePeaksInput[f_, in_, fieldOps_, unitBool_] := Module[
	{objsToDownload, fieldList, downloadedPeaks},

	(* replace raw peaks that does not need to be downloaded *)
	objsToDownload = Replace[in, PacketP[Object[Analysis,Peaks]] -> Null, {1}];

	(* find the field to download for each object *)
	fieldList = preprocessOneInput[f, #, fieldOps] & /@ in;

	(* download specific field in each input and takethe last one if it is pulled for Data object *)
	downloadedPeaks = postDownload /@ If[
		MatchQ[objsToDownload,{Null..}],
		Table[Null,Length[objsToDownload]],
		Quiet[Download[objsToDownload, Evaluate[fieldList]],{Download::FieldDoesntExist,Download::NotLinkField,Download::Part}]
	];

	(* throw error message if download fails *)
	MapThread[
		If[And[!MatchQ[#3, {Null, Null} | {_Null, _Null}], MatchQ[#1, {$Failed, $Failed}]],
			Message[f::BadPeaksField, Head[First[#3]], #2]
		] &,
		{downloadedPeaks, objsToDownload, fieldList}
	];

	(* return either the downloaded peaks or the raw input, in other cases and replace failed cases with Null *)
	MapThread[
		If[MatchQ[#2, {Null, Null}] && MatchQ[#1, PacketP[Object[Analysis,Peaks]]],
			If[unitBool, {#1, defaultUnits}, #1],
			If[unitBool, #2, First[#2]]
		] &,
		{in, downloadedPeaks}
	] /. $Failed -> Null
];


postDownload[{{}, {}}] := {$Failed, $Failed};
postDownload[{pk_List, units_}] := {Last[pk], Last[units]};
postDownload[{pk_Association, units_}] := {If[MatchQ[Lookup[pk,Position],$Failed],$Failed,pk], units};
postDownload[{pk: $Failed, units: $Failed}] := {$Failed, $Failed};
postDownload[_] := {Null, Null};


preprocessOneInput[f_, pk: ObjectP[Object[Analysis, Peaks]], field_] := {Packet@@PeaksFields, PeakUnits};
preprocessOneInput[f_, data: ObjectP[Object[Data]], field_] := With[
	{temp = resolvePeaksField[f, data, field],fields=PeaksFields},
	If[MatchQ[temp,Null],
		{Null,Null},
		{Packet[Field[temp[[-1]][fields]]], Field[temp[[-1]][PeakUnits]]}
	]
];


resolvePeaksField[f_, data_, Automatic] := Module[
	{allPeakFields},
	allPeakFields = LegacySLL`Private`typeToPeaksSourceFields[data[Type]];
	Switch[Length[allPeakFields],
		0, Message[f::NoPeaksFields, data[Object]],
		1, First[allPeakFields],
		_, Message[f::AmbiguousPeaksFields, data[Object], allPeakFields]
	]
];
resolvePeaksField[f_, data_, field_] := Module[
	{allPeakFields},
	allPeakFields = LegacySLL`Private`typeToPeaksSourceFields[data[Type]];
	If[MemberQ[allPeakFields, field], field, Message[f::InvalidPeaksField, field, data[Object]]]
];


whichParam[name_] := First[Flatten[Position[PeaksFields, name]]]/; MemberQ[PeaksFields, name];


defaultUnits = {Position -> None, Height -> None, HalfHeightWidth -> None, Area -> None, PeakRangeStart -> None, PeakRangeEnd -> None, WidthRangeStart -> None, WidthRangeEnd -> None, BaselineIntercept -> None, BaselineSlope -> None};


(* ::Subsubsection::Closed:: *)
(*PeakResolution*)


DefineOptions[PeakResolution,
	Options :> {
		{PeakField -> Automatic, Automatic | (FieldP[Output->Short]), "Field in 'peaks' data that points to Object[Analysis,Peaks] you wish to select from. If the data has only one Object[Analysis,Peaks] field, Automatic will select it automatically."},
		{Method -> HalfHeightWidth, HalfHeightWidth | TangentWidth, "Use half height width or tangent width in the fomular."}
	}
];


PeakResolution::missing = "Input label or position cannot be found in peaks.";


PeakResolution[in: peaksInputSingleP, ops: OptionsPattern[]] := Module[
	{pks, n, func},

	pks = First[resolvePeaksInput[PeakResolution, {in}, OptionValue[PeakField]]];
	If[MatchQ[pks, Null], Return[Null]];

	n = Length[Lookup[pks, Position]];

	func = Switch[OptionValue[Method],
		HalfHeightWidth, peakResolutionInternalHalfHeight,
		TangentWidth, peakResolutionInternalTG
	];

	If[And[MatchQ[OptionValue[Method], TangentWidth], MatchQ[Lookup[pks, TangentWidth], Null | {}]], Return[{}]];

	Table[Table[func[pks, i, j], {i, n}], {j, n}]
];

PeakResolution[in: peaksInputSingleP, pkA: {_String..}, pkB: {_String..}, ops: OptionsPattern[]] := Module[
	{pks, pkLabels, indexA, indexB, func},

	pks = First[resolvePeaksInput[PeakResolution, {in}, OptionValue[PeakField]]];
	If[MatchQ[pks, Null], Return[Null]];

	pkLabels = Lookup[pks, PeakLabel];

	indexA = findPeakIndexByLabel[pkLabels, #] & /@ pkA;
	indexB = findPeakIndexByLabel[pkLabels, #] & /@ pkB;

	func = Switch[OptionValue[Method],
		HalfHeightWidth, peakResolutionInternalHalfHeight,
		TangentWidth, peakResolutionInternalTG
	];

	If[And[MatchQ[OptionValue[Method], TangentWidth], MatchQ[Lookup[pks, TangentWidth], Null | {}]], Return[{}]];

	Table[Table[func[pks, indexA[[i]], indexB[[j]]], {i, Length[indexA]}], {j, Length[indexB]}]
];
PeakResolution[in: peaksInputSingleP, pkA: {_?NumericQ..}, pkB: {_?NumericQ..}, ops: OptionsPattern[]] := Module[
	{pks, pkRanges, indexA, indexB, func},

	pks = First[resolvePeaksInput[PeakResolution, {in}, OptionValue[PeakField]]];
	If[MatchQ[pks, Null], Return[Null]];

	pkRanges = Transpose[Lookup[pks, {PeakRangeStart, PeakRangeEnd}]];

	indexA = findPeakIndexByPosition[pkRanges, #] & /@ pkA;
	indexB = findPeakIndexByPosition[pkRanges, #] & /@ pkB;

	func = Switch[OptionValue[Method],
		HalfHeightWidth, peakResolutionInternalHalfHeight,
		TangentWidth, peakResolutionInternalTG
	];

	Table[Table[func[pks, indexA[[i]], indexB[[j]]], {i, Length[indexA]}], {j, Length[indexB]}]
];

PeakResolution[in: peaksInputSingleP, pkA: _?NumericQ, pkB: _?NumericQ, ops: OptionsPattern[]] :=
	With[{temp = PeakResolution[in, {pkA}, {pkB}, ops]}, If[MatchQ[temp, Null], Null, First[First[temp]]]];
PeakResolution[in: peaksInputSingleP, pkA: _?NumericQ, pkB: {_?NumericQ..}, ops: OptionsPattern[]] :=
	With[{temp = PeakResolution[in, {pkA}, pkB, ops]}, If[MatchQ[temp, Null], Null, Flatten[temp]]];
PeakResolution[in: peaksInputSingleP, pkA: {_?NumericQ..}, pkB: _?NumericQ, ops: OptionsPattern[]] :=
	With[{temp = PeakResolution[in, pkA, {pkB}, ops]}, If[MatchQ[temp, Null], Null, Flatten[temp]]];
PeakResolution[in: peaksInputSingleP, pkA: _String, pkB: _String, ops: OptionsPattern[]] :=
	With[{temp = PeakResolution[in, {pkA}, {pkB}, ops]}, If[MatchQ[temp, Null], Null, First[First[temp]]]];
PeakResolution[in: peaksInputSingleP, pkA: _String, pkB: {_String..}, ops: OptionsPattern[]] :=
	With[{temp = PeakResolution[in, {pkA}, pkB, ops]}, If[MatchQ[temp, Null], Null, Flatten[temp]]];
PeakResolution[in: peaksInputSingleP, pkA: {_String..}, pkB: _String, ops: OptionsPattern[]] :=
	With[{temp = PeakResolution[in, pkA, {pkB}, ops]}, If[MatchQ[temp, Null], Null, Flatten[temp]]];

PeakResolution[_, _, _, ops: OptionsPattern[]] := Message[PeakResolution::InvalidPeaks];


findPeakIndexByLabel[labels_, targetLabel_] := FirstCase[Range[Length[labels]], _?(MatchQ[labels[[#]], targetLabel] &)];
findPeakIndexByPosition[ranges_, targetPosition_] := FirstCase[Range[Length[ranges]], _?((First[ranges[[#]]] <= targetPosition) && (targetPosition <= Last[ranges[[#]]]) &)];


peakResolutionInternalHalfHeight[_, _Missing, _] := Message[PeakResolution::missing];
peakResolutionInternalHalfHeight[_, _, _Missing] := Message[PeakResolution::missing];
peakResolutionInternalHalfHeight[pks_, pkA_, pkB_] := Module[
	{pkPositions, widthRangeStarts, widthRangeEnds, resolution},

	{pkPositions, widthRangeStarts, widthRangeEnds} = Lookup[pks, {Position, WidthRangeStart, WidthRangeEnd}];

	resolution = (2 / 1.7)  * (pkPositions[[pkB]] - pkPositions[[pkA]]) / ((widthRangeEnds[[pkA]] - widthRangeStarts[[pkA]]) + (widthRangeEnds[[pkB]] - widthRangeStarts[[pkB]]));
	resolution
];


peakResolutionInternalTG[_, _Missing, _] := Message[PeakResolution::missing];
peakResolutionInternalTG[_, _, _Missing] := Message[PeakResolution::missing];
peakResolutionInternalTG[pks_, pkA_, pkB_] := Module[
	{pkPositions, tangentWidth, resolution},

	{pkPositions, tangentWidth} = Lookup[pks, {Position, TangentWidth}];

	If[Or[MatchQ[tangentWidth[[pkA]], Null], MatchQ[tangentWidth[[pkB]], Null]], Return[Null]];

	resolution = 2 * (pkPositions[[pkB]] - pkPositions[[pkA]]) / (tangentWidth[[pkA]] + tangentWidth[[pkB]]);
	resolution
];


(* ::Subsection:: *)
(*Plotting*)


(* ::Subsubsection:: *)
(*PeakEpilog*)


DefineOptions[PeakEpilog,
	Options :> {
		{
			OptionName -> Display,
			Default -> {Gradient, Fractions, Peaks},
			Description -> "Additional data to overlay on top of the plot.",
			AllowNull -> False,
			Category -> "Data Specifications",
			Widget -> Alternatives[
				Widget[Type->Enumeration,Pattern:>Alternatives[{}]],
				Widget[
					Type -> MultiSelect,
					Pattern :> DuplicateFreeListableP[Peaks|PeakWidths|Fractions|Ladder|Gradient]
				]
			]
		},
		{
			OptionName -> PlotRange,
			Default -> Automatic,
			Description -> "PlotRange specification for the primary data.  PlotRange units must be compatible with units of primary data.",
			AllowNull -> False,
			Category -> "Plot Style",
			Widget -> Alternatives[
				Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
				{
					"X Range"->Alternatives[
						Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
						Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
						Widget[Type->Expression,Pattern:>_?UnitsQ,Size->Word,PatternTooltip->"Any valid quantity that matches _?UnitsQ."],
						{
							"X Range Minimum"->Alternatives[
								Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
								Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
								Widget[Type->Expression,Pattern:>_?UnitsQ,Size->Word,PatternTooltip->"Any valid quantity that matches _?UnitsQ."]
							],
							"X Range Maximum"->Alternatives[
								Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
								Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
								Widget[Type->Expression,Pattern:>_?UnitsQ,Size->Word,PatternTooltip->"Any valid quantity that matches _?UnitsQ."]
							]
						}
					],
					"Y Range"->Alternatives[
						Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
						Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
						Widget[Type->Expression,Pattern:>_?UnitsQ,Size->Word,PatternTooltip->"Any valid quantity that matches _?UnitsQ."],
						{
							"Y Range Minimum"->Alternatives[
								Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
								Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
								Widget[Type->Expression,Pattern:>_?UnitsQ,Size->Word,PatternTooltip->"Any valid quantity that matches _?UnitsQ."]
							],
							"Y Range Maximum"->Alternatives[
								Widget[Type->Enumeration,Pattern:>Alternatives[Automatic,All,Full]],
								Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
								Widget[Type->Expression,Pattern:>_?UnitsQ,Size->Word,PatternTooltip->"Any valid quantity that matches _?UnitsQ."]
							]
						}
					]
				},
				(* Can resolve to weird nested lists. *)
				Widget[Type->Expression, Pattern:>_, Size->Line]
			]
		},
		{
			OptionName -> SecondYUnscaled,
			Default -> {},
			Description -> "If there is data plotted on a second Y axis, that data is in raw form.  If listable version used, must match list dimensions.",
			AllowNull -> False,
			Category -> "Hidden",
			Widget -> Alternatives[
				Widget[Type->Enumeration,Pattern:>Alternatives[{}]],
				Adder[
					{
						"X"->Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
						"Y"->Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]]
					}
				]
			]
		},
		{
			OptionName -> SecondYScaled,
			Default -> {},
			Description -> "If there is data plotted on a second Y axis, the data plotted on that axis is re-scaled to the primary axes.  If listable version used, must match list dimensions.",
			AllowNull -> False,
			Category -> "Hidden",
			Widget -> Alternatives[
				Widget[Type->Enumeration,Pattern:>Alternatives[{}]],
				Adder[
					{
						"X"->Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]],
						"Y"->Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]]
					}
				]
			]
		},
		{
			OptionName -> Reflected,
			Default -> False,
			Description -> "Must be set to True if the x-axis values are reflected (eg. NMR).",
			AllowNull -> False,
			Category -> "Hidden",
			Widget -> Widget[Type->Enumeration,Pattern:>BooleanP]
		},
		{
			OptionName -> Yaxis,
			Default -> True,
			Description ->  "Draws lines and labels to the Yaxes on mouseover if set to true.",
			AllowNull -> False,
			Category -> "Data Specifications",
			Widget -> Widget[Type->Enumeration,Pattern:>BooleanP]
		},
		{
			OptionName -> LabelStyle,
			Default -> {14, Bold, FontFamily -> "Arial"},
			Description -> "Font options to use for the peak labels.",
			AllowNull -> False,
			Category -> "Plot Style",
			Widget -> Alternatives[
				Widget[Type->Enumeration,Pattern:>Alternatives[Red,Green,Blue,Black,White,Gray,Cyan,Magenta,Yellow,Brown,Orange,Pink,Purple]],
				{
					"Font Size"->Widget[Type->Number,Pattern:>GreaterP[0]],
					"Font Type"->Alternatives[
						Widget[Type->Expression,Pattern:>_,Size->Line],
						Widget[Type->Enumeration,Pattern:>Alternatives[Bold,Italic,Underlined]],
						Widget[Type->Color,Pattern:>ColorP]
					],
					"Font Family"->Alternatives[
						Widget[Type->Expression,Pattern:>_Rule,Size->Line,PatternTooltip->"The font family of the label, in the form FontFamily->_String."]
					]
				},
				Widget[Type -> Expression, Pattern :>_, Size -> Line, PatternTooltip->"The LabelStyle can be set to any valid graphics directive. Evaluate ?LabelStyle in the notebook for more information."]
			]
		},
		{
			OptionName -> PeakPointSize,
			Default -> 0.015,
			Description -> "Size of the points on the picked peaks.",
			AllowNull -> False,
			Category -> "Data Specifications",
			Widget -> Widget[Type->Number,Pattern:>RangeP[-Infinity,Infinity]]
		},
		{
			OptionName -> PeakPointColor,
			Default -> RGBColor[0., 0.5, 1.],
			Description -> "Color of the peak points.",
			AllowNull -> False,
			Category -> "Data Specifications",
			Widget -> Widget[Type->Color,Pattern:>ColorP]
		},
		{
			OptionName -> PeakWidthColor,
			Default -> RGBColor[0.5, 0, 0.5],
			Description -> "Color of the peak width bars.",
			AllowNull -> False,
			Category -> "Data Specifications",
			Widget -> Widget[Type->Color,Pattern:>ColorP]
		},
		{
			OptionName -> PeakAreaColor,
			Default -> RGBColor[0., 0.5, 1.],
			Description -> "Color of the peak areas.",
			AllowNull -> False,
			Category -> "Data Specifications",
			Widget -> Widget[Type->Color,Pattern:>ColorP]
		},
		{
			OptionName -> ImageSize,
			Default -> 600,
			Description -> "The size of the plot on which the peak epilog will be included.",
			AllowNull -> False,
			Category -> "Hidden",
			Widget->Widget[Type->Expression, Pattern:>_, Size->Line]
		},
		{
			OptionName->AspectRatio,
			Default->1/GoldenRatio,
			AllowNull->False,
			Widget->Alternatives[
				Widget[Type->Number, Pattern:>GreaterP[0]],
				Widget[Type->Enumeration, Pattern:>Alternatives[1/GoldenRatio]]
			],
			Description->"The size of the plot on which the peak epilog will be included.",
			Category->"Plot Style"
		},
		{
			OptionName->XTransformationFunction,
			Default->Null,
			AllowNull->True,
			Category->"Hidden",
			Widget->Widget[Type->Expression,Pattern:>_,Size->Line],
			Description->"Function from time to another unit, which will be used to transform the x-axis."
		},
		{
			OptionName->PeakSplitting,
			Default->Automatic,
			AllowNull->False,
			Category->"Hidden",
			Widget->Widget[Type->Enumeration,Pattern:>BooleanP],
			Description->"True for visualization of NMR peak splitting, False otherwise."
		},
		ScaleOption
	}];


peakDataP = CoordinatesP | QuantityCoordinatesP[];


PeakEpilog[{},___]:=Null;
PeakEpilog[plotData:ListableP[peakDataP],Null,ops:OptionsPattern[PeakEpilog]]:={};
PeakEpilog[plotData:ListableP[peakDataP],{Null},ops:OptionsPattern[PeakEpilog]]:={{}};
PeakEpilog[plotData:ListableP[peakDataP],{Rule[_,{Null}]..}|{{Rule[_,{Null}]..}..},ops:OptionsPattern[PeakEpilog]]:={};

PeakEpilog[plotDatas:{peakDataP..},peakDatas:{PacketP[Object[Analysis,Peaks]]..},ops:OptionsPattern[PeakEpilog]]:=Switch[OptionValue[SecondYUnscaled],
	{(_List|Null)..},MapThread[PeakEpilog[#1,#2,SecondYUnscaled->#3,SecondYScaled->#4,XTransformationFunction->#5,ops]&,{plotDatas,peakDatas,OptionValue[SecondYUnscaled],OptionValue[SecondYScaled],OptionValue[XTransformationFunction]}],
	_,MapThread[PeakEpilog[#1,#2,ops]&,{plotDatas,peakDatas}]
]/;SameLengthQ[plotDatas,peakDatas];

PeakEpilog[plotDatas:{peakDataP..},peakData:PacketP[Object[Analysis,Peaks]],ops:OptionsPattern[PeakEpilog]]:=Switch[OptionValue[SecondYUnscaled],
	{(_List|Null)..},MapThread[PeakEpilog[#1,peakData,SecondYUnscaled->#2,SecondYScaled->#3,XTransformationFunction->#4,ops]&,{plotDatas,OptionValue[SecondYUnscaled],OptionValue[SecondYScaled],OptionValue[XTransformationFunction]}],
	_,PeakEpilog[#,peakData,ops]&/@plotDatas
];

(* Lookup necessary fields in the peakData packet and pass to main overload. *)
PeakEpilog[plotData:peakDataP,peakData:ListableP[PacketP[Object[Analysis,Peaks]]],ops:OptionsPattern[PeakEpilog]]:=Module[
	{
		pkEpilog,peakPointGraphic,peakIntegralGraphic,peakLabelGraphic,peakWidthGraphic,
		containsSplittingFieldsQ
	},

	(* Construct the peak epilogs using data from peak Data *)
	pkEpilog=PeakEpilog[plotData,
		Cases[Position/.peakData,Except[Null]],
		Cases[Height/.peakData,Except[Null]],
		Cases[HalfHeightWidth/.peakData,Except[Null]],
		Cases[Area/.peakData,Except[Null]],
		Cases[PeakRangeStart/.peakData,Except[Null]],
		Cases[PeakRangeEnd/.peakData,Except[Null]],
		Cases[WidthRangeStart/.peakData,Except[Null]],
		Cases[WidthRangeEnd/.peakData,Except[Null]],
		Cases[BaselineIntercept/.peakData,Except[Null]],
		Cases[BaselineSlope/.peakData,Except[Null]],
		BaselineFunction/.peakData,
		(* If no PeakLabel key, this will return an empty list *)
		Cases[Lookup[peakData,PeakLabel,Null],Except[Null]],
		ops
	];

	(* If the peak epilog has the correct dimensions, split by type. Otherwise return value (e.g. return single empty list if everything is null) *)
	If[MatchQ[pkEpilog,{_List,_List,_List,_List}],
		{peakPointGraphic,peakIntegralGraphic,peakLabelGraphic,peakWidthGraphic}=pkEpilog,
		Return[pkEpilog]
	];

	(* True if every supplied peak data packet contains peak splitting analysis *)
	containsSplittingFieldsQ=And@@(MatchQ[Lookup[#,NMRChemicalShift],Except[Null|{}|_Missing|$Failed]]&/@ToList[peakData]);

	(* If data has peak splitting fields and PeakSplitting was requested, generate splitting epilogs, else use default ones *)
	If[containsSplittingFieldsQ&&MatchQ[OptionValue[PeakSplitting],True|Automatic],
		splittingEpilog[peakData,peakPointGraphic,peakIntegralGraphic,peakLabelGraphic,peakWidthGraphic],
		Join[
			If[MemberQ[OptionValue[Display],Peaks],peakPointGraphic,{}],
			If[MemberQ[OptionValue[Display],Peaks],peakIntegralGraphic,{}],
			If[MemberQ[OptionValue[Display],Peaks],peakLabelGraphic,{}],
			If[MemberQ[OptionValue[Display],PeakWidths],peakWidthGraphic,{}]
		]
	]
];

(* Case where all information is null *)
PeakEpilog[plotData:peakDataP,<||>,ops:OptionsPattern[PeakEpilog]]:={};

(* Main case *)
PeakEpilog[
	plotData0:peakDataP,
	peakPositions_List,
	peakHeights_List,
	peakWidth_List,
	peakArea_List,
	peakRangeStart_List,
	peakRangeEnd_List,
	peakWidthRangeStart_List,
	peakWidthRangeEnd_List,
	peakBaselineIntercept_List,
	peakBaselineSlopes_List,
	peakBaselineFunction_,
	peakNames_List,
	ops:OptionsPattern[PeakEpilog]
]:=Module[
	{
		xmin,xmax,ymin,ymax,xrange,yrange,peakPoints,peakCenters,peakIntegrals,absoluteHeights,
		peakWidths,peakPointGraphic,peakLabelGraphic,peakIntegralGraphic,peakWidthGraphic,plotData,
		peakIntegralBaslineGraphic, safeOps
	},

	If[MatchQ[peakPositions,{}],
		Return[{}]
	];

	plotData = Unitless[plotData0];

	(* Range finding *)
	{{xmin,xmax},{ymin,ymax}}=OptionValue[PlotRange];
	xrange=xmax-xmin;
	yrange=ymax-ymin;

	(* --- Numeric Information --- *)

	(* Determine the absolute height in Units of the y axis rather than distance above the baseline *)
	absoluteHeights=MapThread[#2+peakBaselineFunction[#1]&,{peakPositions,peakHeights}];

	(* Peak Points are at {Position,Height} *)
	peakPoints=Transpose[{If[OptionValue[Reflected],-1,1](peakPositions),absoluteHeights}];

	(* Centers are at half height and below the dot *)
	peakCenters=Transpose[{If[OptionValue[Reflected],-1,1](peakPositions),Mean[{ymin,Min[#,ymax]}]+(yrange/15)&/@(absoluteHeights)}];

	(* Peak Integrals are the data within the peak range, with the baseline fused in to connect the bottoms of the peaks *)
	peakIntegrals=Module[{peakDomains,peakBaselineFunctions},
		peakDomains=Domains[plotData,If[OptionValue[Reflected],Transpose[{-1(peakRangeEnd),-1(peakRangeStart)}],Transpose[{(peakRangeStart),(peakRangeEnd)}]]];
		peakBaselineFunctions=If[OptionValue[Reflected],Function[arg,peakBaselineFunction[-arg]],peakBaselineFunction];
		includeBaseline[peakDomains,peakBaselineFunctions,plotData]
	];

	(* X cordinates of bars defiend by WidthRange and Y Cordinates of bars as 1/2 the height of the peak *)
	peakWidths=MapThread[
		Function[{widthPoint,height},{{First[widthPoint],height},{Last[widthPoint],height}}],
		{Transpose[{If[OptionValue[Reflected],-1,1](peakWidthRangeStart),If[OptionValue[Reflected],-1,1](peakWidthRangeEnd)}],absoluteHeights/2}
	];

	(* Determine the locations of the second Y axes intercepts (if there are any) *)
	(* --- Graphics --- *)
	peakPointGraphic=Module[{MouseOff,MouseOn,MouseLines},
		MouseOff={OptionValue[PeakPointColor],PointSize->OptionValue[PeakPointSize]0.85,Point[#]}&/@peakPoints;
		MouseOn={OptionValue[PeakPointColor],PointSize->OptionValue[PeakPointSize],Point[#]}&/@peakPoints;
		MouseLines=AxisLines[peakPoints,PlotRange->{{xmin,xmax},{ymin,ymax}},PassOptions[PeakEpilog,AxisLines,ReplaceRule[{ops}, {"LabelStyle" -> {Bold, 18, RGBColor[0, 0.5, 1], FontFamily->"Arial"}}]]];
		MapThread[Mouseover[#1,Join[{#3},{#2}]]&,{MouseOff,MouseOn,MouseLines}]
	];

	peakLabelGraphic=If[MatchQ[peakNames,{}|ToString/@Range[Length[peakPoints]]],
		{},
		Module[{
			standardVerticalOffset,overlapVerticalOffeset,aspectRatio,imageWidth,imageHeight,imageDimensions,
			unplacedPeakLabels,labelPercentageDimensions,pointNameIndexTuples,overlapBooleanIndexTuples,
			peakClusterNumbers,splitByCluster,maxHeightPerCluster,maxClusterHeights,labelStyle,labelEpilogs
		},
			(* Determine pixel size of plot *)
			aspectRatio=OptionValue[AspectRatio];
			imageWidth = OptionValue[ImageSize];
			imageHeight=imageWidth*aspectRatio;
			imageDimensions={imageWidth,imageHeight};

			(* Determine the percentage of the plot our labels will take up *)
			unplacedPeakLabels=Text[stylePeakLabel[#,OptionDefault[OptionValue[LabelStyle]]]]&/@peakNames;
			labelPercentageDimensions=Map[
				(ImageDimensions[ImageCrop[Graphics[#]]]/imageDimensions)&,
				unplacedPeakLabels
			];

			(* Add a wee bit of padding so that labels don't sit right on top of the peaks *)
			standardVerticalOffset=ymax*.045;

			(* If peak labels overlap use larger offset *)
			overlapVerticalOffeset=standardVerticalOffset*1.5;

			(* Generate point, name, index tuples *)
			pointNameIndexTuples=MapThread[
				{#1,#2,#3}&,
				{peakPoints,peakNames,Range[Length[peakPoints]]}
			];

			(* For each peak point ask if it will overlap with its left neighbor *)
			overlapBooleanIndexTuples=Map[
				Function[{pointAndIndex},
					Module[{currentPeakX,currenPeakY,name,index,previousPeakX,previousPeakY,currentLabelDimensions,previousLabelDimensions},

						{{currentPeakX,currenPeakY},name,index}=pointAndIndex;

						(* First peak will never need an adjusted height, return early from this Module *)
						If[MatchQ[index,1],
							Return[{False,index},Module]
						];

						(* Get the coordinates of the previous peak *)
						{previousPeakX,previousPeakY}=peakPoints[[index-1]];

						(* Get the dimensions of the current and previous labels *)
						currentLabelDimensions=labelPercentageDimensions[[index]];
						previousLabelDimensions=labelPercentageDimensions[[index-1]];

						Which[
							(* If the peak height difference is greater than the text height, we don't need to worry about overlapping labels *)
							(* Must account for the planned vertical offset of the current peak label when comparing *)
							Abs[(currenPeakY-previousPeakY)]/yrange>(Last[currentLabelDimensions]+0.025),{False,index},

							(* If the horizontal distance between the peaks is greater than the inner label width, we don't need to worry about overlapping labels *)
							(* Only need to account for half of each label width since they're split across peaks *)
							Abs[(currentPeakX-previousPeakX)]/xrange>(First[currentLabelDimensions]+First[previousLabelDimensions])/2, {False,index},

							(* If the names are long enough such that they intersect, we will need to move the label up *)
							True, {True,index}
						]
					]
				],
				pointNameIndexTuples
			];

			(* Assign each peak a number indicating the position is has in a cluster of nearby peaks *)
			(* For example if there were 6 peaks with the first 3 right next to each other, 1 alone and the last 2 next to each other, numbers would be {1,2,3,0,1,2}*)
			peakClusterNumbers=Fold[
				Function[{clusterNumbers,booleanAndIndex},
					Module[{boolean,index,lastClusterNumber,newClusterNumber},

						{boolean,index}=booleanAndIndex;
						lastClusterNumber = Last[clusterNumbers,0];

						newClusterNumber=Which[
							(* Peak overlaps with previous, so it is in a cluster *)
							boolean,lastClusterNumber+1,

							(* If no overlap with previous, last peak won't be in cluster *)
							!boolean&&MatchQ[index,Length[overlapBooleanIndexTuples]],0,

							(* If no overlap with peak to the left, check if there's overlap with peak to the right (i.e start of a cluster) *)
							!boolean&&First[overlapBooleanIndexTuples[[index+1]]],lastClusterNumber+1,

							(* Peak is not in cluster *)
							!boolean,0
						];

						Append[clusterNumbers,newClusterNumber]
					]
				],
				{},
				overlapBooleanIndexTuples
			];

			splitByCluster=SplitBy[Transpose[{peakClusterNumbers,peakHeights}],First[#]==0&];
			maxHeightPerCluster=Max[#[[All, 2]]]&/@splitByCluster;
			maxClusterHeights=Flatten[
				MapThread[
					Function[{cluster, max},
						ConstantArray[max, Length[cluster]]
					],
					{splitByCluster, maxHeightPerCluster}
				],
				1
			];

			labelStyle=OptionDefault[OptionValue[LabelStyle]];

			labelEpilogs=Flatten[MapThread[
				Function[{peakPoint,name,peakClusterNumber,maxPeakHeight},
					If[MatchQ[peakClusterNumber,0],
						{
							Text[stylePeakLabel[name,labelStyle],{First[peakPoint],Last[peakPoint]+standardVerticalOffset}]
						},
						Module[{labelY},
							labelY=maxPeakHeight+overlapVerticalOffeset*peakClusterNumber;
							{
								{Thin,Dashing[Tiny],defaultLabelColor,Line[{{First[peakPoint],Last[peakPoint]+(0.1*overlapVerticalOffeset)},{First[peakPoint],labelY-(0.275*overlapVerticalOffeset)}}]},
								Text[
									stylePeakLabel[
										name,
										If[MemberQ[labelStyle,Background->_],
											labelStyle,
											Append[labelStyle,Background->White]
										]
									],
									{First[peakPoint],labelY}
								]
							}
						]
					]
				],
				{peakPoints,peakNames,peakClusterNumbers,maxClusterHeights}
			],1];

			(* Sort so that text comes after lines (want it to be on top) *)
			Sort@labelEpilogs
		]
	];

	peakIntegralGraphic=Module[{MouseOff,MouseOn,MouseText},
		MouseOff={Opacity[0],Polygon[#]}&/@peakIntegrals;
		MouseOn={OptionValue[PeakAreaColor],Opacity[0.2],EdgeForm[Directive[Opacity[0.5],OptionValue[PeakAreaColor]]],Polygon[#]}&/@peakIntegrals;
		MouseText=MapThread[Text[peakPrint[#1],#2]&,{peakArea,peakCenters}];
		MapThread[Mouseover[#1,Join[{#2},{#3}]]&,{MouseOff,MouseOn,MouseText}]
	];

	peakWidthGraphic=Module[{MouseOff,MouseOn,MouseText},
		MouseOff={OptionValue[PeakWidthColor],Thickness[0.005],ErrorBar[#,PassOptions[PeakEpilog,ErrorBar,ops]]}&/@peakWidths;
		MouseOn={OptionValue[PeakWidthColor],Thickness[0.006],ErrorBar[#,PassOptions[PeakEpilog,ErrorBar,ops]]}&/@peakWidths;
		MouseText=MapThread[Text[peakPrint[#1],#2]&,{peakWidth,peakCenters}];
		MapThread[Mouseover[#1,Join[{#2},{#3}]]&,{MouseOff,MouseOn,MouseText}]
	];

	peakIntegralBaslineGraphic = Module[
		{drawLine,ys},
		drawLine[x1_, x2_, yf_] := {Opacity[0.2], Dashed, Blue, Line[Transpose[{plotData[[;;,1]],yf[plotData[[;;,1]]]}]]};
		(*MapThread[drawLine[#1, #2, peakBaselineFunction] &, {peakRangeStart, peakRangeEnd}]*)
		{Opacity[0.2], Dashed, Blue, Line[Transpose[{plotData[[;;,1]],peakBaselineFunction/@plotData[[;;,1]]}]]}
	];

	(* Return a list of each type of graphic. *)
	{peakPointGraphic,peakIntegralGraphic,peakLabelGraphic,peakWidthGraphic}
]/; OptionValue[XTransformationFunction]==Null;

(* Case where you have to transform the x data *)
PeakEpilog[
	plotData0:peakDataP,
	peakPositions_List,
	peakHeights_List,
	peakWidth_List,
	peakArea_List,
	peakRangeStart_List,
	peakRangeEnd_List,
	peakWidthRangeStart_List,
	peakWidthRangeEnd_List,
	peakBaselineIntercept_List,
	peakBaselineSlopes_List,
	peakBaselineFunction_,
	peakNames_List,
	ops:OptionsPattern[PeakEpilog]
]:=Module[
	{
		transformationFunction,inverseTransformationFunction,transformedPeakHeights,transformedPeakWidth,
		transformedPeakPositions,transformedPeakRangeStart,transformedPeakRangeEnd,transformedPeakWidthRangeStart,transformedPeakWidthRangeEnd,
		transformedBaselineFunction,transformedSlopesAndIntercepts,transformedPeakBaselineIntercept,transformedPeakBaselineSlope,
		transformedPeakArea,mainData,safeOps,applicableTransformationFunction
	},



	(* Get the safe options *)
	safeOps=SafeOptions[PeakEpilog,{ops}];

	(* Get Transformation functions *)
	(* transformationFunction is a symbolic function whereas applicableTransformationFunction is a pure function,
	   which makes it easier to use throughout the code *)
	transformationFunction=Lookup[safeOps,XTransformationFunction];
	applicableTransformationFunction=transformationFunction/.T->#&;
	inverseTransformationFunction=InverseFunction[applicableTransformationFunction];


	(* Transform basic values (simply applying the transformation function) *)
	{
		transformedPeakPositions,transformedPeakRangeStart,
		transformedPeakRangeEnd,transformedPeakWidthRangeStart,transformedPeakWidthRangeEnd
	}=Map[applicableTransformationFunction[Unitless[#]]&,{peakPositions,peakRangeStart,peakRangeEnd,peakWidthRangeStart,peakWidthRangeEnd},{2}];

	(* Transform the width *)
	transformedPeakWidth=transformedPeakWidthRangeEnd-transformedPeakWidthRangeStart;

	(* Transform baseline function *)
	transformedBaselineFunction=Function[v,First[peakBaselineFunction][inverseTransformationFunction[v]]];

	(* Transform baseline slope and intercept *)
	transformedSlopesAndIntercepts=MapThread[Function[{originalSlope,originalIntercept},
		Module[{originalLine,lineInTermsOfV,rearrangedLineInTermsOfV,transformedIntercept,transformedSlope},
			originalLine=y==originalSlope * t + originalIntercept;
			lineInTermsOfV = originalLine/.t->applicableTransformationFunction[v];
			rearrangedLineInTermsOfV=y/.First[Solve[lineInTermsOfV,y]];
			transformedIntercept=rearrangedLineInTermsOfV/.v->0;
			transformedSlope=D[rearrangedLineInTermsOfV,v];
			{transformedIntercept,transformedSlope}
		]
		],Unitless[{peakBaselineSlopes,peakBaselineIntercept}]
	];

	(* Transform baseline intercept and slope *)
	{transformedPeakBaselineIntercept,transformedPeakBaselineSlope}=Transpose[transformedSlopesAndIntercepts];

	(* Transform Peak Area *)
	transformedPeakArea=MapThread[
		Function[{start,end},
			Module[{neededData,xData,yData,baselineData},
				neededData=Select[plotData0,Between[#[[1]],{start,end}]&];
				xData=neededData[[All,1]];
				yData=neededData[[All,2]];
				baselineData=transformedBaselineFunction[#]&/@xData;
				Total[(Most[yData-baselineData]+Rest[yData-baselineData])/2*Differences[xData]]
			]
		],
		{transformedPeakRangeStart,transformedPeakRangeEnd}
	];

	(* Strip units of the values which don't have to be transformed *)
	transformedPeakHeights=Unitless[peakHeights];

	(* Remove the transformation function from the options and call PeakEpilog with the transformed values *)
	PeakEpilog[
		plotData0,transformedPeakPositions,transformedPeakHeights,transformedPeakWidth,transformedPeakArea,
		transformedPeakRangeStart,transformedPeakRangeEnd,transformedPeakWidthRangeStart,transformedPeakWidthRangeEnd,
		transformedPeakBaselineIntercept,transformedPeakBaselineSlope,transformedBaselineFunction,peakNames,
		Sequence@@Normal[Merge[{Association[safeOps], <|XTransformationFunction -> Null|>}, Last]]
	]
];

(*** Helper functions for PeakEpilog ***)

(* Utilities *)
stylePeakLabel[value_String,stylings_List]:=Style[value,stylings];
defaultLabelColor=GrayLevel[0.3];
peakPrint[value_?NumericQ]:=Style[N[SignificantFigures[value,6]],Bold,Black,FontFamily->"Arial",14,Background->Directive[White,Opacity[0.75]]];
peakPrint[str_String]:=Style[str,Bold,Black,FontFamily->"Arial",14,Background->Directive[White,Opacity[0.9]]];

(* Include the baseline in peak epilog *)
includeBaseline[peakDomains_List,peakBaselineFunction_Function,plotData_]:=Module[
		{peakBaselinesStarts,peakBaselinesEnds,blinePts},

	blinePts = Map[Function[dom,Transpose[{dom[[;;,1]],peakBaselineFunction/@dom[[;;,1]]}]],peakDomains];

	MapThread[
		Function[{domain,bpts},Join[domain,Reverse[bpts]]],
		{peakDomains,blinePts}
	]
];

(* Given a set of peak epilogs and peak splitting data, construct peak splitting epilogs *)
splittingEpilog[
	pkData:ListableP[PacketP[Object[Analysis,Peaks]]],
	pkPointGraphics_,
	pkIntegralGraphics_,
	pkLabelGraphics_,
	pkWidthGraphics_
]:=DynamicModule[
	{
		groupIndexedPkInts,groupIndexedMap,pkIntsByGroup,txtByGroup,labelPositionByGroup,
		pkAnnotations,splitTextLabels,splitIntegralGraphics,polygonBoundingBox,cleanupPeakIntegralGraphic,
		mergedSplitIntegralGraphics,pkAssigns,cleanAssigns,
		commonestMol,defaultPlot,showAssignmentsQ,dynamicIntGraphics,currAssgn
	},

	(* Get Peak splitting information from pkData, and convert to ACS annotations *)
	pkAnnotations=splittingToAnnotation[
		Transpose@Lookup[pkData,
			{NMRChemicalShift,NMRMultiplicity,NMRNuclearIntegral,NMRJCoupling}
		]
	];

	(* Prepend the peak splitting group of each peak to its peak integral graphic *)
	groupIndexedPkInts=MapThread[
		{#1,#2}&,
		{Lookup[pkData,NMRSplittingGroup],pkIntegralGraphics}
	];

	(* Group the peak integral graphics by splitting group *)
	groupIndexedMap=GroupBy[groupIndexedPkInts,First->Last];

	(* Group the peak integral graphics by splitting group *)
	pkIntsByGroup=Map[
		If[KeyExistsQ[groupIndexedMap,#],
			Lookup[groupIndexedMap,#],
			Null
		]&,
		Range[Length[pkAnnotations]]
	];

	(* Extract the text annotations only from the pkIntegralGraphics, by group *)
	txtByGroup=pkIntsByGroup/.{Mouseover[_,{___,tx_Text},___]:>(Last[tx])};

	(* Get the average position of a text label for each peak group *)
	labelPositionByGroup=Map[(Total[#]/Max[Length[#],1])&,txtByGroup];

	(* Text labels for each splitting group *)
	splitTextLabels=MapThread[
		Text[peakPrint["Group "<>ToString[#3]<>"\n"<>#1],#2]&,
		{pkAnnotations,labelPositionByGroup,Range[Length[pkAnnotations]]}
	];

	(* For each splitting group, join all the integral graphics together *)
	splitIntegralGraphics=MapThread[
		If[MatchQ[#1,Except[Null]],
			Mouseover[
				Join[First/@#1],
				Join[Last/@#1]/.{_EdgeForm->Nothing,_Text->#2}
			],
			Nothing
		]&,
		{pkIntsByGroup,splitTextLabels}
	];

	(* Helper function to find the smallest rectangle that contains peak polygons *)
	polygonBoundingBox[lst:{{_Opacity,_Polygon}..}]:=With[
		(* Extract and join all {x,y} points in the polygons *)
		{allPolygonPts=Join@@((Last/@lst)/.{Polygon->Sequence})},
		(* Make an invisible rectangle which covers all peak areas*)
		{{Opacity[0.0],Polygon@@ConvexHullMesh[allPolygonPts]}}
	];

	(* Helper function which prepends invisible bounding box to peak shading graphic *)
	cleanupPeakIntegralGraphic[lst:{{{__},_Text}..},bbox_]:=With[
		{
			(* The text label for the splitting group is duplicated across each peak integral shading, so consolidate *)
			textLabel=First[Last/@lst],

			(* List of peak shading graphics *)
			peakShadings=First/@lst
		},

		(* Join the graphics together *)
		Join[{bbox},peakShadings,{textLabel}]
	];

	(* Find the bounding box for each peak group so it's easier to mouse-over the narrow peaks *)
	mergedSplitIntegralGraphics=splitIntegralGraphics/.{
		Mouseover[pre_,post_,rest___]:>Mouseover[
			polygonBoundingBox[pre],
			cleanupPeakIntegralGraphic[post,polygonBoundingBox[pre]],
			rest
		]
	};

	(* Peak assignments from NMR analysis. Empty list {} if there are no assignments. *)
	pkAssigns=Lookup[pkData,NMRAssignment];

	(* True if peak assignments were provided and can be plotted *)
	showAssignmentsQ=MatchQ[pkAssigns,Except[{}|Null|{{Unknown,{}}..}]];

	(* Molecules in the peak assignments, with unknown tags removed *)
	cleanAssigns=DeleteCases[First/@pkAssigns,Unknown];

	(* The molecule to which the most assignments have been made *)
	commonestMol=If[showAssignmentsQ&&(Length[cleanAssigns]>0),
		First[Commonest[cleanAssigns,1]],
		Null
	];

	(* Default plot *)
	defaultPlot=If[MatchQ[commonestMol,Except[Null]],
		MoleculePlot[
			commonestMol,
			PlotTheme -> "AllAtom",
			Frame->True,
			Background->White,
			FrameTicks->False
		],
		Style["Blank",Opacity[0.0]]
	];

	(* Make the peak labels dynamic to highlight assignments if there are pkAssigns, otherwise return unchanged. *)
	dynamicIntGraphics=If[showAssignmentsQ,
		MapThread[
			Mouseover[
				Dynamic[currAssgn={commonestMol,{}};First[#1]],
				Dynamic[currAssgn=#2;Last[#1]]
			]&,
			{mergedSplitIntegralGraphics,pkAssigns}
		],
		mergedSplitIntegralGraphics
	];

	(* Create a dynamic molecule plot which uses dynamicIntGraphics to highlight peak assignments *)
	moleculeInset=If[showAssignmentsQ,
		{Dynamic@Inset[
			If[MatchQ[First[currAssgn],MoleculeP],
				MoleculePlot[
					First[currAssgn],
					Style[Last[currAssgn],RGBColor[0.4,0.5,0.7]],
					PlotTheme -> "AllAtom",
					Frame->True,
					Background->White,
					FrameTicks->False
				],
				defaultPlot
			],
			Scaled[{0.03,0.92}],
			Scaled[{0,1}],
			Scaled[0.37]
		]},
		{}
	];

	(* Join all the splitting epilogs together and return them alongside the molecule plot inset *)
	Join[pkPointGraphics,dynamicIntGraphics,moleculeInset]
];
